[{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"measure R package extends tidymodels preprocessing steps analytical measurement data (spectroscopy, chromatography, mass spectrometry). provides recipes-style interface spectral preprocessing techniques.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"development-commands","dir":"","previous_headings":"","what":"Development Commands","title":"CLAUDE.md","text":"","code":"# Generate documentation from roxygen2 comments devtools::document()  # Run all tests devtools::test()  # Run a single test file (filter matches test-*.R files) devtools::test(filter = \"smooth\")  # runs test-smooth.R  # Full CRAN-like package check devtools::check()  # Test coverage covr::package_coverage()  # Rebuild README.md from README.Rmd devtools::build_readme()  # Build pkgdown site pkgdown::build_site()  # Bump dev version usethis::use_version(\"dev\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"recipe-step-pattern","dir":"","previous_headings":"Architecture","what":"Recipe Step Pattern","title":"CLAUDE.md","text":"Every preprocessing step follows recipes framework three required methods: Step implementations R/ naming convention: step_measure_{operation}.R","code":"# Constructor function step_measure_*() → calls add_step()  # Three S3 methods required: prep.step_measure_*()   # Learn parameters from training data bake.step_measure_*()   # Apply transformation to new data tidy.step_measure_*()   # Return step parameters as tibble"},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"internal-data-format","dir":"","previous_headings":"Architecture","what":"Internal Data Format","title":"CLAUDE.md","text":"package uses custom S3 class hierarchy store measurement data: measure_tbl: Single measurement (tibble location value columns) measure_list: Collection measurements stored list column named .measures Key helper functions R/helpers.R: - measure_to_matrix() / matrix_to_measure(): Convert formats - find_measure_cols(): Detect measure columns class - check_for_measure() / check_has_measure(): Validation utilities","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"tunable-parameters","dir":"","previous_headings":"Architecture","what":"Tunable Parameters","title":"CLAUDE.md","text":"Parameters hyperparameter tuning tune::tune() defined R/parameters.R. tunable step parameter corresponding dials function (e.g., window_side(), baseline_lambda()).","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"data-flow","dir":"","previous_headings":"Architecture","what":"Data Flow","title":"CLAUDE.md","text":"Input: step_measure_input_long() step_measure_input_wide() converts data internal format Processing: Chain step_measure_*() functions apply transformations Output: step_measure_output_long() step_measure_output_wide() converts back","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"file-organization","dir":"","previous_headings":"Architecture","what":"File Organization","title":"CLAUDE.md","text":"Steps grouped functionality: - input_*.R / output_*.R: Data format conversion - baseline-*.R: Baseline correction methods (ALS, polynomial, etc.) - smooth*.R: Smoothing/filtering operations - align.R: Spectrum alignment (DTW, PTW, COW) - scale.R / normalize.R: Variable-wise scaling / sample-wise normalization - peak-operations.R: Peak detection integration - qc.R: Quality control steps - axis-validation.R: Data validation utilities - data-organization.R: Column detection role assignment","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"analytical-validation-subsystem","dir":"","previous_headings":"Architecture","what":"Analytical Validation Subsystem","title":"CLAUDE.md","text":"package includes complete analytical method validation framework: Calibration & Quantitation (calibration-*.R, lod-loq.R): - measure_calibration_fit() creates calibration curves weighted regression - measure_lod() / measure_loq() calculate detection/quantitation limits Precision & Accuracy (precision.R, accuracy.R): - measure_repeatability(), measure_intermediate_precision(), measure_reproducibility() - measure_accuracy(), measure_linearity() Uncertainty (uncertainty.R): - measure_uncertainty_budget() builds ISO GUM-compliant uncertainty budgets - uncertainty_component(), uncertainty_type_a(), uncertainty_type_b_*() Criteria & Assessment (criteria.R): - criterion() measure_criteria() define acceptance criteria - measure_assess() evaluates results criteria - Preset criteria: criteria_ich_q2(), criteria_bioanalytical(), etc. Validation Reports (validation-report.R): - measure_validation_report() collects validation results - render_validation_report() generates HTML/PDF/Word using Quarto templates - Templates inst/templates/: ICH Q2(R2) USP <1225> formats","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"CLAUDE.md","text":"Tests use testthat edition 3 snapshots tests/testthat/_snaps/. Helper data tests/testthat/helpers-*.R.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"python-integration","dir":"","previous_headings":"","what":"Python Integration","title":"CLAUDE.md","text":"baseline methods use pybaselines via reticulate. Python dependency configured DESCRIPTION Config/reticulate.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"code-style","dir":"","previous_headings":"","what":"Code Style","title":"CLAUDE.md","text":"Tidyverse style guide Roxygen2 Markdown syntax documentation exported functions need @export tag S3 methods validation objects include print(), summary(), tidy() methods","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"linting--formatting","dir":"","previous_headings":"","what":"Linting & Formatting","title":"CLAUDE.md","text":"project uses two complementary code quality tools: jarl catches: - vector_logic: Using | instead || () statements - potential bugs inefficiencies air enforces: - 2-space indentation function signatures - One argument per line long function calls - Closing parenthesis line multi-line constructs - Consistent line length limits Run committing pass CI checks.","code":"# Linter - catches logic/efficiency issues jarl check .        # Check for issues jarl check . --fix  # Auto-fix issues  # Formatter - enforces consistent code style air format .        # Format all R files"},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"pr-workflow","dir":"","previous_headings":"","what":"PR Workflow","title":"CLAUDE.md","text":"creating pull request, run following checks: adding new exported functions, ensure included _pkgdown.yml appropriate reference section. PR merged:","code":"# 1. Format all R files (including tests) air format .  # 2. Check for linting issues and auto-fix jarl check . --fix  # 3. Generate/update documentation R -e 'devtools::document()'  # 4. Run full package check (should pass with 0 errors, 0 warnings, 0 notes) R -e 'devtools::check()'  # 5. Build pkgdown site to verify documentation renders correctly R -e 'pkgdown::build_site()' # Clean up: switch to main, pull changes, delete local/remote feature branch usethis::pr_finish()"},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"technique-pack-registry","dir":"","previous_headings":"","what":"Technique Pack Registry","title":"CLAUDE.md","text":"package includes registry system technique packs (external packages extend measure): R/registry.R: Registration discovery infrastructure register_measure_pack(): extension packages register register_measure_step(): registering individual steps measure_packs(): List registered technique packs measure_steps(): List registered steps (core + extensions) Steps marked superseded (e.g., SEC/GPC steps) point users appropriate technique pack (e.g., measure.sec).","code":""},{"path":"https://jameshwade.github.io/measure/dev/CLAUDE.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"CLAUDE.md","text":"Packages Suggests must available CRAN Bioconductor Technique packs like measure.sec aren’t published yet Suggests Use documentation point users unpublished companion packages","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@rstudio.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to measure","title":"Contributing to measure","text":"outlines propose change measure. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to measure","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to measure","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to measure","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"JamesHWade/measure\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to measure","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://jameshwade.github.io/measure/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to measure","text":"Please note measure project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://jameshwade.github.io/measure/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 James Wade Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with measure","title":"Getting help with measure","text":"Thanks using measure! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"https://jameshwade.github.io/measure/dev/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with measure","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"https://jameshwade.github.io/measure/dev/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with measure","text":"Armed reprex, next step figure ask. ’s question: start community.rstudio.com, /StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"https://jameshwade.github.io/measure/dev/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with measure","text":"efficient possible, development tidyverse packages tends bursty, shouldn’t worry don’t get immediate response. Typically don’t look repo sufficient quantity issues accumulates, ’s burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can’t reproduce bug, can’t fix !","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Baseline Correction","text":"Baseline correction fundamental preprocessing step spectroscopic chromatographic data. Baselines can drift due instrument effects, sample scattering, fluorescence, detector response, obscuring chemical information measurements. measure package provides several baseline correction methods recipe steps, plus ability use custom R functions Python’s pybaselines library.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"the-problem-baseline-drift","dir":"Articles","previous_headings":"","what":"The problem: Baseline drift","title":"Baseline Correction","text":"Let’s visualize baseline issues NIR spectra:  Notice vertical offset spectra? baseline shift isn’t related chemical composition want model.","code":"data(meats)  # Convert to long format for visualization meats_viz <- meats |>   mutate(id = row_number()) |>   pivot_longer(     cols = starts_with(\"x_\"),     names_to = \"channel\",     values_to = \"transmittance\"   ) |>   mutate(channel = as.integer(gsub(\"x_\", \"\", channel)))  # Plot raw spectra meats_viz |>   filter(id <= 20) |>   ggplot(aes(x = channel, y = transmittance, group = id, color = factor(id))) +   geom_line(alpha = 0.7) +   labs(     x = \"Channel\",     y = \"Transmittance\",     title = \"Raw NIR Spectra with Baseline Variation\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"asymmetric-least-squares-als","dir":"Articles","previous_headings":"Built-in baseline correction methods","what":"Asymmetric Least Squares (ALS)","title":"Baseline Correction","text":"step_measure_baseline_als() uses Asymmetric Least Squares algorithm, excellent spectra peaks predominantly one direction (e.g., absorption peaks going emission peaks going ).  Key parameters: lambda: Smoothness penalty (higher = smoother baseline). Try 10^4 10^9. p: Asymmetry parameter (0-1). Lower values fit signal. Try 0.001-0.1.","code":"rec_als <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_als(lambda = 1e6, p = 0.01)  processed_als <- bake(prep(rec_als), new_data = NULL)  # Visualize using unnest plot_als <- processed_als |>   slice(1:20) |>   mutate(id = row_number()) |>   unnest(.measures)  ggplot(plot_als, aes(x = location, y = value, group = id, color = factor(id))) +   geom_line(alpha = 0.7) +   labs(     x = \"Channel\",     y = \"Corrected Transmittance\",     title = \"ALS Baseline Correction\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"polynomial-baseline","dir":"Articles","previous_headings":"Built-in baseline correction methods","what":"Polynomial baseline","title":"Baseline Correction","text":"step_measure_baseline_poly() fits polynomial spectrum subtracts . Simple fast, works well gentle baseline curvature.","code":"rec_poly <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_poly(degree = 2)  processed_poly <- bake(prep(rec_poly), new_data = NULL)  # Visualize using unnest plot_poly <- processed_poly |>   slice(1:20) |>   mutate(id = row_number()) |>   unnest(.measures)  ggplot(plot_poly, aes(x = location, y = value, group = id, color = factor(id))) +   geom_line(alpha = 0.7) +   labs(     x = \"Channel\",     y = \"Corrected Transmittance\",     title = \"Polynomial Baseline Correction (degree = 2)\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"robust-fitting-baseline","dir":"Articles","previous_headings":"Built-in baseline correction methods","what":"Robust fitting baseline","title":"Baseline Correction","text":"step_measure_baseline_rf() uses robust local regression (LOESS iterative reweighting) estimate baseline. Good complex baseline shapes.","code":"rec_rf <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_rf(span = 0.5) |>   step_measure_output_wide(prefix = \"nir_\")  processed_rf <- bake(prep(rec_rf), new_data = NULL) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"detrending","dir":"Articles","previous_headings":"Built-in baseline correction methods","what":"Detrending","title":"Baseline Correction","text":"step_measure_detrend() removes polynomial trends spectra. simplest baseline correction - just removes overall trend.","code":"rec_detrend <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_detrend(degree = 1) |>   step_measure_output_wide(prefix = \"nir_\")  processed_detrend <- bake(prep(rec_detrend), new_data = NULL) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"gpcsec-baseline-correction","dir":"Articles","previous_headings":"Built-in baseline correction methods","what":"GPC/SEC baseline correction","title":"Baseline Correction","text":"step_measure_baseline_gpc() specialized chromatography data baseline regions exist start end chromatogram.","code":"# For chromatography data rec_gpc <- recipe(outcome ~ ., data = chromatogram_data) |>    step_measure_input_long(signal, location = vars(time)) |>   step_measure_baseline_gpc(left_frac = 0.05, right_frac = 0.05, method = \"linear\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"custom-baseline-functions","dir":"Articles","previous_headings":"","what":"Custom baseline functions","title":"Baseline Correction","text":"step_measure_baseline_custom() lets provide R function baseline estimation. function receives measure_tbl (tibble location value columns) return numeric vector baseline values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"using-a-function","dir":"Articles","previous_headings":"Custom baseline functions","what":"Using a function","title":"Baseline Correction","text":"","code":"# Simple moving minimum baseline moving_min_baseline <- function(x, window = 51) {   y <- x$value   n <- length(y)   baseline <- numeric(n)   half_win <- window %/% 2     for (i in seq_len(n)) {     start <- max(1, i - half_win)     end <- min(n, i + half_win)     baseline[i] <- min(y[start:end], na.rm = TRUE)   }   baseline }  rec_custom <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_custom(.fn = moving_min_baseline, window = 101) |>   step_measure_output_wide(prefix = \"nir_\")  processed_custom <- bake(prep(rec_custom), new_data = NULL) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"using-a-formula","dir":"Articles","previous_headings":"Custom baseline functions","what":"Using a formula","title":"Baseline Correction","text":"quick one-liners, use formula interface .x measure_tbl:","code":"# LOESS baseline using formula rec_loess <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_custom(     .fn = ~ stats::loess(.x$value ~ .x$location, span = span)$fitted,     span = 0.3   ) |>   step_measure_output_wide(prefix = \"nir_\")  processed_loess <- bake(prep(rec_loess), new_data = NULL) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"extracting-the-baseline","dir":"Articles","previous_headings":"Custom baseline functions","what":"Extracting the baseline","title":"Baseline Correction","text":"step_measure_baseline_custom() step_measure_baseline_py(), set subtract = FALSE get baseline instead corrected signal:","code":"# Use custom baseline with subtract = FALSE to extract the baseline rec_extract <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_custom(     .fn = ~ stats::loess(.x$value ~ .x$location, span = 0.5)$fitted,     subtract = FALSE   )  baselines <- bake(prep(rec_extract), new_data = NULL)  # The .measures column now contains the estimated baselines baselines |>   slice(1) |>   unnest(.measures) |>   head() #> # A tibble: 6 × 5 #>   water   fat protein location value #>   <dbl> <dbl>   <dbl>    <dbl> <dbl> #> 1  60.5  22.5    16.7        1  2.62 #> 2  60.5  22.5    16.7        2  2.62 #> 3  60.5  22.5    16.7        3  2.62 #> 4  60.5  22.5    16.7        4  2.62 #> 5  60.5  22.5    16.7        5  2.62 #> 6  60.5  22.5    16.7        6  2.62"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"python-pybaselines-integration","dir":"Articles","previous_headings":"","what":"Python pybaselines integration","title":"Baseline Correction","text":"step_measure_baseline_py() provides access 50 baseline correction algorithms Python pybaselines library.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"setup","dir":"Articles","previous_headings":"Python pybaselines integration","what":"Setup","title":"Baseline Correction","text":"First, install pybaselines:","code":"# Install reticulate if needed install.packages(\"reticulate\")  # Install pybaselines reticulate::py_require(\"pybaselines\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"using-pybaselines-methods","dir":"Articles","previous_headings":"Python pybaselines integration","what":"Using pybaselines methods","title":"Baseline Correction","text":"","code":"# Asymmetric Least Squares rec_py_asls <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_py(method = \"asls\", lam = 1e6, p = 0.01) |>   step_measure_output_wide(prefix = \"nir_\")  # SNIP algorithm (good for spectroscopy) rec_py_snip <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_py(method = \"snip\", max_half_window = 40) |>   step_measure_output_wide(prefix = \"nir_\")  # Modified polynomial rec_py_modpoly <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_py(method = \"modpoly\", poly_order = 3) |>   step_measure_output_wide(prefix = \"nir_\")  # Morphological (rolling ball) rec_py_mor <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_py(method = \"rolling_ball\", half_window = 30) |>   step_measure_output_wide(prefix = \"nir_\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"available-pybaselines-methods","dir":"Articles","previous_headings":"Python pybaselines integration","what":"Available pybaselines methods","title":"Baseline Correction","text":"See pybaselines documentation full list parameter details.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"using-derivatives-for-baseline-correction","dir":"Articles","previous_headings":"","what":"Using derivatives for baseline correction","title":"Baseline Correction","text":"Savitzky-Golay derivatives remain powerful approach baseline correction, especially NIR spectroscopy:","code":"# First derivative removes constant baseline rec_d1 <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 1) |>   step_measure_output_wide(prefix = \"nir_\")  # Second derivative removes linear baseline rec_d2 <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 2) |>   step_measure_output_wide(prefix = \"nir_\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"hyperparameter-tuning","dir":"Articles","previous_headings":"","what":"Hyperparameter tuning","title":"Baseline Correction","text":"baseline correction steps tunable tidymodels tuning framework: step_measure_baseline_custom(), can declare tunable parameters explicitly:","code":"library(tune)  # Create tunable recipe rec_tunable <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_als(     lambda = tune(),  # Will be tuned     p = tune()        # Will be tuned   ) |>   step_measure_output_wide(prefix = \"nir_\")  # The tunable parameters are automatically detected tunable(rec_tunable) rec_custom_tunable <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_baseline_custom(     .fn = ~ stats::loess(.x$value ~ .x$location, span = span)$fitted,     span = 0.5,     tunable = list(       span = list(pkg = \"dials\", fun = \"degree\", range = c(0.1, 0.9))     )   )"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"complete-preprocessing-pipeline","dir":"Articles","previous_headings":"","what":"Complete preprocessing pipeline","title":"Baseline Correction","text":"Baseline correction often works best part complete preprocessing pipeline:","code":"rec_complete <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   # Baseline correction   step_measure_baseline_als(lambda = 1e6, p = 0.01) |>   # Scatter correction   step_measure_snv() |>   # Smoothing with mild derivative   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   # Output for modeling   step_measure_output_wide(prefix = \"nir_\")  final_data <- bake(prep(rec_complete), new_data = NULL) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L) final_data[1:5, 1:8] #> # A tibble: 5 × 8 #>   water   fat protein nir_01    nir_02    nir_03    nir_04    nir_05    #>   <dbl> <dbl>   <dbl> <list>    <list>    <list>    <list>    <list>    #> 1  60.5  22.5    16.7 <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> #> 2  46    40.1    13.5 <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> #> 3  71     8.4    20.5 <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> <dbl [1]> #> 4  72.8   5.9    20.7 <dbl [2]> <dbl [2]> <dbl [2]> <dbl [2]> <dbl [2]> #> 5  58.3  25.5    15.5 <dbl [2]> <dbl [2]> <dbl [2]> <dbl [2]> <dbl [2]>"},{"path":"https://jameshwade.github.io/measure/dev/articles/baseline.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Baseline Correction","text":"ALS (step_measure_baseline_als()) good default spectroscopy applications Polynomial (step_measure_baseline_poly()) works well simple baseline shapes Derivatives via step_measure_savitzky_golay() effective NIR/IR peak shapes aren’t critical Custom functions (step_measure_baseline_custom()) provide maximum flexibility pybaselines (step_measure_baseline_py()) offers 50+ advanced algorithms R options aren’t sufficient Combine baseline correction normalization (SNV/MSC) best results","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Internal Class System","text":"vignette describes measure’s internal class system. users won’t need interact internals directly, understanding useful ’re: Debugging unexpected behavior Contributing measure Building extensions work measure data","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Internal Class System","text":"Early versions measure relied column named .measures store spectral data. worked limitations: Name clashes users .measures column way multiple measure columns Detection relied column names, types Following Issue #16, measure now uses custom S3 classes. enables robust detection via inherits() supports multiple measure columns per dataset (see Multiple Measure Columns ).","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"the-two-classes","dir":"Articles","previous_headings":"","what":"The two classes","title":"Internal Class System","text":"measure uses two-level class hierarchy:","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"measure_tbl","dir":"Articles","previous_headings":"The two classes","what":"measure_tbl","title":"Internal Class System","text":"single measurement - tibble location value columns:","code":"# After preprocessing, each row's .measures element is a measure_tbl rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  result <- bake(rec, new_data = NULL)  # Extract one measurement one_measurement <- result$.measures[[1]] one_measurement #> <measure_tbl [100 x 2]> #> # A tibble: 100 × 2 #>    location value #>       <int> <dbl> #>  1        1  2.62 #>  2        2  2.62 #>  3        3  2.62 #>  4        4  2.62 #>  5        5  2.62 #>  6        6  2.62 #>  7        7  2.62 #>  8        8  2.62 #>  9        9  2.63 #> 10       10  2.63 #> # ℹ 90 more rows  # Check the class class(one_measurement) #> [1] \"measure_tbl\" \"tbl_df\"      \"tbl\"         \"data.frame\" is_measure_tbl(one_measurement) #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"measure_list","dir":"Articles","previous_headings":"The two classes","what":"measure_list","title":"Internal Class System","text":"list column containing multiple measure_tbl objects - one per row data:","code":"# The .measures column itself is a measure_list class(result$.measures) #> [1] \"measure_list\"  \"vctrs_list_of\" \"vctrs_vctr\"    \"list\" is_measure_list(result$.measures) #> [1] TRUE  # Nice printing in tibbles result #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"detecting-measure-columns","dir":"Articles","previous_headings":"","what":"Detecting measure columns","title":"Internal Class System","text":"measure provides helper functions find validate measure columns:","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"is_measure_list-and-is_measure_tbl","dir":"Articles","previous_headings":"Detecting measure columns","what":"is_measure_list() and is_measure_tbl()","title":"Internal Class System","text":"Test object appropriate class:","code":"is_measure_list(result$.measures) #> [1] TRUE is_measure_tbl(result$.measures[[1]]) #> [1] TRUE  # Regular lists and tibbles return FALSE is_measure_list(list()) #> [1] FALSE is_measure_tbl(tibble::tibble(location = 1:5, value = rnorm(5))) #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"find_measure_cols","dir":"Articles","previous_headings":"Detecting measure columns","what":"find_measure_cols()","title":"Internal Class System","text":"Find measure columns data frame:","code":"find_measure_cols(result) #> [1] \".measures\""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"has_measure_col","dir":"Articles","previous_headings":"Detecting measure columns","what":"has_measure_col()","title":"Internal Class System","text":"Check data frame least one measure column, erroring : used internally processing steps validate input.","code":"has_measure_col(result)"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"why-this-matters","dir":"Articles","previous_headings":"","what":"Why this matters","title":"Internal Class System","text":"class-based approach provides several benefits: Robust detection: Steps use inherits(x, \"measure_list\") instead checking column names Nice printing: Tibbles show <meas [100]> instead raw list output Multiple columns: can multiple measure columns per dataset (e.g., UV MS spectra) Validation: classes enforce measurements expected structure","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"for-package-developers","dir":"Articles","previous_headings":"","what":"For package developers","title":"Internal Class System","text":"’re writing functions work measure data: helper functions measure_to_matrix() matrix_to_measure() R/helpers.R convert measure lists matrices bulk operations.","code":"my_function <- function(data) {   # Validate input has measure columns   has_measure_col(data)    # Find measure columns   meas_cols <- find_measure_cols(data)    # Work with the measure_list   for (col in meas_cols) {     measurements <- data[[col]]     # Each element is a measure_tbl with $location and $value   } }"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"working-with-measure-data-interactively","dir":"Articles","previous_headings":"","what":"Working with Measure Data Interactively","title":"Internal Class System","text":"recipe steps primary interface production pipelines, measure provides utility functions interactive exploration debugging.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"measure_map-prototyping-transformations","dir":"Articles","previous_headings":"Working with Measure Data Interactively","what":"measure_map(): Prototyping transformations","title":"Internal Class System","text":"developing custom transformation, use measure_map() test interactively: Important: measure_map() exploration . transformation works, move step_measure_map() reproducible pipelines:","code":"# Apply a transformation to each sample's measurements centered <- measure_map(result, ~ {   .x$value <- .x$value - mean(.x$value)   .x })  # Check the result mean(centered$.measures[[1]]$value)  # Should be ~0 #> [1] -1.599431e-16 # For production use rec <- recipe(...) |>   step_measure_input_long(...) |>   step_measure_map(~ { .x$value <- .x$value - mean(.x$value); .x })"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"measure_map_safely-fault-tolerant-exploration","dir":"Articles","previous_headings":"Working with Measure Data Interactively","what":"measure_map_safely(): Fault-tolerant exploration","title":"Internal Class System","text":"exploring data might problematic samples, use safer variant:","code":"result <- measure_map_safely(data, risky_function)  # Check which samples failed result$errors  # result$result contains data with successful transforms # (failed samples keep original values)"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"measure_summarize-understanding-your-data","dir":"Articles","previous_headings":"Working with Measure Data Interactively","what":"measure_summarize(): Understanding your data","title":"Internal Class System","text":"Compute summary statistics across samples measurement location: useful : Computing reference spectra (e.g., MSC-style corrections) Identifying high-variability regions Quality control outlier detection","code":"# Default: mean and SD at each location stats <- measure_summarize(result) head(stats) #> # A tibble: 6 × 3 #>   location  mean    sd #>      <int> <dbl> <dbl> #> 1        1  2.81 0.411 #> 2        2  2.81 0.413 #> 3        3  2.81 0.416 #> 4        4  2.82 0.418 #> 5        5  2.82 0.421 #> 6        6  2.82 0.424"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"multiple-measure-columns","dir":"Articles","previous_headings":"","what":"Multiple Measure Columns","title":"Internal Class System","text":"measure supports multiple measure columns single dataset. useful different types measurements (e.g., UV MS spectra) need separate processing.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"creating-multiple-measure-columns","dir":"Articles","previous_headings":"Multiple Measure Columns","what":"Creating multiple measure columns","title":"Internal Class System","text":"Use col_name parameter input steps:","code":"rec <- recipe(outcome ~ ., data = my_data) |>   step_measure_input_wide(     starts_with(\"uv_\"),     col_name = \".uv_spectrum\"   ) |>   step_measure_input_wide(     starts_with(\"ms_\"),     col_name = \".ms_spectrum\"   )"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"processing-steps","dir":"Articles","previous_headings":"Multiple Measure Columns","what":"Processing steps","title":"Internal Class System","text":"default, processing steps operate measure columns: process specific columns, use measures parameter:","code":"rec <- rec |>   step_measure_snv()  # Applies to both .uv_spectrum and .ms_spectrum rec <- rec |>   step_measure_snv(measures = \".uv_spectrum\")  # Only UV"},{"path":"https://jameshwade.github.io/measure/dev/articles/internals.html","id":"output-steps","dir":"Articles","previous_headings":"Multiple Measure Columns","what":"Output steps","title":"Internal Class System","text":"multiple measure columns exist, output steps require specify column output: don’t specify multiple columns exist, ’ll get helpful error message telling columns available.","code":"rec <- rec |>   step_measure_output_wide(measures = \".uv_spectrum\", prefix = \"uv_\") |>   step_measure_output_wide(measures = \".ms_spectrum\", prefix = \"ms_\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with measure","text":"measure package extends tidymodels preprocessing steps designed specifically analytical measurement data. work spectroscopy, chromatography, instrument-generated signals, measure provides familiar recipes-style preprocessing integrates seamlessly tidymodels ecosystem.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"why-measure","dir":"Articles","previous_headings":"Introduction","what":"Why measure?","title":"Getting Started with measure","text":"Analytical data unique preprocessing requirements: Multi-dimensional signals: sample produces many measurements (e.g., absorbance hundreds wavelengths) Specialized transformations: Techniques like Savitzky-Golay derivatives scatter correction standard practice Format flexibility: Data may arrive wide format (one column per wavelength) long format (one row per measurement) measure handles keeping intuitive recipes interface already know. ## measure workflow typical measure workflow three phases: Input step: Convert data measure’s internal format Processing steps: Apply spectral preprocessing (smoothing, derivatives, normalization) Output step: Convert back format suitable modeling Let’s see action real data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"example-nir-spectroscopy-of-meat-samples","dir":"Articles","previous_headings":"","what":"Example: NIR spectroscopy of meat samples","title":"Getting Started with measure","text":"’ll use meats_long dataset included measure. contains NIR (Near-Infrared) transmittance spectra meat samples, goal predicting water, fat, protein content. data “long” format row represents one measurement one channel one sample. Let’s visualize spectra:","code":"data(meats_long)  # Each sample has 100 spectral channels meats_long #> # A tibble: 21,500 × 6 #>       id water   fat protein channel transmittance #>    <int> <dbl> <dbl>   <dbl>   <int>         <dbl> #>  1     1  60.5  22.5    16.7       1          2.62 #>  2     1  60.5  22.5    16.7       2          2.62 #>  3     1  60.5  22.5    16.7       3          2.62 #>  4     1  60.5  22.5    16.7       4          2.62 #>  5     1  60.5  22.5    16.7       5          2.62 #>  6     1  60.5  22.5    16.7       6          2.62 #>  7     1  60.5  22.5    16.7       7          2.62 #>  8     1  60.5  22.5    16.7       8          2.62 #>  9     1  60.5  22.5    16.7       9          2.63 #> 10     1  60.5  22.5    16.7      10          2.63 #> # ℹ 21,490 more rows meats_long |>   filter(id <= 10) |>   ggplot(aes(x = channel, y = transmittance, group = id, color = factor(id))) +   geom_line(alpha = 0.8) +   labs(     x = \"Channel\",     y = \"Transmittance\",     title = \"Raw NIR Spectra\",     color = \"Sample ID\"   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"creating-a-recipe","dir":"Articles","previous_headings":"Example: NIR spectroscopy of meat samples","what":"Creating a recipe","title":"Getting Started with measure","text":"start creating recipe specifies outcome variables predictors:","code":"rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   # Mark 'id' as an identifier, not a predictor   update_role(id, new_role = \"id\")  rec #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   3 #> predictor: 2 #> id:        1"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"step-1-input-the-measurements","dir":"Articles","previous_headings":"Example: NIR spectroscopy of meat samples","what":"Step 1: Input the measurements","title":"Getting Started with measure","text":"Since data long format, use step_measure_input_long(). converts transmittance values (indexed channel) measure’s internal format: prepping baking, ’ll see original transmittance channel columns replaced .measures column containing nested tibbles:","code":"rec <- rec |>   step_measure_input_long(transmittance, location = vars(channel))  rec #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   3 #> predictor: 2 #> id:        1 #>  #> ── Operations #> • Collate long analytical measurements: transmittance rec_prepped <- prep(rec) internal_format <- bake(rec_prepped, new_data = NULL)  # The data now has a .measures list-column internal_format #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows  # Each element contains location and value internal_format$.measures[[1]] #> <measure_tbl [100 x 2]> #> # A tibble: 100 × 2 #>    location value #>       <int> <dbl> #>  1        1  2.62 #>  2        2  2.62 #>  3        3  2.62 #>  4        4  2.62 #>  5        5  2.62 #>  6        6  2.62 #>  7        7  2.62 #>  8        8  2.62 #>  9        9  2.63 #> 10       10  2.63 #> # ℹ 90 more rows"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"step-2-apply-preprocessing","dir":"Articles","previous_headings":"Example: NIR spectroscopy of meat samples","what":"Step 2: Apply preprocessing","title":"Getting Started with measure","text":"Now can add spectral preprocessing steps. operate internal .measures column: measure provides many built-preprocessing steps: Filtering: step_measure_savitzky_golay() smoothing derivatives Scatter correction: step_measure_snv(), step_measure_msc() Sample-wise normalization: step_measure_normalize_sum(), step_measure_normalize_max(), step_measure_normalize_peak(), Variable-wise scaling: step_measure_center(), step_measure_scale_auto(), step_measure_scale_pareto(), Custom transformations: step_measure_map() built-steps don’t cover needs See vignette(\"preprocessing\") details available options. Let’s see transforms spectra:","code":"rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>    # Savitzky-Golay first derivative for baseline removal   step_measure_savitzky_golay(     window_side = 5,     differentiation_order = 1   ) |>   # Standard Normal Variate for scatter correction   step_measure_snv()  rec #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:   3 #> predictor: 2 #> id:        1 #>  #> ── Operations #> • Collate long analytical measurements: transmittance #> Savitzky-Golay preprocessing on  #> SNV transformation on processed <- bake(prep(rec), new_data = NULL)  # Unnest for plotting plot_data <- processed |>   filter(row_number() <= 10) |>   mutate(sample_id = row_number()) |>   unnest(.measures)  ggplot(plot_data, aes(x = location, y = value, group = sample_id, color = factor(sample_id))) +   geom_line(alpha = 0.8) +   labs(     x = \"Channel\",     y = \"Preprocessed Signal\",     title = \"After Savitzky-Golay + SNV\",     subtitle = \"First derivative removes baseline; SNV normalizes scatter\",     color = \"Sample\"   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"step-3-output-for-modeling","dir":"Articles","previous_headings":"Example: NIR spectroscopy of meat samples","what":"Step 3: Output for modeling","title":"Getting Started with measure","text":"modeling workflows, ’ll want data wide format (one column per spectral feature):","code":"rec_full <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv() |>   step_measure_output_wide(prefix = \"nir_\")  modeling_data <- bake(prep(rec_full), new_data = NULL)  # Ready for modeling! modeling_data[1:5, 1:10] #> # A tibble: 5 × 10 #>      id water   fat protein  nir_01  nir_02  nir_03  nir_04  nir_05  nir_06 #>   <int> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1     1  60.5  22.5    16.7 -0.126  -0.110  -0.0928 -0.0745 -0.0553 -0.0346 #> 2     2  46    40.1    13.5  0.0184  0.0381  0.0601  0.0841  0.110   0.137  #> 3     3  71     8.4    20.5  0.105   0.114   0.125   0.136   0.148   0.159  #> 4     4  72.8   5.9    20.7  0.0716  0.0786  0.0871  0.0974  0.108   0.119  #> 5     5  58.3  25.5    15.5 -0.132  -0.118  -0.101  -0.0817 -0.0608 -0.0385"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"working-with-wide-format-data","dir":"Articles","previous_headings":"","what":"Working with wide-format data","title":"Getting Started with measure","text":"data starts wide format (measurements columns), use step_measure_input_wide() instead. ’s example using data modeldata:","code":"library(modeldata) data(meats)  # This data has x_001, x_002, ... columns for spectral channels head(meats[, 1:8]) #> # A tibble: 6 × 8 #>   x_001 x_002 x_003 x_004 x_005 x_006 x_007 x_008 #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  2.62  2.62  2.62  2.62  2.62  2.62  2.62  2.62 #> 2  2.83  2.84  2.84  2.85  2.85  2.86  2.86  2.87 #> 3  2.58  2.58  2.59  2.59  2.59  2.59  2.59  2.60 #> 4  2.82  2.82  2.83  2.83  2.83  2.83  2.83  2.84 #> 5  2.79  2.79  2.79  2.79  2.80  2.80  2.80  2.80 #> 6  3.01  3.02  3.02  3.03  3.03  3.04  3.04  3.05  # Create location values (optional - defaults to 1, 2, 3, ...) wavelengths <- seq(850, 1050, length.out = 100)  rec_wide <- recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(     starts_with(\"x_\"),     location_values = wavelengths   ) |>   step_measure_snv() |>   step_measure_output_wide(prefix = \"spec_\")  bake(prep(rec_wide), new_data = NULL)[1:5, 1:8] #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L) #> # A tibble: 5 × 8 #>   water   fat protein spec_0850.0000 spec_0852.0202 spec_0854.0404 #>   <dbl> <dbl>   <dbl> <list>         <list>         <list>         #> 1  60.5  22.5    16.7 <dbl [1]>      <dbl [1]>      <dbl [1]>      #> 2  46    40.1    13.5 <dbl [1]>      <dbl [1]>      <dbl [1]>      #> 3  71     8.4    20.5 <dbl [1]>      <dbl [1]>      <dbl [1]>      #> 4  72.8   5.9    20.7 <dbl [2]>      <dbl [2]>      <dbl [2]>      #> 5  58.3  25.5    15.5 <dbl [2]>      <dbl [2]>      <dbl [2]>      #> # ℹ 2 more variables: spec_0856.0606 <list>, spec_0858.0808 <list>"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"applying-recipes-to-new-data","dir":"Articles","previous_headings":"","what":"Applying recipes to new data","title":"Getting Started with measure","text":"Like recipe, prep training data, bake new data:","code":"# Split the data set.seed(123) train_idx <- sample(nrow(meats), 180) train_data <- meats[train_idx, ] test_data <- meats[-train_idx, ]  # Prep on training data rec <- recipe(water + fat + protein ~ ., data = train_data) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 1) |>   step_measure_snv() |>   step_measure_output_wide(prefix = \"nir_\")  rec_prepped <- prep(rec, training = train_data) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)  # Bake on both train_processed <- bake(rec_prepped, new_data = NULL) test_processed <- bake(rec_prepped, new_data = test_data) #> Warning: Values from `value` are not uniquely identified; output will contain list-cols. #> • Use `values_fn = list` to suppress this warning. #> • Use `values_fn = {summary_fun}` to summarise duplicates. #> • Use the following dplyr code to identify duplicates. #>   {data} |> #>   dplyr::summarise(n = dplyr::n(), .by = c(water, fat, protein, location)) |> #>   dplyr::filter(n > 1L)  cat(\"Training samples:\", nrow(train_processed), \"\\n\") #> Training samples: 153 cat(\"Test samples:\", nrow(test_processed), \"\\n\") #> Test samples: 32"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"integration-with-tidymodels","dir":"Articles","previous_headings":"","what":"Integration with tidymodels","title":"Getting Started with measure","text":"measure recipes work seamlessly broader tidymodels ecosystem. See vignette(\"recipes\") complete examples including: Bundling preprocessing models using workflows Cross-validation measure recipes Hyperparameter tuning preprocessing steps Comparing preprocessing strategies","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"included-datasets","dir":"Articles","previous_headings":"Finding test data","what":"Included datasets","title":"Getting Started with measure","text":"measure package includes several datasets testing examples:","code":"# NIR spectroscopy data(meats_long)           # 215 meat samples, long format  # Raman spectroscopy data(glucose_bioreactors)  # Loads bioreactors_small (210) and bioreactors_large (42)  # Chromatography data(hplc_chromatograms)   # 20 simulated HPLC samples data(sec_chromatograms)    # 10 SEC samples (5 standards + 5 polymers) data(sec_calibration)      # MW calibration standards  # Mass spectrometry data(maldi_spectra)        # 16 simulated MALDI-TOF spectra"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"external-data-sources","dir":"Articles","previous_headings":"Finding test data","what":"External data sources","title":"Getting Started with measure","text":"additional test data, several R packages provide spectral datasets: Online repositories public analytical data: Mendeley Data - Search spectroscopy/chromatography datasets Zenodo - Open science data repository NIST Chemistry WebBook - Reference IR, MS, UV-Vis spectra MassBank - Mass spectrometry database HMDB - Human Metabolome Database (NMR, MS)","code":"# modeldata - meats dataset in wide format library(modeldata) data(meats)  # prospectr - NIR soil spectroscopy (825 samples) data(NIRsoil, package = \"prospectr\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/measure.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting Started with measure","text":"Savitzky-Golay smoothing derivatives SNV MSC scatter correction Sample-wise normalization (sum, max, range, peak region) Variable-wise scaling (centering, auto-scaling, Pareto scaling) Explore hyperparameter tuning tune - Savitzky-Golay peak normalization steps tunable! Check function reference available steps","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multi-Dimensional Measurements","text":"Many analytical techniques produce multi-dimensional data. Examples include: LC-DAD: Liquid chromatography diode array detection (time × wavelength) GC×GC: Comprehensive two-dimensional gas chromatography (time₁ × time₂) EEM: Excitation-emission matrix fluorescence (excitation × emission wavelength) 2D NMR: Two-dimensional nuclear magnetic resonance (chemical shift × chemical shift) measure package provides native support n-dimensional measurement data measure_nd_tbl measure_nd_list classes.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"creating-2d-measurement-data","dir":"Articles","previous_headings":"","what":"Creating 2D Measurement Data","title":"Multi-Dimensional Measurements","text":"Let’s create synthetic LC-DAD data retention time wavelength dimensions: typical “long format” 2D analytical data, row represents single measurement specific (time, wavelength) coordinate.","code":"set.seed(42)  # Simulate 3 samples with LC-DAD measurements # 10 time points × 4 wavelengths = 40 data points per sample lc_dad_data <- tibble(   sample_id = rep(1:3, each = 40),   retention_time = rep(rep(seq(0, 9, by = 1), each = 4), 3),   wavelength = rep(c(254, 280, 320, 350), 30),   absorbance = rnorm(120, mean = 100, sd = 10),   concentration = rep(c(10, 25, 50), each = 40) )  head(lc_dad_data, 12) #> # A tibble: 12 × 5 #>    sample_id retention_time wavelength absorbance concentration #>        <int>          <dbl>      <dbl>      <dbl>         <dbl> #>  1         1              0        254      114.             10 #>  2         1              0        280       94.4            10 #>  3         1              0        320      104.             10 #>  4         1              0        350      106.             10 #>  5         1              1        254      104.             10 #>  6         1              1        280       98.9            10 #>  7         1              1        320      115.             10 #>  8         1              1        350       99.1            10 #>  9         1              2        254      120.             10 #> 10         1              2        280       99.4            10 #> 11         1              2        320      113.             10 #> 12         1              2        350      123.             10"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"ingesting-2d-data","dir":"Articles","previous_headings":"","what":"Ingesting 2D Data","title":"Multi-Dimensional Measurements","text":"Use step_measure_input_long() multiple location columns create 2D measure column: .measures column now contains measure_nd_list objects - one 2D measurement per sample:","code":"rec <- recipe(concentration ~ ., data = lc_dad_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_input_long(     absorbance,     location = vars(retention_time, wavelength),     dim_names = c(\"time\", \"wavelength\"),     dim_units = c(\"min\", \"nm\")   ) |>   prep()  result <- bake(rec, new_data = NULL) result #> # A tibble: 3 × 3 #>   sample_id concentration .measures #>       <int>         <dbl>  <meas2d> #> 1         1            10  [40 × 3] #> 2         2            25  [40 × 3] #> 3         3            50  [40 × 3] class(result$.measures) #> [1] \"measure_nd_list\" \"measure_list\"    \"vctrs_list_of\"   \"vctrs_vctr\"      #> [5] \"list\" measure_ndim(result$.measures) #> [1] 2"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"inspecting-2d-measurements","dir":"Articles","previous_headings":"","what":"Inspecting 2D Measurements","title":"Multi-Dimensional Measurements","text":"element measure column measure_nd_tbl: Dimension metadata preserved:","code":"# First sample's measurement m1 <- result$.measures[[1]] class(m1) #> [1] \"measure_nd_tbl\" \"measure_tbl\"    \"tbl_df\"         \"tbl\"            #> [5] \"data.frame\" m1 #> <measure_nd_tbl [40 x 3] time x wavelength> #> <measure_tbl [40 x 3]> #> # A tibble: 40 × 3 #>    location_1 location_2 value #>         <dbl>      <dbl> <dbl> #>  1          0        254 114.  #>  2          0        280  94.4 #>  3          0        320 104.  #>  4          0        350 106.  #>  5          1        254 104.  #>  6          1        280  98.9 #>  7          1        320 115.  #>  8          1        350  99.1 #>  9          2        254 120.  #> 10          2        280  99.4 #> # ℹ 30 more rows measure_dim_names(m1) #> [1] \"time\"       \"wavelength\" measure_dim_units(m1) #> [1] \"min\" \"nm\""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"grid-information","dir":"Articles","previous_headings":"","what":"Grid Information","title":"Multi-Dimensional Measurements","text":"measure_grid_info() function provides detailed information measurement grid: “regular” grid means combinations location values present (complete rectangular grid).","code":"info <- measure_grid_info(m1) info$ndim #> [1] 2 info$shape #> dim_1 dim_2  #>    10     4 info$n_points #> [1] 40 info$is_regular #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"applying-1d-operations-to-2d-data","dir":"Articles","previous_headings":"","what":"Applying 1D Operations to 2D Data","title":"Multi-Dimensional Measurements","text":"measure_apply() function enables existing 1D preprocessing operations work n-dimensional data applying along specified dimensions. Apply smoothing along time dimension (dimension 1): function applied independently wavelength slice, treating time 1D axis.","code":"# Define a simple 1D smoothing function smooth_1d <- function(x, window = 3) {   if (nrow(x) < window) return(x)   smoothed <- stats::filter(x$value, rep(1/window, window), sides = 2)   valid <- !is.na(smoothed)   new_measure_tbl(     location = x$location[valid],     value = as.numeric(smoothed[valid])   ) } # Apply to a single 2D measurement smoothed <- measure_apply(m1, smooth_1d, along = 1, window = 3)  # Original had 40 points (10 time × 4 wavelength) nrow(m1) #> [1] 40  # Smoothed has fewer points (edges removed by filter) nrow(smoothed) #> [1] 32"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"converting-back-to-long-format","dir":"Articles","previous_headings":"","what":"Converting Back to Long Format","title":"Multi-Dimensional Measurements","text":"Use step_measure_output_long() convert nested measure back long format: 2D data, location columns named dimension suffixes (loc_1, loc_2).","code":"output_rec <- recipe(concentration ~ ., data = lc_dad_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_input_long(     absorbance,     location = vars(retention_time, wavelength)   ) |>   step_measure_output_long(     values_to = \"absorbance\",     location_to = \"loc\"   ) |>   prep()  output_result <- bake(output_rec, new_data = NULL) head(output_result) #> # A tibble: 6 × 5 #>   sample_id concentration loc_1 loc_2 absorbance #>       <int>         <dbl> <dbl> <dbl>      <dbl> #> 1         1            10     0   254      114.  #> 2         1            10     0   280       94.4 #> 3         1            10     0   320      104.  #> 4         1            10     0   350      106.  #> 5         1            10     1   254      104.  #> 6         1            10     1   280       98.9"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"irregular-grids","dir":"Articles","previous_headings":"","what":"Irregular Grids","title":"Multi-Dimensional Measurements","text":"2D data forms regular rectangular grid. package handles irregular grids gracefully:","code":"# Create irregular data (different wavelengths sampled at different times) irregular_data <- tibble(   sample_id = rep(1, 7),   time = c(0, 0, 0, 5, 5, 10, 10),   wavelength = c(254, 280, 320, 254, 280, 254, 350),   value = rnorm(7),   outcome = 1 )  irr_rec <- recipe(outcome ~ ., data = irregular_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_input_long(value, location = vars(time, wavelength)) |>   prep()  irr_result <- bake(irr_rec, new_data = NULL)  # Check regularity measure_is_regular(irr_result$.measures[[1]]) #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"dimension-reduction-operations","dir":"Articles","previous_headings":"","what":"Dimension Reduction Operations","title":"Multi-Dimensional Measurements","text":"package provides several operations reducing dimensionality nD data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"unfolding-and-folding","dir":"Articles","previous_headings":"Dimension Reduction Operations","what":"Unfolding and Folding","title":"Multi-Dimensional Measurements","text":"measure_unfold() converts nD data 1D use modeling techniques expect vectors: measure_fold() reconstructs original nD structure:","code":"# Unfold 2D to 1D m1d <- measure_unfold(m1) m1d #> <measure_tbl [40 x 2]> #> # A tibble: 40 × 2 #>    location value #>       <int> <dbl> #>  1        1 114.  #>  2        2 104.  #>  3        3 120.  #>  4        4  86.1 #>  5        5  97.2 #>  6        6  96.9 #>  7        7 119.  #>  8        8 105.  #>  9        9 110.  #> 10       10  92.2 #> # ℹ 30 more rows  # The fold metadata is preserved attr(m1d, \"fold_info\")$ndim #> [1] 2 # Reconstruct 2D from 1D m2d_restored <- measure_fold(m1d) measure_ndim(m2d_restored) #> [1] 2"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"slicing","dir":"Articles","previous_headings":"Dimension Reduction Operations","what":"Slicing","title":"Multi-Dimensional Measurements","text":"measure_slice() extracts subsets specific coordinates:","code":"# Extract data at wavelength = 254 slice_254 <- measure_slice(m1, wavelength = 254) slice_254 #> <measure_tbl [10 x 2]> #> # A tibble: 10 × 2 #>    location value #>       <dbl> <dbl> #>  1        0 114.  #>  2        1 104.  #>  3        2 120.  #>  4        3  86.1 #>  5        4  97.2 #>  6        5  96.9 #>  7        6 119.  #>  8        7 105.  #>  9        8 110.  #> 10        9  92.2  # Extract multiple wavelengths (keeps 2D structure) slice_uv <- measure_slice(m1, wavelength = c(254, 280), drop = FALSE) measure_ndim(slice_uv) #> [1] 2"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"projection","dir":"Articles","previous_headings":"Dimension Reduction Operations","what":"Projection","title":"Multi-Dimensional Measurements","text":"measure_project() aggregates across dimensions:","code":"# Average across wavelengths to get time trace time_trace <- measure_project(m1, along = \"wavelength\") time_trace #> <measure_tbl [10 x 2]> #> # A tibble: 10 × 2 #>    location value #>       <dbl> <dbl> #>  1        0 105.  #>  2        1 104.  #>  3        2 114.  #>  4        3  97.1 #>  5        4  89.8 #>  6        5  97.4 #>  7        6  98.6 #>  8        7 102.  #>  9        8  98.0 #> 10        9  90.0  # Sum across time to get total absorbance per wavelength wl_total <- measure_project(m1, along = \"time\", fn = sum) wl_total #> <measure_tbl [4 x 2]> #> # A tibble: 4 × 2 #>   location value #>      <dbl> <dbl> #> 1      254 1044. #> 2      280  920. #> 3      320  987. #> 4      350 1033."},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"multi-channel-operations","dir":"Articles","previous_headings":"","what":"Multi-Channel Operations","title":"Multi-Dimensional Measurements","text":"working multiple detector channels (e.g., UV + RI SEC, multiple wavelengths LC-DAD), package provides steps aligning, combining, computing ratios channels.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"channel-alignment","dir":"Articles","previous_headings":"Multi-Channel Operations","what":"Channel Alignment","title":"Multi-Dimensional Measurements","text":"step_measure_channel_align() aligns multiple measure columns common grid: Methods include: - \"intersection\": Keep locations present channels - \"union\": Include locations, interpolating missing values - \"reference\": Align channels reference channel’s grid","code":"# Align UV and RI detector signals to the same time grid rec <- recipe(outcome ~ ., data = sec_data) |>  step_measure_input_wide(starts_with(\"uv_\"), col_name = \"uv\") |>  step_measure_input_wide(starts_with(\"ri_\"), col_name = \"ri\") |>  step_measure_channel_align(uv, ri, method = \"intersection\") |>  prep()"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"channel-combination","dir":"Articles","previous_headings":"Multi-Channel Operations","what":"Channel Combination","title":"Multi-Dimensional Measurements","text":"step_measure_channel_combine() merges multiple channels: Strategies include: - \"stack\": Create 2D measure channel dimension - \"concat\": Concatenate single 1D vector - \"mean\" \"weighted_sum\": Combine single channel","code":"# Stack channels into a single 2D measure (location x channel) rec <- recipe(outcome ~ ., data = multi_detector_data) |>  step_measure_input_wide(starts_with(\"uv_\"), col_name = \"uv\") |>  step_measure_input_wide(starts_with(\"ri_\"), col_name = \"ri\") |>  step_measure_channel_align(uv, ri) |>  step_measure_channel_combine(uv, ri, strategy = \"stack\") |>  prep()"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"channel-ratios","dir":"Articles","previous_headings":"Multi-Channel Operations","what":"Channel Ratios","title":"Multi-Dimensional Measurements","text":"step_measure_channel_ratio() computes ratios channels:","code":"# Compute UV/RI ratio for each sample rec <- recipe(outcome ~ ., data = sec_data) |>  step_measure_input_wide(starts_with(\"uv_\"), col_name = \"uv\") |>  step_measure_input_wide(starts_with(\"ri_\"), col_name = \"ri\") |>  step_measure_channel_align(uv, ri) |>  step_measure_channel_ratio(numerator = uv, denominator = ri) |>  prep()"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"multi-way-analysis","dir":"Articles","previous_headings":"","what":"Multi-Way Analysis","title":"Multi-Dimensional Measurements","text":"extracting interpretable components 2D 3D measurement data, package provides multi-way decomposition methods.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"parafac-decomposition","dir":"Articles","previous_headings":"Multi-Way Analysis","what":"PARAFAC Decomposition","title":"Multi-Dimensional Measurements","text":"step_measure_parafac() performs Parallel Factor Analysis, extracting trilinear components: PARAFAC particularly useful : - EEM fluorescence (excitation x emission matrices) - Resolving overlapping chromatographic peaks - Identifying underlying chemical species mixtures","code":"# Extract 3 PARAFAC components from EEM fluorescence data rec <- recipe(concentration ~ ., data = eem_data) |>  step_measure_input_long(    fluorescence,    location = vars(excitation, emission)  ) |>  step_measure_parafac(n_components = 3) |>  prep()  # Result contains parafac_1, parafac_2, parafac_3 score columns baked <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"tucker-decomposition","dir":"Articles","previous_headings":"Multi-Way Analysis","what":"Tucker Decomposition","title":"Multi-Dimensional Measurements","text":"step_measure_tucker() provides flexibility independent ranks per mode:","code":"# Tucker decomposition with different ranks for each dimension rec <- recipe(concentration ~ ., data = lc_dad_data) |>  step_measure_input_long(    absorbance,    location = vars(time, wavelength)  ) |>  step_measure_tucker(ranks = c(5, 3)) |>  # 5 time, 3 wavelength components  prep()"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"mcr-als-experimental","dir":"Articles","previous_headings":"Multi-Way Analysis","what":"MCR-ALS (Experimental)","title":"Multi-Dimensional Measurements","text":"step_measure_mcr_als() implements Multivariate Curve Resolution Alternating Least Squares: Note: MCR-ALS marked experimental. implementation uses simple ALS algorithm suitable exploratory analysis.","code":"# MCR-ALS with non-negativity constraints rec <- recipe(concentration ~ ., data = chrom_data) |>  step_measure_input_long(    absorbance,    location = vars(time, wavelength)  ) |>  step_measure_mcr_als(    n_components = 3,    non_negativity = TRUE  ) |>  prep()"},{"path":"https://jameshwade.github.io/measure/dev/articles/multidimensional.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Multi-Dimensional Measurements","text":"Key functions multi-dimensional measurement data:","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Preprocessing Techniques","text":"Spectral preprocessing essential building accurate chemometric models. Raw spectra often contain unwanted variation physical effects (scatter, baseline drift) obscure chemical information ’re trying model. vignette covers preprocessing technique available measure use .","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"why-preprocess-spectra","dir":"Articles","previous_headings":"","what":"Why preprocess spectra?","title":"Preprocessing Techniques","text":"diving specific techniques, let’s understand ’re dealing . raw NIR spectra meats dataset:  Notice spectra shifted vertically relative ? offset isn’t due chemical differences - ’s caused physical factors like particle size, path length, light scatter. preprocessing goal remove unwanted effects preserving chemical information.","code":"rec_raw <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths)  raw_data <- get_internal(rec_raw)  plot_spectra(raw_data, \"Raw NIR Spectra\", \"Note the vertical offset differences between samples\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"what-it-does","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"What it does","title":"Preprocessing Techniques","text":"Savitzky-Golay filter performs polynomial smoothing can compute derivatives. fits polynomial sliding window points, using polynomial’s value (derivative) center point output.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"when-to-use-it","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"When to use it","title":"Preprocessing Techniques","text":"Smoothing (order = 0): Reduce random noise preserving peak shapes First derivative (order = 1): Remove constant baseline offsets, enhance peak differences Second derivative (order = 2): Remove linear baseline trends, enhance peak resolution","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"parameters","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"Parameters","title":"Preprocessing Techniques","text":"window_side: Number points side center point (total window = 2 * window_side + 1) differentiation_order: 0 smoothing, 1 first derivative, 2 second derivative degree: Polynomial degree (defaults differentiation_order + 1)","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"examples","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"Examples","title":"Preprocessing Techniques","text":"","code":"# Just smoothing rec_smooth <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 0)  # First derivative rec_d1 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1)  # Second derivative rec_d2 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 2) library(patchwork)  p1 <- plot_spectra(raw_data, \"Raw\") p2 <- plot_spectra(get_internal(rec_smooth), \"Smoothed (window = 15)\") p3 <- plot_spectra(get_internal(rec_d1), \"1st Derivative\", \"Baseline offset removed\") p4 <- plot_spectra(get_internal(rec_d2), \"2nd Derivative\", \"Linear baseline removed\")  (p1 + p2) / (p3 + p4)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"choosing-window-size","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"Choosing window size","title":"Preprocessing Techniques","text":"window size bias-variance trade-: - Smaller window: Less smoothing, preserves sharp features, noise - Larger window: smoothing, may blur sharp peaks, less noise good starting point window spans narrowest feature want preserve.","code":"windows <- c(3, 7, 15)  window_data <- lapply(windows, function(w) {   rec <- recipe(water ~ ., data = meats) |>     step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>     step_measure_savitzky_golay(window_side = w, differentiation_order = 1)    get_internal(rec) |>     filter(sample_id == 1) |>     mutate(window = paste0(\"window_side = \", w)) }) |>   bind_rows()  ggplot(window_data, aes(x = location, y = value, color = window)) +   geom_line() +   labs(     x = \"Wavelength\",     y = \"Signal\",     title = \"Effect of Window Size on First Derivative\",     color = NULL   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"tuning-with-dials","dir":"Articles","previous_headings":"Savitzky-Golay Filtering","what":"Tuning with dials","title":"Preprocessing Techniques","text":"Savitzky-Golay step tunable! means can use tune() find optimal parameters:","code":"library(tune) library(workflows)  rec_tunable <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(     window_side = tune(),     differentiation_order = tune()   ) |>   step_measure_output_wide()  # The tunable parameters are: tunable(rec_tunable)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"spectral-math-transformations","dir":"Articles","previous_headings":"","what":"Spectral Math Transformations","title":"Preprocessing Techniques","text":"measure package includes mathematical transformations commonly used spectroscopy chemometrics.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"absorbance-and-transmittance","dir":"Articles","previous_headings":"Spectral Math Transformations","what":"Absorbance and Transmittance","title":"Preprocessing Techniques","text":"Convert transmittance absorbance using Beer-Lambert relationship: Absorbance: =−log10(T)= -\\log_{10}(T) Transmittance: T=10−= 10^{-}  transformations inverses - round-trip preserves values:","code":"# Convert transmittance to absorbance rec_abs <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_absorbance()  plot_spectra(get_internal(rec_abs), \"Absorbance\", \"Converted from transmittance\") rec_roundtrip <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_absorbance() |>   step_measure_transmittance()  # Back to original"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"log-transformation","dir":"Articles","previous_headings":"Spectral Math Transformations","what":"Log Transformation","title":"Preprocessing Techniques","text":"Apply logarithmic transformation configurable base offset:","code":"# Natural log (base e) rec_log <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_log()  # Log base 10 with offset for handling zeros rec_log10 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_log(base = 10, offset = 1)  plot_spectra(get_internal(rec_log), \"Natural Log Transform\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"kubelka-munk-transformation","dir":"Articles","previous_headings":"Spectral Math Transformations","what":"Kubelka-Munk Transformation","title":"Preprocessing Techniques","text":"diffuse reflectance data, Kubelka-Munk transformation converts reflectance quantity proportional concentration: f(R)=(1−R)22Rf(R) = \\frac{(1-R)^2}{2R}","code":"# For reflectance data (values between 0 and 1) rec_km <- recipe(concentration ~ ., data = reflectance_data) |>   step_measure_input_wide(starts_with(\"r_\")) |>   step_measure_kubelka_munk()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"simple-finite-difference-derivatives","dir":"Articles","previous_headings":"Spectral Math Transformations","what":"Simple Finite Difference Derivatives","title":"Preprocessing Techniques","text":"quick derivatives without smoothing, use step_measure_derivative(): Note: Derivatives reduce spectrum length (first derivative: n-1 points, second derivative: n-2 points). order parameter tunable.","code":"# First derivative - removes constant baseline offsets rec_fd1 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_derivative(order = 1)  # Second derivative - removes linear baseline trends rec_fd2 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_derivative(order = 2)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"gap-norris-williams-derivatives","dir":"Articles","previous_headings":"Spectral Math Transformations","what":"Gap (Norris-Williams) Derivatives","title":"Preprocessing Techniques","text":"Gap derivatives compute differences points separated gap, commonly used NIR chemometrics:  gap segment parameters tunable dials.","code":"# Gap derivative with gap=5 rec_gap <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_derivative_gap(gap = 5)  # Norris-Williams with segment averaging for noise reduction rec_nw <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_derivative_gap(gap = 5, segment = 3)  plot_spectra(get_internal(rec_gap), \"Gap Derivative (gap=5)\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"region-operations","dir":"Articles","previous_headings":"","what":"Region Operations","title":"Preprocessing Techniques","text":"Region operations allow select, exclude, resample specific portions measurements. essential chromatographic workflows useful focusing analysis regions interest.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"trimming-to-a-range","dir":"Articles","previous_headings":"Region Operations","what":"Trimming to a range","title":"Preprocessing Techniques","text":"step_measure_trim() keeps measurements within specified x-axis range:  Common use cases: - Remove noisy regions measurement edges - Focus spectral region interest - Define integration windows chromatography","code":"# Keep only wavelengths 880-1020 rec_trim <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_trim(range = c(880, 1020))  trim_data <- get_internal(rec_trim) plot_spectra(trim_data, \"Trimmed to 880-1020 nm\",              \"Removed noisy edge regions\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"excluding-ranges","dir":"Articles","previous_headings":"Region Operations","what":"Excluding ranges","title":"Preprocessing Techniques","text":"step_measure_exclude() removes measurements within one specified ranges:  Common use cases: - Remove solvent peaks chromatography - Exclude detector saturation regions - Remove known interference regions","code":"# Exclude water absorption bands rec_exclude <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_exclude(ranges = list(c(920, 940), c(980, 1000)))  exclude_data <- get_internal(rec_exclude) plot_spectra(exclude_data, \"Excluded Regions\",              \"Removed wavelength ranges 920-940 and 980-1000\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"resampling-to-a-new-grid","dir":"Articles","previous_headings":"Region Operations","what":"Resampling to a new grid","title":"Preprocessing Techniques","text":"step_measure_resample() interpolates measurements new regular grid:  can also specify spacing points: Common use cases: - Align data different instruments different sampling rates - Reduce data density faster processing - Ensure uniform spacing methods require ","code":"# Resample to 50 evenly spaced points rec_resample <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_resample(n = 50, method = \"spline\")  resample_data <- get_internal(rec_resample) plot_spectra(resample_data, \"Resampled to 50 Points\",              \"Spline interpolation to regular grid\") # Resample with 5 nm spacing rec_resample_spacing <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_resample(spacing = 5, method = \"linear\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"combining-region-operations","dir":"Articles","previous_headings":"Region Operations","what":"Combining region operations","title":"Preprocessing Techniques","text":"Region operations often used together start preprocessing pipeline:","code":"rec_regions <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   # First trim to region of interest   step_measure_trim(range = c(860, 1040)) |>   # Then resample to regular grid   step_measure_resample(n = 50, method = \"spline\") |>   # Now apply spectral preprocessing   step_measure_savitzky_golay(window_side = 3, differentiation_order = 1) |>   step_measure_snv()  region_pipeline_data <- get_internal(rec_regions) plot_spectra(region_pipeline_data, \"Region Selection + Preprocessing\",              \"Trim → Resample → SG derivative → SNV\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"baseline-correction","dir":"Articles","previous_headings":"","what":"Baseline Correction","title":"Preprocessing Techniques","text":"Baseline correction critical removing unwanted background signals spectral data. measure package provides several algorithms suited different situations.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"rolling-ball-baseline","dir":"Articles","previous_headings":"Baseline Correction","what":"Rolling ball baseline","title":"Preprocessing Techniques","text":"rolling ball algorithm “rolls” ball specified radius spectrum estimate baseline:  Key parameters: - window_size: Diameter rolling ball (larger = smoother baseline) - smoothing: Amount smoothing applied estimated baseline","code":"rec_rolling <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_baseline_rolling(window_size = 50)  rolling_data <- get_internal(rec_rolling) plot_spectra(rolling_data, \"Rolling Ball Baseline Correction\",              \"Window size = 50\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"airpls-baseline","dir":"Articles","previous_headings":"Baseline Correction","what":"airPLS baseline","title":"Preprocessing Techniques","text":"Adaptive Iteratively Reweighted Penalized Least Squares adapts complex, varying baselines:  lambda parameter controls smoothness (larger = smoother baseline) tunable dials.","code":"rec_airpls <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_baseline_airpls(lambda = 1e5, max_iter = 20)  airpls_data <- get_internal(rec_airpls) plot_spectra(airpls_data, \"airPLS Baseline Correction\",              \"lambda = 1e5\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"snip-baseline","dir":"Articles","previous_headings":"Baseline Correction","what":"SNIP baseline","title":"Preprocessing Techniques","text":"Statistics-sensitive Non-linear Iterative Peak-clipping (SNIP) well-suited spectroscopy sharp peaks:  Key parameters: - iterations: Number clipping iterations (= aggressive baseline removal) - decreasing: Whether decrease window size iterations (recommended peaks)","code":"rec_snip <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_baseline_snip(iterations = 30)  snip_data <- get_internal(rec_snip) plot_spectra(snip_data, \"SNIP Baseline Correction\",              \"30 iterations, decreasing window\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"what-it-does-1","dir":"Articles","previous_headings":"Standard Normal Variate (SNV)","what":"What it does","title":"Preprocessing Techniques","text":"SNV normalizes spectrum independently centering scaling: SNV(x)=x−x‾sxSNV(x) = \\frac{x - \\bar{x}}{s_x} x‾\\bar{x} spectrum’s mean sxs_x standard deviation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"when-to-use-it-1","dir":"Articles","previous_headings":"Standard Normal Variate (SNV)","what":"When to use it","title":"Preprocessing Techniques","text":"Remove multiplicative scatter effects Correct path length variations Normalize spectra similar magnitude SNV particularly effective diffuse reflectance spectra particle size causes scatter variations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"example","dir":"Articles","previous_headings":"Standard Normal Variate (SNV)","what":"Example","title":"Preprocessing Techniques","text":"","code":"rec_snv <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_snv()  snv_data <- get_internal(rec_snv) plot_spectra(snv_data, \"After SNV Normalization\", \"Each spectrum has mean = 0 and sd = 1\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"combining-with-derivatives","dir":"Articles","previous_headings":"Standard Normal Variate (SNV)","what":"Combining with derivatives","title":"Preprocessing Techniques","text":"SNV often combined Savitzky-Golay derivatives. order matters:","code":"# Derivative then SNV (more common) rec_d1_snv <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv()  plot_spectra(get_internal(rec_d1_snv), \"1st Derivative + SNV\",              \"Combined baseline removal and scatter correction\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"what-it-does-2","dir":"Articles","previous_headings":"Multiplicative Scatter Correction (MSC)","what":"What it does","title":"Preprocessing Techniques","text":"MSC aligns spectrum reference spectrum (typically mean training spectra) correcting additive multiplicative effects: Fit spectrum xix_i reference xrx_r: xi=mi⋅xr+aix_i = m_i \\cdot x_r + a_i Correct: MSC(xi)=xi−aimiMSC(x_i) = \\frac{x_i - a_i}{m_i}","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"when-to-use-it-2","dir":"Articles","previous_headings":"Multiplicative Scatter Correction (MSC)","what":"When to use it","title":"Preprocessing Techniques","text":"Similar applications SNV good reference spectrum Often slightly better SNV scatter correction","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"how-it-differs-from-snv","dir":"Articles","previous_headings":"Multiplicative Scatter Correction (MSC)","what":"How it differs from SNV","title":"Preprocessing Techniques","text":"SNV: spectrum normalized independently (reference needed) MSC: spectra aligned common reference (learns reference prep) means MSC trained step - learns reference spectrum training data applies reference new data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"example-1","dir":"Articles","previous_headings":"Multiplicative Scatter Correction (MSC)","what":"Example","title":"Preprocessing Techniques","text":"","code":"rec_msc <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_msc()  msc_data <- get_internal(rec_msc) plot_spectra(msc_data, \"After MSC\", \"Spectra aligned to mean reference\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"comparing-snv-and-msc","dir":"Articles","previous_headings":"Multiplicative Scatter Correction (MSC)","what":"Comparing SNV and MSC","title":"Preprocessing Techniques","text":"methods produce similar results dataset. practice, try compare model performance.","code":"p_snv <- plot_spectra(get_internal(rec_snv), \"SNV\") p_msc <- plot_spectra(get_internal(rec_msc), \"MSC\")  p_snv / p_msc"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"extended-scatter-correction","dir":"Articles","previous_headings":"","what":"Extended Scatter Correction","title":"Preprocessing Techniques","text":"complex scatter effects, measure provides advanced scatter correction methods.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"extended-msc-emsc","dir":"Articles","previous_headings":"Extended Scatter Correction","what":"Extended MSC (EMSC)","title":"Preprocessing Techniques","text":"EMSC extends standard MSC modeling wavelength-dependent scatter effects using polynomial terms:  degree parameter controls polynomial order wavelength terms (0 = standard MSC, higher = flexibility). parameter tunable.","code":"rec_emsc <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_emsc(degree = 2)  emsc_data <- get_internal(rec_emsc) plot_spectra(emsc_data, \"After EMSC (degree=2)\", \"Wavelength-dependent scatter correction\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"orthogonal-signal-correction-osc","dir":"Articles","previous_headings":"Extended Scatter Correction","what":"Orthogonal Signal Correction (OSC)","title":"Preprocessing Techniques","text":"OSC removes variation spectra orthogonal (uncorrelated) response variable. supervised technique requires outcome variables:  OSC automatically detects outcome variables recipe formula. n_components parameter controls many orthogonal components remove tunable. use EMSC vs OSC: - EMSC: Physical scatter effects vary wavelength - OSC: Systematic variation unrelated response (supervised)","code":"rec_osc <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_osc(n_components = 2)  osc_data <- get_internal(rec_osc) plot_spectra(osc_data, \"After OSC\", \"Removed 2 orthogonal components\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"feature-engineering","dir":"Articles","previous_headings":"","what":"Feature Engineering","title":"Preprocessing Techniques","text":"Feature engineering steps extract scalar features spectral data, creating new predictor columns useful modeling.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"region-integration","dir":"Articles","previous_headings":"Feature Engineering","what":"Region Integration","title":"Preprocessing Techniques","text":"step_measure_integrals() calculates integrated areas specified regions, useful quantifying peak areas:","code":"rec_integrals <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_integrals(     regions = list(       region_a = c(870, 920),       region_b = c(950, 1000)     ),     method = \"trapezoid\"   )  # View extracted features bake(prep(rec_integrals), new_data = NULL) |>   select(starts_with(\"integral_\")) |>   head() #> # A tibble: 6 × 2 #>   integral_region_a integral_region_b #>               <dbl>             <dbl> #> 1              131.              161. #> 2              146.              170. #> 3              129.              152. #> 4              140.              167. #> 5              141.              177. #> 6              155.              183."},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"region-ratios","dir":"Articles","previous_headings":"Feature Engineering","what":"Region Ratios","title":"Preprocessing Techniques","text":"step_measure_ratios() calculates ratios integrated regions, often used internal calibration:","code":"rec_ratios <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_ratios(     numerator = c(870, 920),     denominator = c(950, 1000),     name = \"peak_ratio\"   )  bake(prep(rec_ratios), new_data = NULL) |>   select(peak_ratio) |>   head() #> # A tibble: 6 × 1 #>   peak_ratio #>        <dbl> #> 1      0.810 #> 2      0.855 #> 3      0.849 #> 4      0.841 #> 5      0.795 #> 6      0.851"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"statistical-moments","dir":"Articles","previous_headings":"Feature Engineering","what":"Statistical Moments","title":"Preprocessing Techniques","text":"step_measure_moments() extracts statistical moments spectra:","code":"rec_moments <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_moments(moments = c(\"mean\", \"sd\", \"skewness\", \"kurtosis\"))  bake(prep(rec_moments), new_data = NULL) |>   select(starts_with(\"moment_\")) |>   head() #> # A tibble: 6 × 4 #>   moment_mean moment_sd moment_skewness moment_kurtosis #>         <dbl>     <dbl>           <dbl>           <dbl> #> 1        2.97     0.270           0.222           -1.38 #> 2        3.24     0.234          -0.311           -1.19 #> 3        2.82     0.206           0.536           -1.15 #> 4        3.09     0.238           0.540           -1.19 #> 5        3.25     0.326           0.102           -1.37 #> 6        3.48     0.262          -0.387           -1.17"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"spectral-binning","dir":"Articles","previous_headings":"Feature Engineering","what":"Spectral Binning","title":"Preprocessing Techniques","text":"step_measure_bin() reduces spectral resolution averaging summing bins. can reduce noise dimensionality:  bin_width parameter tunable:","code":"rec_bin <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_bin(n_bins = 20, method = \"mean\")  bin_data <- get_internal(rec_bin) plot_spectra(bin_data, \"Binned to 20 Points\", \"Reduced dimensionality\") rec_tunable_bin <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_bin(bin_width = tune()) |>   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"sample-wise-normalization","dir":"Articles","previous_headings":"","what":"Sample-wise Normalization","title":"Preprocessing Techniques","text":"measure package provides several sample-wise normalization methods normalize spectrum independently. Unlike SNV/MSC address scatter, methods adjust differences total signal intensity.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"sum-normalization","dir":"Articles","previous_headings":"Sample-wise Normalization","what":"Sum normalization","title":"Preprocessing Techniques","text":"Divides spectrum total intensity. transformation, spectra sum 1:","code":"rec_norm_sum <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_normalize_sum()  plot_spectra(get_internal(rec_norm_sum), \"Sum Normalized\",              \"Each spectrum sums to 1\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"max-normalization","dir":"Articles","previous_headings":"Sample-wise Normalization","what":"Max normalization","title":"Preprocessing Techniques","text":"Divides spectrum maximum value, useful peak-focused analysis:","code":"rec_norm_max <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_normalize_max()  plot_spectra(get_internal(rec_norm_max), \"Max Normalized\",              \"Each spectrum has maximum = 1\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"peak-region-normalization-tunable","dir":"Articles","previous_headings":"Sample-wise Normalization","what":"Peak region normalization (tunable)","title":"Preprocessing Techniques","text":"internal standard known location, use step_measure_normalize_peak() normalize specific region:  location_min location_max parameters tunable:","code":"rec_norm_peak <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_normalize_peak(     location_min = 900,     location_max = 950,     method = \"mean\"  # or \"max\" or \"integral\"   )  plot_spectra(get_internal(rec_norm_peak), \"Peak Region Normalized\",              \"Normalized by mean of region 900-950\") rec_tunable_peak <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_normalize_peak(     location_min = tune(),     location_max = tune(),     method = \"mean\"   ) |>   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"variable-wise-scaling","dir":"Articles","previous_headings":"","what":"Variable-wise Scaling","title":"Preprocessing Techniques","text":"sample-wise methods normalize spectrum independently, variable-wise scaling operates across samples measurement location. methods learn statistics training data apply consistently new data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"when-to-use-variable-wise-scaling","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"When to use variable-wise scaling","title":"Preprocessing Techniques","text":"PCA/PLS: Centering essential; scaling equalizes variable importance variables different scales: Auto-scaling gives equal weight locations metabolomics data: Pareto scaling common practice","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"mean-centering","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"Mean centering","title":"Preprocessing Techniques","text":"step_measure_center() subtracts column mean location:","code":"rec_center <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_center()  center_data <- get_internal(rec_center) plot_spectra(center_data, \"Mean Centered\",              \"Column means are zero\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"auto-scaling-z-score","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"Auto-scaling (z-score)","title":"Preprocessing Techniques","text":"step_measure_scale_auto() centers scales unit variance location:","code":"rec_auto <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_scale_auto()  auto_data <- get_internal(rec_auto) plot_spectra(auto_data, \"Auto-Scaled (Z-Score)\",              \"Column means = 0, SDs = 1\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"pareto-scaling","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"Pareto scaling","title":"Preprocessing Techniques","text":"step_measure_scale_pareto() divides square root standard deviation - compromise scaling auto-scaling:","code":"rec_pareto <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |>   step_measure_scale_pareto()  pareto_data <- get_internal(rec_pareto) plot_spectra(pareto_data, \"Pareto Scaled\",              \"Reduces influence of large values while preserving fold changes\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"comparing-scaling-methods","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"Comparing scaling methods","title":"Preprocessing Techniques","text":"","code":"p_raw <- plot_spectra(raw_data, \"Raw\") p_center <- plot_spectra(center_data, \"Centered\") p_auto <- plot_spectra(auto_data, \"Auto-Scaled\") p_pareto <- plot_spectra(pareto_data, \"Pareto Scaled\")  (p_raw + p_center) / (p_auto + p_pareto)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"learned-parameters","dir":"Articles","previous_headings":"Variable-wise Scaling","what":"Learned parameters","title":"Preprocessing Techniques","text":"Variable-wise scaling steps store learned parameters can examined training:","code":"rec_prepped <- prep(rec_auto)  # View learned parameters tidy_params <- tidy(rec_prepped, number = 2) head(tidy_params) #> # A tibble: 6 × 5 #>   terms     location  mean    sd id                       #>   <chr>        <dbl> <dbl> <dbl> <chr>                    #> 1 .measures     850   2.81 0.411 measure_scale_auto_uVs7T #> 2 .measures     852.  2.81 0.413 measure_scale_auto_uVs7T #> 3 .measures     854.  2.81 0.416 measure_scale_auto_uVs7T #> 4 .measures     856.  2.82 0.418 measure_scale_auto_uVs7T #> 5 .measures     858.  2.82 0.421 measure_scale_auto_uVs7T #> 6 .measures     860.  2.82 0.424 measure_scale_auto_uVs7T  # Plot the learned means and SDs ggplot(tidy_params, aes(x = location)) +   geom_line(aes(y = mean), color = \"blue\") +   geom_ribbon(aes(ymin = mean - sd, ymax = mean + sd), alpha = 0.3, fill = \"blue\") +   labs(x = \"Wavelength\", y = \"Value\",        title = \"Learned Parameters from Auto-Scaling\",        subtitle = \"Mean ± 1 SD at each wavelength\") +   theme_minimal()"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"when-built-in-steps-arent-enough","dir":"Articles","previous_headings":"Custom Transformations","what":"When built-in steps aren’t enough","title":"Preprocessing Techniques","text":"built-preprocessing steps cover common operations, may need domain-specific transformations: Custom baseline correction algorithms Instrument-specific corrections Experimental preprocessing techniques Transformations specialized packages step_measure_map() provides “escape hatch” applying custom function measurements staying within recipes framework.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"using-step_measure_map","dir":"Articles","previous_headings":"Custom Transformations","what":"Using step_measure_map()","title":"Preprocessing Techniques","text":"function provide must accept tibble location value columns return tibble structure:","code":"# Example: Shift spectra to start at zero zero_baseline <- function(x) {  x$value <- x$value - min(x$value) x }  rec_custom <- recipe(water ~ ., data = meats) |> step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |> step_measure_map(zero_baseline) |> step_measure_snv()  plot_spectra(get_internal(rec_custom), \"Custom Zero-Baseline + SNV\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"formula-syntax-for-inline-transformations","dir":"Articles","previous_headings":"Custom Transformations","what":"Formula syntax for inline transformations","title":"Preprocessing Techniques","text":"simple transformations, use formula syntax instead defining separate function:","code":"rec_inline <- recipe(water ~ ., data = meats) |> step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |> step_measure_map(~ { # Log transform (common for absorbance data) .x$value <- log1p(.x$value) .x })"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"passing-additional-arguments","dir":"Articles","previous_headings":"Custom Transformations","what":"Passing additional arguments","title":"Preprocessing Techniques","text":"can pass extra arguments transformation function:","code":"# A function with configurable parameters robust_scale <- function(x, center_fn = median, scale_fn = mad) { x$value <- (x$value - center_fn(x$value)) / scale_fn(x$value) x }  # Use with custom parameters rec <- recipe(water ~ ., data = meats) |> step_measure_input_wide(starts_with(\"x_\")) |> step_measure_map(robust_scale, center_fn = mean, scale_fn = sd)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"prototyping-with-measure_map","dir":"Articles","previous_headings":"Custom Transformations","what":"Prototyping with measure_map()","title":"Preprocessing Techniques","text":"developing custom transformation, helps prototype interactively putting recipe. Use measure_map() exploration: transformation works correctly, move step_measure_map() production use. ensures transformation : Applied consistently prep() bake() Included bundling recipes workflows Reproducible across sessions","code":"# First, get data in internal format rec_internal <- recipe(water ~ ., data = meats) |> step_measure_input_wide(starts_with(\"x_\"), location_values = wavelengths) |> prep()  baked_data <- bake(rec_internal, new_data = NULL)  # Prototype your transformation result <- measure_map(baked_data, ~ { # Experiment with different approaches .x$value <- .x$value - median(.x$value) .x })  # Check results result$.measures[[1]] #> <measure_tbl [100 x 2]> #> # A tibble: 100 × 2 #>    location  value #>       <dbl>  <dbl> #>  1     850  -0.317 #>  2     852. -0.316 #>  3     854. -0.316 #>  4     856. -0.315 #>  5     858. -0.314 #>  6     860. -0.314 #>  7     862. -0.312 #>  8     864. -0.311 #>  9     866. -0.309 #> 10     868. -0.307 #> # ℹ 90 more rows"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"handling-problematic-samples","dir":"Articles","previous_headings":"Custom Transformations","what":"Handling problematic samples","title":"Preprocessing Techniques","text":"Use measure_map_safely() exploring data might problematic samples:","code":"# A transformation that might fail for some samples risky_transform <- function(x) { if (any(x$value <= 0)) stop(\"Non-positive values!\") x$value <- log(x$value) x }  # Errors are captured, not thrown result <- measure_map_safely(baked_data, risky_transform)  # Check which samples failed if (nrow(result$errors) > 0) { print(result$errors) }  # result$result contains the data with successful transforms # (failed samples keep their original values)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"understanding-your-data-with-measure_summarize","dir":"Articles","previous_headings":"Custom Transformations","what":"Understanding your data with measure_summarize()","title":"Preprocessing Techniques","text":"preprocessing, ’s often helpful compute summary statistics across samples:  can help identify: - Wavelength regions high variability - Potential outliers - Reference spectra custom corrections","code":"# Compute mean and SD at each wavelength summary_stats <- measure_summarize(baked_data) summary_stats #> # A tibble: 100 × 3 #>    location  mean    sd #>       <dbl> <dbl> <dbl> #>  1     850   2.81 0.411 #>  2     852.  2.81 0.413 #>  3     854.  2.81 0.416 #>  4     856.  2.82 0.418 #>  5     858.  2.82 0.421 #>  6     860.  2.82 0.424 #>  7     862.  2.83 0.426 #>  8     864.  2.83 0.429 #>  9     866.  2.83 0.432 #> 10     868.  2.84 0.434 #> # ℹ 90 more rows  # Visualize the mean spectrum with variability ggplot(summary_stats, aes(x = location)) + geom_ribbon(aes(ymin = mean - sd, ymax = mean + sd), alpha = 0.3) + geom_line(aes(y = mean)) + labs(x = \"Wavelength\", y = \"Signal\", title = \"Mean Spectrum ± 1 SD\") + theme_minimal()"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"common-combinations","dir":"Articles","previous_headings":"Preprocessing pipelines","what":"Common combinations","title":"Preprocessing Techniques","text":"commonly used preprocessing pipelines:","code":"# Pipeline 1: Basic scatter correction pipe1 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_snv() |>   step_measure_output_wide()  # Pipeline 2: Derivative + normalization pipe2 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv() |>   step_measure_output_wide()  # Pipeline 3: Second derivative (often enough on its own) pipe3 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 2) |>   step_measure_output_wide()  # Pipeline 4: MSC + smoothing pipe4 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_msc() |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 0) |>   step_measure_output_wide()  # Pipeline 5: For PCA/PLS - SNV + centering pipe5 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_snv() |>   step_measure_center() |>   step_measure_output_wide()  # Pipeline 6: Metabolomics-style with Pareto scaling pipe6 <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_normalize_sum() |>   step_measure_scale_pareto() |>   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"order-of-operations","dir":"Articles","previous_headings":"Preprocessing pipelines","what":"Order of operations","title":"Preprocessing Techniques","text":"order preprocessing steps matters. General guidelines: Derivatives first: Apply Savitzky-Golay derivatives transformations Sample-wise normalization variable-wise scaling: Normalize spectra (SNV, MSC, normalize_*) centering/scaling Center/scale last: Variable-wise scaling typically final step modeling Keep simple: Often, single well-chosen step outperforms complex pipelines typical order might :","code":"Derivatives → Sample normalization (SNV/MSC) → Variable scaling (center/auto-scale)"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"data-augmentation","dir":"Articles","previous_headings":"","what":"Data Augmentation","title":"Preprocessing Techniques","text":"Data augmentation steps add controlled variations training data, helping models generalize better. steps default skip = TRUE, meaning apply training (via prep()) skipped applying recipe new data (via bake() new_data).","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"adding-random-noise","dir":"Articles","previous_headings":"Data Augmentation","what":"Adding Random Noise","title":"Preprocessing Techniques","text":"step_measure_augment_noise() adds random noise simulate measurement uncertainty:","code":"rec_noise <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_augment_noise(     sd = 0.01,              # Noise level (relative to signal range)     distribution = \"gaussian\",     relative = TRUE         # TRUE = sd is relative to signal range   ) |>   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"random-x-axis-shifts","dir":"Articles","previous_headings":"Data Augmentation","what":"Random X-axis Shifts","title":"Preprocessing Techniques","text":"step_measure_augment_shift() applies small random shifts along x-axis, helping models become shift-invariant:","code":"rec_shift <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_augment_shift(max_shift = 2) |>  # Max shift in location units   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"random-intensity-scaling","dir":"Articles","previous_headings":"Data Augmentation","what":"Random Intensity Scaling","title":"Preprocessing Techniques","text":"step_measure_augment_scale() applies random scaling factors intensities:","code":"rec_scale <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_augment_scale(range = c(0.9, 1.1)) |>  # Scale between 90-110%   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"combining-augmentations","dir":"Articles","previous_headings":"Data Augmentation","what":"Combining Augmentations","title":"Preprocessing Techniques","text":"Multiple augmentation steps can combined. Augmentations reproducible - applying recipe data produces identical results: use augmentation: - Training deep learning models - Small training sets variation helps - Building shift/scale-invariant models","code":"rec_augment <- recipe(water ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_augment_noise(sd = 0.005) |>   step_measure_augment_shift(max_shift = 1) |>   step_measure_augment_scale(range = c(0.95, 1.05)) |>   step_measure_snv() |>   step_measure_output_wide()  # Augmentation only applies during training prepped <- prep(rec_augment) training_data <- bake(prepped, new_data = NULL)  # Augmented new_data <- bake(prepped, new_data = meats[1:5, ])  # Not augmented"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"tips-for-choosing-preprocessing","dir":"Articles","previous_headings":"","what":"Tips for choosing preprocessing","title":"Preprocessing Techniques","text":"Start simple: Try SNV first derivative alone complex pipelines Visualize: Always plot preprocessed spectra check artifacts Validate: Use cross-validation compare preprocessing strategies Domain knowledge: Consider physics measurement system Tune: Use tune() optimize Savitzky-Golay parameters","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/preprocessing.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Preprocessing Techniques","text":"Savitzky, ., Golay, M. J. E. (1964). Smoothing Differentiation Data Simplified Least Squares Procedures. Analytical Chemistry, 36(8), 1627-1639. Barnes, R. J., Dhanoa, M. S., Lister, S. J. (1989). Standard Normal Variate Transformation De-Trending Near-Infrared Diffuse Reflectance Spectra. Applied Spectroscopy, 43(5), 772-777. Geladi, P., MacDougall, D., Martens, H. (1985). Linearization Scatter-Correction Near-Infrared Reflectance Spectra Meat. Applied Spectroscopy, 39(3), 491-500.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Integrating with tidymodels","text":"One measure’s key design goals seamless integration tidymodels ecosystem. vignette shows use measure preprocessing within complete modeling workflows, including: Bundling preprocessing models using workflows Cross-validation measure recipes Hyperparameter tuning preprocessing steps Comparing preprocessing strategies","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"setup-the-meats-dataset","dir":"Articles","previous_headings":"","what":"Setup: The meats dataset","title":"Integrating with tidymodels","text":"’ll use NIR spectroscopy dataset modeldata predict water content meat samples. ’ll focus just predicting water keep example simple.","code":"data(meats)  # Keep only water as outcome and spectral columns meats_water <- meats |>   select(water, starts_with(\"x_\"))  # Create train/test split split <- initial_split(meats_water, prop = 0.75) train <- training(split) test <- testing(split)  cat(\"Training samples:\", nrow(train), \"\\n\") #> Training samples: 161 cat(\"Test samples:\", nrow(test), \"\\n\") #> Test samples: 54"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"basic-workflow","dir":"Articles","previous_headings":"","what":"Basic workflow","title":"Integrating with tidymodels","text":"simplest way use measure tidymodels workflow bundles preprocessing modeling:","code":"# Define preprocessing recipe rec <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv() |>   step_measure_output_wide()  # Define model - simple linear regression # (For real applications, use regularization like glmnet or PLS) lm_spec <- linear_reg() |>   set_engine(\"lm\")  # Create workflow wf <- workflow() |>   add_recipe(rec) |>   add_model(lm_spec)  wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_measure_input_wide() #> • step_measure_savitzky_golay() #> • step_measure_snv() #> • step_measure_output_wide() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Linear Regression Model Specification (regression) #>  #> Computational engine: lm"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"fit-and-evaluate","dir":"Articles","previous_headings":"Basic workflow","what":"Fit and evaluate","title":"Integrating with tidymodels","text":"","code":"# Fit the workflow wf_fit <- fit(wf, data = train)  # Predict on test data predictions <- predict(wf_fit, test) |>   bind_cols(test |> select(water))  # Evaluate metrics(predictions, truth = water, estimate = .pred)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-validation","title":"Integrating with tidymodels","text":"Cross-validation straightforward workflows:","code":"# Create folds folds <- vfold_cv(train, v = 5)  # Fit resamples cv_results <- fit_resamples(wf, resamples = folds)  # Collect metrics collect_metrics(cv_results)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"tuning-preprocessing-parameters","dir":"Articles","previous_headings":"","what":"Tuning preprocessing parameters","title":"Integrating with tidymodels","text":"Several measure steps tunable parameters: step_measure_savitzky_golay(): window_side, differentiation_order, degree step_measure_normalize_peak(): location_min, location_max Baseline correction steps: lambda, p, degree, etc. Let’s find optimal Savitzky-Golay parameters:","code":"# Create a tunable recipe rec_tune <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(     window_side = tune(),     differentiation_order = tune()   ) |>   step_measure_snv() |>   step_measure_output_wide()  # Create tunable workflow wf_tune <- workflow() |>   add_recipe(rec_tune) |>   add_model(lm_spec)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"define-the-parameter-grid","dir":"Articles","previous_headings":"Tuning preprocessing parameters","what":"Define the parameter grid","title":"Integrating with tidymodels","text":"","code":"# Create a grid grid <- grid_regular(   window_side(range = c(3L, 11L)),   differentiation_order(range = c(0L, 2L)),   levels = c(5, 3) )  grid"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"run-the-tuning","dir":"Articles","previous_headings":"Tuning preprocessing parameters","what":"Run the tuning","title":"Integrating with tidymodels","text":"","code":"tune_results <- tune_grid(   wf_tune,   resamples = folds,   grid = grid )  # Show best results show_best(tune_results, metric = \"rmse\", n = 5)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"visualize-tuning-results","dir":"Articles","previous_headings":"Tuning preprocessing parameters","what":"Visualize tuning results","title":"Integrating with tidymodels","text":"","code":"autoplot(tune_results)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"finalize-the-workflow","dir":"Articles","previous_headings":"Tuning preprocessing parameters","what":"Finalize the workflow","title":"Integrating with tidymodels","text":"","code":"# Select best parameters best_params <- select_best(tune_results, metric = \"rmse\") best_params  # Finalize workflow final_wf <- finalize_workflow(wf_tune, best_params)  # Fit on full training data and evaluate on test final_fit <- last_fit(final_wf, split)  collect_metrics(final_fit)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"comparing-preprocessing-strategies","dir":"Articles","previous_headings":"","what":"Comparing preprocessing strategies","title":"Integrating with tidymodels","text":"common workflow comparing different preprocessing approaches. ’s set fair comparison:","code":"# Strategy 1: SNV only rec_snv <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_snv() |>   step_measure_output_wide()  # Strategy 2: First derivative + SNV rec_d1_snv <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 1) |>   step_measure_snv() |>   step_measure_output_wide()  # Strategy 3: MSC rec_msc <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_msc() |>   step_measure_output_wide()  # Strategy 4: Second derivative only rec_d2 <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_savitzky_golay(window_side = 7, differentiation_order = 2) |>   step_measure_output_wide()  # Strategy 5: SNV + centering (good for PLS) rec_snv_center <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_snv() |>   step_measure_center() |>   step_measure_output_wide()  # Strategy 6: Sum normalization + auto-scaling rec_norm_scale <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_normalize_sum() |>   step_measure_scale_auto() |>   step_measure_output_wide()  # Create workflow set wf_set <- workflow_set(   preproc = list(     snv = rec_snv,     d1_snv = rec_d1_snv,     msc = rec_msc,     d2 = rec_d2,     snv_center = rec_snv_center,     norm_scale = rec_norm_scale   ),   models = list(lm = lm_spec) )  wf_set"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"evaluate-all-strategies","dir":"Articles","previous_headings":"Comparing preprocessing strategies","what":"Evaluate all strategies","title":"Integrating with tidymodels","text":"","code":"# Fit all workflows with cross-validation comparison <- workflow_map(   wf_set,   fn = \"fit_resamples\",   resamples = folds )  # Rank by performance rank_results(comparison, rank_metric = \"rmse\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"visualize-comparison","dir":"Articles","previous_headings":"Comparing preprocessing strategies","what":"Visualize comparison","title":"Integrating with tidymodels","text":"","code":"autoplot(comparison) +   labs(title = \"Preprocessing Strategy Comparison\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"working-with-workflows-and-new-data","dir":"Articles","previous_headings":"","what":"Working with workflows and new data","title":"Integrating with tidymodels","text":"’ve selected final workflow, ’s use predictions new data:","code":"# Use the finalized workflow from tuning final_trained <- fit(final_wf, train)  # Predict on new data new_predictions <- predict(final_trained, test)  # Or use augment for predictions with original data augment(final_trained, test) |>   select(water, .pred) |>   head()"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"high-dimensional-data","dir":"Articles","previous_headings":"Tips for spectral modeling","what":"High-dimensional data","title":"Integrating with tidymodels","text":"Spectral data typically high-dimensional (many features, fewer samples). Consider: Regularization: Use ridge elastic net regression (linear_reg(penalty = tune(), mixture = tune())) PLS regression: Use pls() parsnip mixOmics engine Feature selection: Consider variable importance initial modeling","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"preprocessing-for-pcapls","dir":"Articles","previous_headings":"Tips for spectral modeling","what":"Preprocessing for PCA/PLS","title":"Integrating with tidymodels","text":"multivariate methods like PCA PLS, centering essential: Use step_measure_scale_auto() want give equal weight wavelengths, step_measure_scale_pareto() compromise preserves magnitude information.","code":"rec_for_pls <- recipe(water ~ ., data = train) |>   step_measure_input_wide(starts_with(\"x_\")) |>   step_measure_snv() |>   step_measure_center() |>  # Essential for PCA/PLS   step_measure_output_wide()"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"memory-considerations","dir":"Articles","previous_headings":"Tips for spectral modeling","what":"Memory considerations","title":"Integrating with tidymodels","text":"large spectral datasets: internal .measures format memory-efficient Consider processing batches memory limited Use step_measure_output_wide() needed modeling","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"reproducibility","dir":"Articles","previous_headings":"Tips for spectral modeling","what":"Reproducibility","title":"Integrating with tidymodels","text":"Always set seed cross-validation tuning:","code":"set.seed(123) folds <- vfold_cv(train, v = 10)"},{"path":"https://jameshwade.github.io/measure/dev/articles/recipes.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Integrating with tidymodels","text":"measure integrates naturally tidymodels: Use workflow() bundle preprocessing modeling Cross-validate fit_resamples() vfold_cv() Tune preprocessing parameters (Savitzky-Golay, peak normalization, baseline) tune_grid() Compare strategies workflow_set() Variable-wise scaling steps (step_measure_center(), step_measure_scale_*()) learn training data apply consistently new data recipes paradigm means preprocessing applied consistently training data, cross-validation folds, new predictions - eliminating common source data leakage chemometric modeling.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Data Organization and Diagnostic Plots","text":"working analytical data, proper organization visualization essential building effective preprocessing pipelines. measure package provides tools : Detect column types automatically based naming conventions Assign roles columns use recipes Validate recipes running Visualize spectra preprocessing effects vignette covers data organization diagnostic capabilities.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"detecting-column-types","dir":"Articles","previous_headings":"","what":"Detecting Column Types","title":"Data Organization and Diagnostic Plots","text":"Analytical data often follows naming conventions indicate column represents. measure_identify_columns() function automatically detects patterns:","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"example-identifying-columns-in-wide-format-data","dir":"Articles","previous_headings":"Detecting Column Types","what":"Example: Identifying columns in wide-format data","title":"Data Organization and Diagnostic Plots","text":"function returns tibble : - column: Column name - type: Detected type (“” pattern matched) - suggested_role: Recommended recipe role - n_values: Count non-NA values - class: R class column","code":"# Create example wide-format spectral data spec_data <- data.frame(  sample_id = paste0(\"S\", 1:5),   concentration = c(10.2, 25.1, 50.3, 75.0, 100.5),   batch = c(\"A\", \"A\", \"B\", \"B\", \"B\"),   wn_1000 = rnorm(5),   wn_1001 = rnorm(5),   wn_1002 = rnorm(5),   wn_1003 = rnorm(5),   wn_1004 = rnorm(5) )  # Identify column types col_info <- measure_identify_columns(spec_data) col_info #> # A tibble: 8 × 5 #>   column        type       suggested_role n_values class     #>   <chr>         <chr>      <chr>             <int> <chr>     #> 1 sample_id     other      id                    5 character #> 2 concentration other      outcome               5 numeric   #> 3 batch         other      predictor             5 character #> 4 wn_1000       wavenumber predictor             5 numeric   #> 5 wn_1001       wavenumber predictor             5 numeric   #> 6 wn_1002       wavenumber predictor             5 numeric   #> 7 wn_1003       wavenumber predictor             5 numeric   #> 8 wn_1004       wavenumber predictor             5 numeric"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"summarizing-by-type","dir":"Articles","previous_headings":"Detecting Column Types","what":"Summarizing by type","title":"Data Organization and Diagnostic Plots","text":"quick overview, use measure_column_summary():","code":"measure_column_summary(spec_data) #> # A tibble: 2 × 3 #>   type       n_columns example_cols                    #>   <chr>          <int> <chr>                           #> 1 wavenumber         5 wn_1000, wn_1001, wn_1002       #> 2 other              3 sample_id, concentration, batch"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"assigning-roles-in-recipes","dir":"Articles","previous_headings":"","what":"Assigning Roles in Recipes","title":"Data Organization and Diagnostic Plots","text":"Recipes use roles determine columns treated. Common roles include:","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"using-set_measure_roles","dir":"Articles","previous_headings":"Assigning Roles in Recipes","what":"Using set_measure_roles()","title":"Data Organization and Diagnostic Plots","text":"set_measure_roles() function provides convenient way assign multiple roles : equivalent calling update_role() multiple times, concise common analytical data patterns.","code":"rec <- recipe(concentration ~ ., data = spec_data) |>   set_measure_roles(     id_cols = sample_id,     metadata_cols = batch   )  # Check the assigned roles rec$var_info #> # A tibble: 8 × 4 #>   variable      type      role      source   #>   <chr>         <list>    <chr>     <chr>    #> 1 sample_id     <chr [3]> id        original #> 2 batch         <chr [3]> metadata  original #> 3 wn_1000       <chr [2]> predictor original #> 4 wn_1001       <chr [2]> predictor original #> 5 wn_1002       <chr [2]> predictor original #> 6 wn_1003       <chr [2]> predictor original #> 7 wn_1004       <chr [2]> predictor original #> 8 concentration <chr [2]> outcome   original"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"custom-roles-for-analytical-workflows","dir":"Articles","previous_headings":"Assigning Roles in Recipes","what":"Custom roles for analytical workflows","title":"Data Organization and Diagnostic Plots","text":"analytical chemistry workflows, might want identify special sample types:","code":"# Example with QC and blank samples analytical_data <- data.frame(   sample_id = c(\"blank_1\", \"QC_1\", \"S1\", \"S2\", \"QC_2\", \"S3\"),   sample_type = c(\"blank\", \"qc\", \"sample\", \"sample\", \"qc\", \"sample\"),   concentration = c(NA, 50, 10, 25, 50, 75),   wn_1000 = rnorm(6),   wn_1001 = rnorm(6) )  rec <- recipe(concentration ~ ., data = analytical_data) |>   set_measure_roles(     id_cols = sample_id,     blank_cols = starts_with(\"blank\"),     qc_cols = starts_with(\"QC\")   )"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"validating-recipe-structure","dir":"Articles","previous_headings":"","what":"Validating Recipe Structure","title":"Data Organization and Diagnostic Plots","text":"running preprocessing pipeline, check_measure_recipe() validates recipe structure identifies potential issues:","code":"# A well-structured recipe data(meats_long)  good_rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_snv() |>   step_measure_output_wide()  issues <- check_measure_recipe(good_rec) issues #> # A tibble: 0 × 3 #> # ℹ 3 variables: level <chr>, check <chr>, message <chr>"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"detecting-common-issues","dir":"Articles","previous_headings":"Validating Recipe Structure","what":"Detecting common issues","title":"Data Organization and Diagnostic Plots","text":"function checks : Errors (cause failures): - input step - Multiple input steps - Output step input step Warnings (may cause issues): - output step - Processing steps output step Info (suggestions): - ID column - Large number predictors","code":"# A recipe with issues bad_rec <- recipe(water ~ ., data = meats_long) |>   step_measure_snv()  # Missing input step!  issues <- check_measure_recipe(bad_rec) issues #> # A tibble: 3 × 3 #>   level   check     message                                                      #>   <chr>   <chr>     <chr>                                                        #> 1 error   no_input  Recipe has no input step. Add step_measure_input_wide() or … #> 2 warning no_output Recipe has no output step. Data will remain in internal .me… #> 3 info    no_id     No ID column identified. Consider using update_role(col, ne…"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"interactive-mode","dir":"Articles","previous_headings":"Validating Recipe Structure","what":"Interactive mode","title":"Data Organization and Diagnostic Plots","text":"Use strict = FALSE interactive feedback:","code":"check_measure_recipe(bad_rec, strict = FALSE) # ✖ Recipe has no input step. Add step_measure_input_wide() or step_measure_input_long()."},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"visualizing-spectra","dir":"Articles","previous_headings":"","what":"Visualizing Spectra","title":"Data Organization and Diagnostic Plots","text":"measure package provides autoplot() methods quick visualization spectral data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"plotting-a-single-spectrum","dir":"Articles","previous_headings":"Visualizing Spectra","what":"Plotting a single spectrum","title":"Data Organization and Diagnostic Plots","text":"","code":"# Create a single spectrum spec <- new_measure_tbl(   location = seq(1000, 1100, by = 1),   value = sin(seq(1000, 1100, by = 1) / 20) + rnorm(101, sd = 0.1) )  autoplot(spec)"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"plotting-multiple-spectra","dir":"Articles","previous_headings":"Visualizing Spectra","what":"Plotting multiple spectra","title":"Data Organization and Diagnostic Plots","text":"","code":"# Process some data to get a measure_list rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep(retain = TRUE)  baked <- bake(rec, new_data = NULL)  # Plot the spectra autoplot(baked$.measures, max_spectra = 20)"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"adding-summary-statistics","dir":"Articles","previous_headings":"Visualizing Spectra","what":"Adding summary statistics","title":"Data Organization and Diagnostic Plots","text":"Use summary = TRUE overlay mean ± standard deviation:","code":"autoplot(baked$.measures, summary = TRUE, max_spectra = 30, alpha = 0.2)"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"beforeafter-comparison","dir":"Articles","previous_headings":"Visualizing Preprocessing Effects","what":"Before/after comparison","title":"Data Organization and Diagnostic Plots","text":"autoplot() method recipes shows preprocessing effects:","code":"# Create a preprocessing recipe rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv() |>   prep(retain = TRUE)  autoplot(rec, n_samples = 10) #> Warning: Could not extract 'before' data for comparison. #> ℹ Showing processed data only. #> ✖ ℹ In argument: `dplyr::all_of(rename_map)`. Caused by error in #>   `dplyr::all_of()`: ! Can't subset elements that don't exist. ✖ Elements #>   `transmittance` and `channel` don't exist."},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"summary-statistics-view","dir":"Articles","previous_headings":"Visualizing Preprocessing Effects","what":"Summary statistics view","title":"Data Organization and Diagnostic Plots","text":"","code":"autoplot(rec, which = \"summary\", n_samples = 50)"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"comparing-preprocessing-strategies","dir":"Articles","previous_headings":"","what":"Comparing Preprocessing Strategies","title":"Data Organization and Diagnostic Plots","text":"Use plot_measure_comparison() compare different preprocessing approaches side--side:","code":"# Define different preprocessing strategies base_rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel))  # Strategy 1: Just SNV snv_rec <- base_rec |>   step_measure_snv() |>   prep(retain = TRUE)  # Strategy 2: Savitzky-Golay + SNV sg_snv_rec <- base_rec |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv() |>   prep(retain = TRUE)  # Strategy 3: MSC msc_rec <- base_rec |>   step_measure_msc() |>   prep(retain = TRUE)  # Compare all three plot_measure_comparison(   \"SNV\" = snv_rec,   \"SG + SNV\" = sg_snv_rec,   \"MSC\" = msc_rec,   n_samples = 15 )"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"summary-comparison","dir":"Articles","previous_headings":"Comparing Preprocessing Strategies","what":"Summary comparison","title":"Data Organization and Diagnostic Plots","text":"cleaner comparison, use summary_only = TRUE:","code":"plot_measure_comparison(   \"SNV\" = snv_rec,   \"SG + SNV\" = sg_snv_rec,   \"MSC\" = msc_rec,   n_samples = 50,   summary_only = TRUE )"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"summary-plot-for-processed-data","dir":"Articles","previous_headings":"","what":"Summary Plot for Processed Data","title":"Data Organization and Diagnostic Plots","text":"measure_plot_summary() function creates publication-ready summary plots:  Show full range show_range = TRUE:","code":"baked <- bake(sg_snv_rec, new_data = NULL) measure_plot_summary(baked) measure_plot_summary(baked, show_range = TRUE)"},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Data Organization and Diagnostic Plots","text":"Always check recipe check_measure_recipe() running long preprocessing pipelines Use measure_identify_columns() understand data structure building recipes Assign roles explicitly ID columns, metadata, special sample types Visualize stage - use autoplot() verify preprocessing effects Compare strategies plot_measure_comparison() committing preprocessing approach","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/roles-diagnostics.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Data Organization and Diagnostic Plots","text":"See vignette(\"preprocessing\") details preprocessing steps See vignette(\"recipes\") integration tidymodels workflows Explore hyperparameter tuning preprocessing steps tune","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Case Study: Bioreactor Glucose Prediction","text":"vignette demonstrates complete chemometric modeling workflow using measure. ’ll predict glucose concentration bioreactors using Raman spectroscopy data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"the-dataset","dir":"Articles","previous_headings":"","what":"The dataset","title":"Case Study: Bioreactor Glucose Prediction","text":"glucose_bioreactors dataset contains Raman spectra bioreactor experiments described Kuhn Johnson’s Feature Engineering Selection (2020). dataset : - 2,651 spectral channels (Raman wavenumbers) - glucose: target variable predict - day: sampling day (1-14) - batch_id batch_sample: reactor identifiers","code":"data(glucose_bioreactors)  # Small-scale bioreactors (15 reactors, 14 days) dim(bioreactors_small) #> [1]  210 2655  # Large-scale bioreactors (3 reactors, 14 days) dim(bioreactors_large) #> [1]   42 2655"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"exploratory-visualization","dir":"Articles","previous_headings":"","what":"Exploratory visualization","title":"Case Study: Bioreactor Glucose Prediction","text":"Let’s visualize spectra small-scale reactors:","code":"# Get spectral column names (numeric wavenumbers) spec_cols <- names(bioreactors_small)[sapply(names(bioreactors_small), function(x) !is.na(suppressWarnings(as.numeric(x))))]  # Convert a few samples to long format for plotting viz_data <- bioreactors_small |>   slice(1:10) |>   mutate(sample_id = row_number()) |>   select(sample_id, glucose, all_of(spec_cols[1:500])) |>  # First 500 channels   pivot_longer(     cols = -c(sample_id, glucose),     names_to = \"wavenumber\",     values_to = \"intensity\"   ) |>   mutate(wavenumber = as.numeric(wavenumber))  ggplot(viz_data, aes(x = wavenumber, y = intensity, group = sample_id, color = glucose)) +   geom_line(alpha = 0.7) +   scale_color_viridis_c() +   labs(     x = \"Wavenumber\",     y = \"Intensity\",     title = \"Raman Spectra from Small-Scale Bioreactors\",     subtitle = \"Color indicates glucose concentration\",     color = \"Glucose\"   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"building-a-preprocessing-recipe","dir":"Articles","previous_headings":"","what":"Building a preprocessing recipe","title":"Case Study: Bioreactor Glucose Prediction","text":"Raman spectroscopy, typical preprocessing pipeline includes: Smoothing reduce noise Baseline correction (via derivatives) Normalization instrument variations","code":"# Use first 500 spectral columns for faster example spec_cols_subset <- spec_cols[1:500] wavenumbers <- as.numeric(spec_cols_subset)  # Prepare training data train_data <- bioreactors_small |>   select(glucose, day, batch_id, all_of(spec_cols_subset))  # Create preprocessing recipe rec <- recipe(glucose ~ ., data = train_data) |>   # Don't use day and batch_id as predictors   update_role(day, batch_id, new_role = \"id\") |>   # Convert wide spectral columns to internal format   step_measure_input_wide(     all_of(spec_cols_subset),     location_values = wavenumbers   ) |>   # Savitzky-Golay smoothing + first derivative   step_measure_savitzky_golay(     window_side = 7,     differentiation_order = 1   ) |>   # Standard Normal Variate normalization   step_measure_snv() |>   # Convert back to wide format   step_measure_output_wide(prefix = \"raman_\")  rec #>  #> ── Recipe ────────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> outcome:     1 #> predictor: 500 #> id:          2 #>  #> ── Operations #> • Collate wide analytical measurements: all_of(spec_cols_subset) #> Savitzky-Golay preprocessing on  #> SNV transformation on #> • Restructure analytical measurements to wide format: \"<internal data>\""},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the data","title":"Case Study: Bioreactor Glucose Prediction","text":"preprocessed data fewer columns : - day batch_id columns preserved ID columns - 500 spectral columns transformed renamed prefix raman_","code":"# Prep the recipe (learns parameters from training data) rec_prepped <- prep(rec)  # Bake to get preprocessed data train_processed <- bake(rec_prepped, new_data = NULL)  # Check dimensions dim(train_processed) #> [1] 210 489"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"visualize-preprocessed-spectra","dir":"Articles","previous_headings":"","what":"Visualize preprocessed spectra","title":"Case Study: Bioreactor Glucose Prediction","text":"","code":"# Get preprocessed spectral columns proc_cols <- names(train_processed)[grepl(\"^raman_\", names(train_processed))]  proc_viz <- train_processed |>   slice(1:10) |>   mutate(sample_id = row_number()) |>   select(sample_id, glucose, all_of(proc_cols)) |>   pivot_longer(     cols = starts_with(\"raman_\"),     names_to = \"feature\",     values_to = \"value\"   ) |>   mutate(wavenumber = as.numeric(gsub(\"raman_\", \"\", feature)))  ggplot(proc_viz, aes(x = wavenumber, y = value, group = sample_id, color = glucose)) +   geom_line(alpha = 0.7) +   scale_color_viridis_c() +   labs(     x = \"Wavenumber\",     y = \"Preprocessed Intensity\",     title = \"Preprocessed Raman Spectra\",     subtitle = \"After SG derivative + SNV normalization\",     color = \"Glucose\"   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"fitting-a-model","dir":"Articles","previous_headings":"","what":"Fitting a model","title":"Case Study: Bioreactor Glucose Prediction","text":"Now can fit model predict glucose:","code":"library(parsnip)  # Simple linear model (PLS would be better for real applications) lm_spec <- linear_reg() |>   set_engine(\"lm\")  # Fit model model <- lm_spec |>   fit(glucose ~ ., data = train_processed |> select(-day, -batch_id))  # Training performance train_preds <- predict(model, train_processed) |>   bind_cols(train_processed |> select(glucose))  train_preds |>   summarize(     rmse = sqrt(mean((glucose - .pred)^2)),     r_squared = cor(glucose, .pred)^2   ) #> # A tibble: 1 × 2 #>       rmse r_squared #>      <dbl>     <dbl> #> 1 1.76e-12         1"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"applying-to-new-data","dir":"Articles","previous_headings":"","what":"Applying to new data","title":"Case Study: Bioreactor Glucose Prediction","text":"key advantage recipes framework consistent preprocessing new data:","code":"# Prepare test data from large-scale bioreactors test_data <- bioreactors_large |>   select(glucose, day, batch_id, all_of(spec_cols_subset))  # Apply the same preprocessing test_processed <- bake(rec_prepped, new_data = test_data)  # Predict test_preds <- predict(model, test_processed) |>   bind_cols(test_processed |> select(glucose, batch_id, day)) #> Warning in predict.lm(object = object$fit, newdata = new_data, type = #> \"response\", : prediction from rank-deficient fit; consider predict(., #> rankdeficient=\"NA\")  # Plot predictions vs actual ggplot(test_preds, aes(x = glucose, y = .pred, color = batch_id)) +   geom_point(alpha = 0.7) +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +   labs(     x = \"Actual Glucose\",     y = \"Predicted Glucose\",     title = \"Model Performance on Large-Scale Bioreactors\",     color = \"Reactor\"   ) +   theme_minimal()"},{"path":"https://jameshwade.github.io/measure/dev/articles/sec-analysis-example.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Case Study: Bioreactor Glucose Prediction","text":"case study demonstrated: Loading exploring spectral data bioreactors Building preprocessing recipe measure steps Fitting model preprocessed training data Applying consistent preprocessing new data Key takeaways: recipe framework ensures identical preprocessing training test data step_measure_input_wide() handles conversion many spectral columns Processing steps like Savitzky-Golay SNV remove unwanted variation step_measure_output_wide() produces modeling-ready data real applications, consider: Using PLS ridge regression high-dimensional spectral data Tuning preprocessing parameters cross-validation Validating truly independent test sets","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Analytical Method Validation","text":"measure package provides comprehensive suite functions analytical method validation. functions designed compatible regulatory frameworks including: - ICH Q2(R2): Validation Analytical Procedures - ISO/IEC 17025: General requirements testing calibration laboratories - USP <1225>: Validation Compendial Procedures - ICH M10: Bioanalytical Method Validation (applicable workflows) vignette demonstrates key validation workflows including calibration, precision, accuracy, uncertainty, quality control.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"fitting-calibration-curves","dir":"Articles","previous_headings":"Calibration Curves","what":"Fitting Calibration Curves","title":"Analytical Method Validation","text":"measure_calibration_fit() function fits weighted unweighted calibration curves comprehensive diagnostics.","code":"# Create calibration data set.seed(42) cal_data <- data.frame(   nominal_conc = c(1, 5, 10, 25, 50, 100, 250, 500),   response = c(1, 5, 10, 25, 50, 100, 250, 500) * 1.05 +              rnorm(8, sd = c(0.1, 0.3, 0.5, 1, 2, 4, 10, 20)) )  # Fit with 1/x^2 weighting (common for bioanalytical methods) cal <- measure_calibration_fit(   cal_data,   response ~ nominal_conc,   weights = \"1/x2\" )  print(cal) #> <measure_calibration> #>   Model: linear #>   Weighting: 1/x2 #>   Formula: response ~ nominal_conc #>   N points: 8 #>   R²: 0.9989"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"visualizing-the-calibration","dir":"Articles","previous_headings":"Calibration Curves","what":"Visualizing the Calibration","title":"Analytical Method Validation","text":"","code":"autoplot(cal, type = \"curve\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"checking-residuals","dir":"Articles","previous_headings":"Calibration Curves","what":"Checking Residuals","title":"Analytical Method Validation","text":"","code":"autoplot(cal, type = \"residuals\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"predicting-unknown-concentrations","dir":"Articles","previous_headings":"Calibration Curves","what":"Predicting Unknown Concentrations","title":"Analytical Method Validation","text":"","code":"unknowns <- data.frame(   sample_id = c(\"Sample_1\", \"Sample_2\", \"Sample_3\"),   response = c(52.3, 125.8, 280.5) )  predictions <- measure_calibration_predict(   cal,   newdata = unknowns,   interval = \"confidence\" )  cbind(unknowns, predictions) #>   sample_id response .pred_conc .pred_lower .pred_upper #> 1  Sample_1     52.3    49.3896    49.30708    49.47213 #> 2  Sample_2    125.8   118.9571   118.87457   119.03962 #> 3  Sample_3    280.5   265.3801   265.29758   265.46263"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"calibration-verification","dir":"Articles","previous_headings":"Calibration Curves","what":"Calibration Verification","title":"Analytical Method Validation","text":"Verify calibration remains valid using QC samples:","code":"qc_data <- data.frame(   sample_id = c(\"QC_Low\", \"QC_Mid\", \"QC_High\"),   nominal_conc = c(3, 75, 400),   response = c(3.1, 77.5, 395.2) )  verification <- measure_calibration_verify(cal, qc_data) print(verification) #>  #> ── Calibration Verification ──────────────────────────────────────────────────── #> ✔ Overall: PASS (3/3 samples within 15%) #>  #> ── Sample Results ── #>  #> # A tibble: 3 × 8 #>   sample_id nominal_conc response predicted_conc accuracy_pct deviation_pct #>   <chr>            <dbl>    <dbl>          <dbl>        <dbl>         <dbl> #> 1 QC_Low               3      3.1           2.82         94.1         -5.93 #> 2 QC_Mid              75     77.5          73.2          97.7         -2.34 #> 3 QC_High            400    395.          374.           93.5         -6.51 #> # ℹ 2 more variables: acceptance_limit <dbl>, pass <lgl>"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"multiple-methods","dir":"Articles","previous_headings":"Limits of Detection and Quantitation","what":"Multiple Methods","title":"Analytical Method Validation","text":"measure supports multiple approaches calculating LOD/LOQ:","code":"# Blank-based approach (3σ/10σ) blank_data <- data.frame(   sample_type = rep(\"blank\", 10),   response = rnorm(10, mean = 0.5, sd = 0.08) )  lod_result <- measure_lod(   blank_data,   \"response\",   method = \"blank_sd\",   calibration = cal ) print(lod_result) #> <measure_lod> #>   Value: 0.8726 #>   Method: blank_sd #>   k: 3 #>   Uncertainty: 0.1142 #>   Parameters: #>     blank_mean: 0.5115 #>     blank_sd: 0.1203 #>     n_blanks: 10  # Or calculate both together lod_loq <- measure_lod_loq(   blank_data,   \"response\",   method = \"blank_sd\",   calibration = cal ) tidy(lod_loq) #> # A tibble: 2 × 5 #>   limit_type value method       k uncertainty #>   <chr>      <dbl> <chr>    <dbl>       <dbl> #> 1 LOD        0.873 blank_sd     3       0.114 #> 2 LOQ        1.72  blank_sd    10       0.381"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"repeatability-within-run-precision","dir":"Articles","previous_headings":"Precision Studies","what":"Repeatability (Within-Run Precision)","title":"Analytical Method Validation","text":"","code":"# Data from replicate measurements repeat_data <- data.frame(   sample_id = rep(c(\"Low\", \"Mid\", \"High\"), each = 6),   concentration = c(     rnorm(6, 10, 0.5),     rnorm(6, 100, 4),     rnorm(6, 500, 18)   ) )  repeatability <- measure_repeatability(   repeat_data,   \"concentration\",   group_col = \"sample_id\" ) print(repeatability) #> measure_precision: repeatability  #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Group: Low  #>   n = 6  #>   Mean = 9.82  #>   SD = 0.7645  #>   CV = 7.8 % #>   95% CI: [9.017, 10.62] #>  #> Group: Mid  #>   n = 6  #>   Mean = 99.51  #>   SD = 4.893  #>   CV = 4.9 % #>   95% CI: [94.37, 104.6] #>  #> Group: High  #>   n = 6  #>   Mean = 501.1  #>   SD = 18.58  #>   CV = 3.7 % #>   95% CI: [481.6, 520.6]"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"intermediate-precision","dir":"Articles","previous_headings":"Precision Studies","what":"Intermediate Precision","title":"Analytical Method Validation","text":"","code":"# Data from multiple days ip_data <- data.frame(   day = rep(1:3, each = 6),   analyst = rep(c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"), 3),   concentration = 100 +     rep(c(-2, 0, 2), each = 6) +  # Day effect     rep(c(-1, 1), 9) +            # Analyst effect     rnorm(18, sd = 3)             # Residual )  ip_result <- measure_intermediate_precision(   ip_data,   \"concentration\",   factors = c(\"day\", \"analyst\") ) print(ip_result) #> measure_precision: intermediate  #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Variance Components: #>   day: 15.78 (57%) #>   analyst: 3.82 (14%) #>   Residual: 8.135 (29%) #>  #> CV by component: #>   day: 4% #>   analyst: 2% #>   Residual: 2.9%"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"gage-rr-analysis","dir":"Articles","previous_headings":"Precision Studies","what":"Gage R&R Analysis","title":"Analytical Method Validation","text":"measurement system analysis:","code":"# Gage R&R data grr_data <- data.frame(   part = rep(1:5, each = 6),   operator = rep(rep(c(\"Op1\", \"Op2\"), each = 3), 5),   measurement = c(     # Part 1     10.1, 10.2, 10.0, 10.3, 10.1, 10.2,     # Part 2     20.2, 20.1, 20.3, 20.0, 20.2, 20.1,     # Part 3     15.1, 15.0, 15.2, 15.3, 15.1, 15.0,     # Part 4     25.0, 25.1, 24.9, 25.2, 25.0, 25.1,     # Part 5     30.1, 30.2, 30.0, 30.1, 30.0, 30.2   ) )  grr_result <- measure_gage_rr(   grr_data,   \"measurement\",   part_col = \"part\",   operator_col = \"operator\" ) print(grr_result) #> measure_gage_rr: Measurement System Analysis #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Study design: #>   Parts: 5  #>   Operators: 2  #>   Replicates: 3  #>  #> Variance Components: #>   Repeatability: 0.01133 (0.02% contribution) #>   Reproducibility: 0 (0% contribution) #>   Total R&R: 0.01133 (0.02% contribution) #>   Part-to-Part: 62.08 (100% contribution) #>  #> % Study Variation: #>   Repeatability: 1% #>   Reproducibility: 0% #>   Total R&R: 1% #>   Part-to-Part: 100% #>  #> Number of Distinct Categories (ndc): 104  #>  #> Assessment: #>   Measurement system is ACCEPTABLE (%R&R < 10%)"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"bias-and-recovery","dir":"Articles","previous_headings":"Accuracy Assessment","what":"Bias and Recovery","title":"Analytical Method Validation","text":"","code":"accuracy_data <- data.frame(   level = rep(c(\"Low\", \"Mid\", \"High\"), each = 5),   measured = c(     rnorm(5, 10.2, 0.3),   # Low level, slight positive bias     rnorm(5, 100, 2.5),    # Mid level, no bias     rnorm(5, 498, 8)       # High level, slight negative bias   ),   reference = rep(c(10, 100, 500), each = 5) )  accuracy <- measure_accuracy(   accuracy_data,   \"measured\",   \"reference\",   group_col = \"level\" ) print(accuracy) #> measure_accuracy #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Group: Low  #>   n = 5  #>   Mean measured = 10.09  #>   Mean reference = 10  #>   Bias = 0.08854 ( 0.89 %) #>   Recovery = 101 % #>   Recovery 95% CI: [95%, 106%] #>  #> Group: Mid  #>   n = 5  #>   Mean measured = 101  #>   Mean reference = 100  #>   Bias = 1.042 ( 1 %) #>   Recovery = 101 % #>   Recovery 95% CI: [99%, 103%] #>  #> Group: High  #>   n = 5  #>   Mean measured = 502.6  #>   Mean reference = 500  #>   Bias = 2.593 ( 0.52 %) #>   Recovery = 101 % #>   Recovery 95% CI: [99%, 102%]"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"linearity-assessment","dir":"Articles","previous_headings":"Accuracy Assessment","what":"Linearity Assessment","title":"Analytical Method Validation","text":"","code":"linearity_data <- data.frame(   concentration = rep(c(10, 25, 50, 75, 100), each = 3),   response = rep(c(10, 25, 50, 75, 100), each = 3) * 1.02 +              rnorm(15, sd = 1.5) )  linearity <- measure_linearity(   linearity_data,   \"concentration\",   \"response\" ) print(linearity) #> measure_linearity #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Data: #>   n = 15 ( 5 levels ) #>   Range: 10 - 100  #>  #> Regression: #>   Slope = 1.023  #>     95% CI: [1.003, 1.044] #>   Intercept = -0.1535  #>     95% CI: [-1.436, 1.129] #>  #> Fit Quality: #>   R-squared = 0.99884  #>   Adj. R-squared = 0.99875  #>   Residual SD = 1.222  #>   Residual CV = 2.3 % #>  #> Lack-of-Fit Test: #>   F = 0.649  #>   p-value = 0.6015  #>   Result: Not significant (linearity acceptable)  # Plot with fit line autoplot(linearity, type = \"fit\")"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"iso-gum-uncertainty","dir":"Articles","previous_headings":"Uncertainty Budgets","what":"ISO GUM Uncertainty","title":"Analytical Method Validation","text":"Create uncertainty budgets following GUM (Guide Expression Uncertainty Measurement):","code":"# Define uncertainty components components <- list(   uncertainty_component(     name = \"Repeatability\",     type = \"A\",     value = 0.5,     df = 9   ),   uncertainty_component(     name = \"Calibration\",     type = \"B\",     value = 0.3,     distribution = \"normal\"   ),   uncertainty_component(     name = \"Reference Standard\",     type = \"B\",     value = 0.1,     distribution = \"rectangular\"   ),   uncertainty_component(     name = \"Temperature\",     type = \"B\",     value = 0.2,     sensitivity = 0.5  # Sensitivity coefficient   ) )  budget <- measure_uncertainty_budget(.list = components) print(budget) #> <measure_uncertainty_budget> #>   Components: 4 (1 Type A, 3 Type B) #>   Combined u: 0.6 #>   Effective df: 19 #>   Coverage k: 2 #>   Expanded U: 1.2"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"visualizing-uncertainty-contributions","dir":"Articles","previous_headings":"Uncertainty Budgets","what":"Visualizing Uncertainty Contributions","title":"Analytical Method Validation","text":"","code":"autoplot(budget)"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"setting-up-control-limits","dir":"Articles","previous_headings":"Control Charts","what":"Setting Up Control Limits","title":"Analytical Method Validation","text":"","code":"# Historical QC data qc_history <- data.frame(   run_order = 1:30,   qc_value = rnorm(30, mean = 100, sd = 2) )  limits <- measure_control_limits(qc_history, \"qc_value\") print(limits) #> measure_control_limits: shewhart chart #> ────────────────────────────────────────────────────────────────────────────────  #>  #>   n = 30  #>   Center = 100.1  #>   Sigma = 1.737  #>   UCL (+3s) = 105.3  #>   UWL (+2s) = 103.6  #>   LWL (-2s) = 96.61  #>   LCL (-3s) = 94.88"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"monitoring-with-westgard-rules","dir":"Articles","previous_headings":"Control Charts","what":"Monitoring with Westgard Rules","title":"Analytical Method Validation","text":"","code":"# New run data including potential out-of-control point new_run <- data.frame(   run_order = 1:20,   qc_value = c(rnorm(19, 100, 2), 108)  # Last point is high )  chart <- measure_control_chart(   new_run,   \"qc_value\",   \"run_order\",   limits = limits,   rules = c(\"1_3s\", \"2_2s\", \"R_4s\", \"10x\") ) print(chart) #> measure_control_chart #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Observations: 20  #> Rules applied: 1_3s, 2_2s, R_4s, 10x  #> Violations detected: 4  #>  #> Status: OUT OF CONTROL #>  #> Violation summary: #> # A tibble: 4 × 3 #>   run_order qc_value violation #>       <int>    <dbl> <chr>     #> 1         4    105.  1:3s R:4s #> 2         5     97.3 R:4s      #> 3        19    100.  R:4s      #> 4        20    108   1:3s R:4s autoplot(chart)"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"defining-criteria","dir":"Articles","previous_headings":"Acceptance Criteria","what":"Defining Criteria","title":"Analytical Method Validation","text":"","code":"# Create custom criteria my_criteria <- measure_criteria(   criterion(\"cv\", \"<=\", 15, description = \"Precision CV\"),   criterion(\"bias_pct\", \"between\", c(-10, 10), description = \"Bias\"),   criterion(\"recovery\", \"between\", c(85, 115), description = \"Recovery %\") ) print(my_criteria) #> <measure_criteria> with 3 criteria #>   • Precision CV #>   • Bias #>   • Recovery %"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"using-preset-criteria","dir":"Articles","previous_headings":"Acceptance Criteria","what":"Using Preset Criteria","title":"Analytical Method Validation","text":"","code":"# ICH Q2 presets ich_criteria <- criteria_ich_q2() print(ich_criteria) #> <measure_criteria> with 4 criteria #>   • Repeatability RSD <= 2% #>   • Intermediate precision RSD <= 5% #>   • Recovery 98-102% #>   • R² >= 0.999  # Bioanalytical presets bio_criteria <- criteria_bioanalytical() print(bio_criteria) #> <measure_criteria> with 5 criteria #>   • QC CV <= 15% #>   • Calibration CV <= 20% #>   • R² >= 0.99 #>   • Recovery 80-120% #>   • Bias within +/-15%"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"assessing-results","dir":"Articles","previous_headings":"Acceptance Criteria","what":"Assessing Results","title":"Analytical Method Validation","text":"","code":"# Sample results to assess (single summary values per criterion) # For example, from a method validation summary results <- list(   cv = 5.2,          # Overall precision CV   bias_pct = 1.3,    # Overall bias   recovery = 101.3   # Mean recovery )  assessment <- measure_assess(results, my_criteria) print(assessment) #> <measure_assessment> [PASS] #>   3 passed, 0 failed #>  #>   ✓ cv: 5.2 (<= 15) #>   ✓ bias_pct: 1.3 (between [-10, 10]) #>   ✓ recovery: 101.3 (between [85, 115])  # Check if all criteria passed all_pass(assessment) #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"method-comparison","dir":"Articles","previous_headings":"","what":"Method Comparison","title":"Analytical Method Validation","text":"validating new method, often need compare reference existing method. measure package provides several approaches method comparison studies.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"bland-altman-analysis","dir":"Articles","previous_headings":"Method Comparison","what":"Bland-Altman Analysis","title":"Analytical Method Validation","text":"Bland-Altman plots show agreement two methods plotting differences means:","code":"# Paired measurements from two methods comparison_data <- data.frame(   sample_id = 1:30,   method_A = rnorm(30, mean = 100, sd = 15),   method_B = rnorm(30, mean = 102, sd = 16) )  ba <- measure_bland_altman(   comparison_data,   method1_col = \"method_A\",   method2_col = \"method_B\",   regression = \"linear\"  # Test for proportional bias ) print(ba) #> measure_bland_altman #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Bias Statistics: #>   n = 30  #>   Mean bias = 4.083  #>   SD of differences = 17.97  #>   95% CI for bias: [-2.625, 10.79] #>  #> Limits of Agreement: #>   Lower LOA = -31.13 (95% CI: [ -42.75 ,  -19.51 ]) #>   Upper LOA = 39.3 (95% CI: [ 27.68 ,  50.92 ]) #>   LOA Width = 70.43  #>  #> Proportional Bias Test: #>   Slope = 0.2046  #>   p-value = 0.57  #>   Result: No significant proportional bias autoplot(ba) #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"regression-methods","dir":"Articles","previous_headings":"Method Comparison","what":"Regression Methods","title":"Analytical Method Validation","text":"method comparison regression, use Deming Passing-Bablok regression account error methods: Passing-Bablok regression (non-parametric), install mcr package:","code":"# Method comparison with known measurement error deming_data <- data.frame(   reference = c(5, 10, 25, 50, 100, 200, 400),   test_method = c(5.2, 10.3, 25.8, 51.2, 101.5, 203.1, 408.2) )  deming <- measure_deming_regression(   deming_data,   method1_col = \"reference\",   method2_col = \"test_method\",   bootstrap = TRUE,   bootstrap_n = 500 ) #> Using default error ratio of 1. Provide `error_ratio` or SDs for more accurate #> results. print(deming) #> measure_deming_regression #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Coefficients: #> # A tibble: 2 × 4 #>   term      estimate ci_lower ci_upper #>   <chr>        <dbl>    <dbl>    <dbl> #> 1 intercept -0.00414   -0.325    0.437 #> 2 slope      1.02       1.01     1.02  #>  #> Statistics: #>   n = 7  #>   Error ratio = 1  #>   RMSE = 0.4087  #>   R² = 1  #>  #> (Fitted using mcr package)  # Check if methods are equivalent glance(deming) #> # A tibble: 1 × 6 #>   intercept slope intercept_ci_includes_0 slope_ci_includes_1 r_squared  rmse #>       <dbl> <dbl> <lgl>                   <lgl>                   <dbl> <dbl> #> 1  -0.00414  1.02 TRUE                    FALSE                   1.000 0.409 # Requires: install.packages(\"mcr\") pb <- measure_passing_bablok(   deming_data,   method1_col = \"reference\",   method2_col = \"test_method\" ) print(pb)"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"proficiency-testing","dir":"Articles","previous_headings":"Method Comparison","what":"Proficiency Testing","title":"Analytical Method Validation","text":"Evaluate laboratory performance proficiency testing programs:","code":"# PT results from multiple labs pt_data <- data.frame(   lab_id = paste0(\"Lab_\", 1:10),   measured = c(99.2, 100.5, 98.8, 101.2, 97.5, 100.1, 99.8, 102.3, 100.6, 94.0),   assigned = rep(100, 10),   uncertainty = c(1.5, 2.0, 1.8, 1.6, 2.2, 1.9, 1.7, 2.1, 1.5, 2.0) )  # z-scores with known sigma z_scores <- measure_proficiency_score(   pt_data,   measured_col = \"measured\",   reference_col = \"assigned\",   score_type = \"z_score\",   sigma = 2.5 ) print(z_scores) #> measure_proficiency_score #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Score Type: z_score  #> Sigma: 2.5  #>  #> Results (n = 10 ): #>   Satisfactory (|z| ≤ 2): 9 ( 90 %) #>   Questionable (2 < |z| ≤ 3): 1  #>   Unsatisfactory (|z| > 3): 0  #>  #> Score Statistics: #>   Mean score: -0.24  #>   SD score: 0.925  #>   Max |score|: 2.4 autoplot(z_scores)"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"matrix-effects","dir":"Articles","previous_headings":"","what":"Matrix Effects","title":"Analytical Method Validation","text":"Matrix effects (ion suppression/enhancement) must evaluated LC-MS/MS similar methods.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"evaluating-matrix-effects","dir":"Articles","previous_headings":"Matrix Effects","what":"Evaluating Matrix Effects","title":"Analytical Method Validation","text":"","code":"# Post-extraction spike experiment me_data <- data.frame(   sample_type = rep(c(\"matrix\", \"neat\"), each = 6),   matrix_lot = rep(c(\"Lot1\", \"Lot2\", \"Lot3\"), 4),   concentration = rep(c(\"low\", \"high\"), each = 3, times = 2),   response = c(     # Matrix samples (some suppression)     9200, 9500, 8900, 47500, 48200, 46800,     # Neat samples     10000, 10000, 10000, 50000, 50000, 50000   ) )  me <- measure_matrix_effect(   me_data,   response_col = \"response\",   sample_type_col = \"sample_type\",   matrix_level = \"matrix\",   neat_level = \"neat\",   concentration_col = \"concentration\" ) print(me) #> measure_matrix_effect #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Overall Matrix Effect Summary: #>   Groups evaluated: 2  #>   Mean ME: 94 % #>   SD ME: 2 % #>   CV ME: 2 % #>   Range: 92 - 95 % #>  #> Effect Classification: #>   Ion suppression (ME < 100%): 2  #>   Ion enhancement (ME > 100%): 0  #>   Acceptable (80-120%): 2 / 2 autoplot(me, type = \"bar\")"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"standard-addition-correction","dir":"Articles","previous_headings":"Matrix Effects","what":"Standard Addition Correction","title":"Analytical Method Validation","text":"matrix effects vary samples, standard addition provides sample-specific correction:","code":"library(recipes)  # Standard addition data sa_data <- data.frame(   sample_id = rep(c(\"Sample1\", \"Sample2\"), each = 4),   addition = rep(c(0, 10, 20, 30), 2),   response = c(     150, 250, 350, 450,  # Sample 1     250, 350, 450, 550   # Sample 2   ) )  rec <- recipe(~ ., data = sa_data) |>   step_measure_standard_addition(     response,     addition_col = \"addition\",     sample_id_col = \"sample_id\"   ) |>   prep()  # Original concentrations calculated via extrapolation bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"sample-preparation-qc","dir":"Articles","previous_headings":"","what":"Sample Preparation QC","title":"Analytical Method Validation","text":"Recipe steps quality control sample preparation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"dilution-factor-correction","dir":"Articles","previous_headings":"Sample Preparation QC","what":"Dilution Factor Correction","title":"Analytical Method Validation","text":"Back-calculate concentrations diluted samples:","code":"library(recipes)  dilution_data <- data.frame(   sample_id = paste0(\"S\", 1:5),   dilution_factor = c(1, 2, 5, 10, 1),   analyte = c(50, 45, 42, 48, 51)  # Measured after dilution )  rec <- recipe(~ ., data = dilution_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_dilution_correct(     analyte,     dilution_col = \"dilution_factor\",     operation = \"multiply\"   ) |>   prep()  # Back-calculated original concentrations bake(rec, new_data = NULL) #> # A tibble: 5 × 3 #>   sample_id dilution_factor analyte #>   <chr>               <dbl>   <dbl> #> 1 S1                      1      50 #> 2 S2                      2      90 #> 3 S3                      5     210 #> 4 S4                     10     480 #> 5 S5                      1      51"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"surrogate-recovery","dir":"Articles","previous_headings":"Sample Preparation QC","what":"Surrogate Recovery","title":"Analytical Method Validation","text":"Monitor extraction efficiency surrogate standards:","code":"qc_data <- data.frame(   sample_id = paste0(\"QC\", 1:6),   surrogate = c(95, 105, 88, 112, 75, 132)  # Expected = 100 )  rec <- recipe(~ ., data = qc_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_surrogate_recovery(     surrogate,     expected_value = 100,     action = \"flag\",     min_recovery = 80,     max_recovery = 120   ) |>   prep()  # Flag samples outside recovery limits bake(rec, new_data = NULL) #> # A tibble: 6 × 3 #>   sample_id surrogate .surrogate_pass #>   <chr>         <dbl> <lgl>           #> 1 QC1              95 TRUE            #> 2 QC2             105 TRUE            #> 3 QC3              88 TRUE            #> 4 QC4             112 TRUE            #> 5 QC5              75 FALSE           #> 6 QC6             132 FALSE"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"detecting-drift","dir":"Articles","previous_headings":"Drift Correction","what":"Detecting Drift","title":"Analytical Method Validation","text":"","code":"# Data with drift drift_data <- data.frame(   sample_type = rep(\"qc\", 20),   run_order = 1:20,   feature1 = 100 + (1:20) * 0.8 + rnorm(20, sd = 2),  # Has drift    feature2 = 100 + rnorm(20, sd = 2)                   # No drift )  drift_result <- measure_detect_drift(   drift_data,   features = c(\"feature1\", \"feature2\"),   qc_type = \"qc\" ) print(drift_result) #> # A tibble: 2 × 5 #>   feature    slope slope_pvalue percent_change significant #>   <chr>      <dbl>        <dbl>          <dbl> <lgl>       #> 1 feature1  0.630     0.0000148         11.1   TRUE        #> 2 feature2 -0.0351    0.634             -0.662 FALSE"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"correcting-drift","dir":"Articles","previous_headings":"Drift Correction","what":"Correcting Drift","title":"Analytical Method Validation","text":"","code":"library(recipes)  # Using QC-LOESS correction in a recipe rec <- recipe(~ ., data = drift_data) |>   step_measure_drift_qc_loess(     feature1, feature2,     qc_type = \"qc\"   ) |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"validation-reports","dir":"Articles","previous_headings":"","what":"Validation Reports","title":"Analytical Method Validation","text":"’ve completed validation studies, can compile results reproducible validation report using measure_validation_report(). package provides templates following regulatory frameworks like ICH Q2(R2) USP <1225>. ### Creating Validation Report","code":"# Gather validation results (using objects from above) report <- measure_validation_report(   # Metadata   title = \"HPLC-UV Method Validation Report\",   method_name = \"Compound X Assay\",   method_description = \"Reversed-phase HPLC with UV detection at 254 nm\",   analyst = \"J. Smith\",   reviewer = \"A. Jones\",   lab = \"Analytical Development\",   instrument = \"Agilent 1260 Infinity II\",     # Validation sections (results from earlier in this vignette)   calibration = cal,   lod_loq = lod_loq,   accuracy = accuracy,   precision = list(repeatability = repeatability, intermediate = ip_result),   linearity = linearity,   range = list(lower = 1, upper = 500, units = \"ng/mL\"),   uncertainty = budget,    # Text sections   specificity = \"No interfering peaks observed at the analyte retention time when analyzing blank matrix samples.\",   robustness = list(     factors = c(\"Flow rate (±0.1 mL/min)\", \"Column temperature (±5°C)\", \"Mobile phase pH (±0.2)\"),     conclusion = \"Method showed acceptable robustness within tested parameter ranges.\"   ),    # Conclusions   conclusions = list(     summary = \"The analytical method meets all acceptance criteria for precision, accuracy, and linearity.\",     recommendations = c(       \"Method is suitable for intended use\",       \"Revalidate if significant changes are made to instrumentation or reagents\"     )   ),    # References   references = c(     \"ICH Q2(R2) Validation of Analytical Procedures (2023)\",     \"USP <1225> Validation of Compendial Procedures\"   ) )  print(report) #>  #> ── Validation Report ─────────────────────────────────────────────────────────── #> Title: HPLC-UV Method Validation Report #> Method: Compound X Assay #> Analyst: J. Smith #> Lab: Analytical Development #> Date: 2026-01-01 #>  #> ── Validation Sections ── #>  #> ℹ Calibration #> ℹ LOD/LOQ #> ℹ Accuracy #> ℹ Precision #> ℹ Linearity #> ℹ Range #> ℹ Specificity/Selectivity #> ℹ Robustness #> ℹ Measurement Uncertainty #>  #> ── Conclusions ── #>  #> The analytical method meets all acceptance criteria for precision, accuracy, #> and linearity. #>  #> ── Provenance ── #>  #> Generated: 2026-01-01 14:28:29.797234 #> R version: 4.5.2 #> measure version: 0.0.1.9001 #>  #> ℹ Use `render_validation_report()` to generate document"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"inspecting-report-sections","dir":"Articles","previous_headings":"Validation Reports","what":"Inspecting Report Sections","title":"Analytical Method Validation","text":"","code":"# Check which sections are included summary(report) #>  #> ── Validation Report Summary ─────────────────────────────────────────────────── #> Method: Compound X Assay #> Date: 2026-01-01 #>  #> # A tibble: 9 × 4 #>   section                 status n_results notes              #>   <chr>                   <chr>      <int> <chr>              #> 1 Calibration             info           8 \"\"                 #> 2 LOD/LOQ                 info          NA \"Method: blank_sd\" #> 3 Accuracy                info           3 \"\"                 #> 4 Precision               info          NA \"\"                 #> 5 Linearity               info          NA \"\"                 #> 6 Range                   info          NA \"\"                 #> 7 Specificity/Selectivity info          NA \"\"                 #> 8 Robustness              info          NA \"\"                 #> 9 Measurement Uncertainty info          NA \"\" #>  #> ✔ All sections meet acceptance criteria  # Access specific sections has_validation_section(report, \"calibration\") #> [1] TRUE has_validation_section(report, \"stability\")  # Not included #> [1] FALSE  # Get section data get_validation_section(report, \"range\") #> $lower #> [1] 1 #>  #> $upper #> [1] 500 #>  #> $units #> [1] \"ng/mL\""},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"adding-custom-sections","dir":"Articles","previous_headings":"Validation Reports","what":"Adding Custom Sections","title":"Analytical Method Validation","text":"can add additional sections report creation:","code":"# Add a stability section later report <- add_validation_section(   report,   \"stability\",   list(     description = \"Short-term stability at room temperature\",     results = data.frame(       timepoint = c(\"0h\", \"4h\", \"8h\", \"24h\"),       recovery_pct = c(100, 99.5, 98.8, 97.2)     ),     conclusion = \"Sample is stable for 24 hours at room temperature.\"   ) )  has_validation_section(report, \"stability\") #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"tidy-output","dir":"Articles","previous_headings":"Validation Reports","what":"Tidy Output","title":"Analytical Method Validation","text":"Extract results tidy tibble analysis:","code":"tidy(report) #> # A tibble: 10 × 41 #>    section              term  estimate std_error statistic   p_value group     n #>    <chr>                <chr>    <dbl>     <dbl>     <dbl>     <dbl> <chr> <int> #>  1 Calibration          (Int…    0.119    0.0395      3.00  2.39e- 2 NA       NA #>  2 Calibration          nomi…    1.06     0.0143     73.8   4.16e-10 NA       NA #>  3 Accuracy             NA      NA       NA          NA    NA        Low       5 #>  4 Accuracy             NA      NA       NA          NA    NA        Mid       5 #>  5 Accuracy             NA      NA       NA          NA    NA        High      5 #>  6 Linearity            NA      NA       NA          NA    NA        NA       15 #>  7 Measurement Uncerta… NA      NA       NA          NA    NA        NA       NA #>  8 Measurement Uncerta… NA      NA       NA          NA    NA        NA       NA #>  9 Measurement Uncerta… NA      NA       NA          NA    NA        NA       NA #> 10 Measurement Uncerta… NA      NA       NA          NA    NA        NA       NA #> # ℹ 33 more variables: mean_measured <dbl>, mean_reference <dbl>, bias <dbl>, #> #   bias_pct <dbl>, mean_recovery <dbl>, sd_recovery <dbl>, cv_recovery <dbl>, #> #   recovery_ci_lower <dbl>, recovery_ci_upper <dbl>, n_levels <int>, #> #   range_min <dbl>, range_max <dbl>, slope <dbl>, slope_ci_lower <dbl>, #> #   slope_ci_upper <dbl>, intercept <dbl>, intercept_ci_lower <dbl>, #> #   intercept_ci_upper <dbl>, r_squared <dbl>, adj_r_squared <dbl>, #> #   residual_sd <dbl>, residual_cv <dbl>, lof_f <dbl>, lof_p <dbl>, …"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"rendering-reports","dir":"Articles","previous_headings":"Validation Reports","what":"Rendering Reports","title":"Analytical Method Validation","text":"render validation report HTML PDF, use render_validation_report(). Two templates provided: ICH Q2(R2): Organized validation characteristics (specificity, linearity, range, accuracy, precision, etc.) USP <1225>: Organized procedure category (, II, III, IV) rendered report includes: Header: Method name, date, analyst, reviewer, lab, instrument Table Contents: Auto-generated sections Validation Sections: formatted tables plots Provenance: R version, package versions, timestamp reproducibility","code":"# Render to HTML using ICH Q2 template (default) render_validation_report(   report,   output_file = \"validation_report.html\",   template = \"ich_q2\" )  # Render to PDF using USP <1225> template render_validation_report(   report,   output_file = \"validation_report.pdf\",   output_format = \"pdf\",   template = \"usp_1225\" )  # Use a custom Quarto template render_validation_report(   report,   output_file = \"custom_report.html\",   template_path = \"path/to/custom_template.qmd\" )"},{"path":"https://jameshwade.github.io/measure/dev/articles/validation.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Analytical Method Validation","text":"measure package provides complete toolkit analytical method validation: functions follow consistent design philosophy: - Tidy outputs: Results tibbles tidy(), glance(), autoplot() methods - Transparent diagnostics: hidden decisions; parameters flags visible - Regulatory compatibility: Designed ICH, ISO, FDA guidelines mind - Provenance tracking: Audit trails outlier handling data modifications details function, see package documentation ?function_name.","code":""},{"path":"https://jameshwade.github.io/measure/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James Wade. Author, maintainer. Max Kuhn. Contributor.","code":""},{"path":"https://jameshwade.github.io/measure/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wade J (2026). measure: Recipes-Style Interface Tidymodels Analytical Measurements. R package version 0.0.1.9001, https://jameshwade.github.io/measure/.","code":"@Manual{,   title = {measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements},   author = {James Wade},   year = {2026},   note = {R package version 0.0.1.9001},   url = {https://jameshwade.github.io/measure/}, }"},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"measure extends tidymodels preprocessing steps analytical measurement data spectroscopy, chromatography, instrument-generated signals. provides recipes-style interface common spectral preprocessing techniques. measure helps : Convert measurement data wide long formats internal representation Preprocess spectra using techniques like smoothing, derivatives, normalization Transform data back wide long format modeling visualization Handle multi-dimensional data like LC-DAD, EEM fluorescence, 2D NMR native nD support Decompose complex signals using PARAFAC, Tucker, MCR-ALS methods","code":""},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"can install development version measure GitHub:","code":"# install.packages(\"pak\") pak::pak(\"JamesHWade/measure\")"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"measure workflow follows familiar recipes pattern: define recipe, add steps, prep, bake.","code":"library(measure) library(recipes) library(ggplot2)  # NIR spectroscopy data for predicting meat composition data(meats_long) head(meats_long) #> # A tibble: 6 × 6 #>      id water   fat protein channel transmittance #>   <int> <dbl> <dbl>   <dbl>   <int>         <dbl> #> 1     1  60.5  22.5    16.7       1          2.62 #> 2     1  60.5  22.5    16.7       2          2.62 #> 3     1  60.5  22.5    16.7       3          2.62 #> 4     1  60.5  22.5    16.7       4          2.62 #> 5     1  60.5  22.5    16.7       5          2.62 #> 6     1  60.5  22.5    16.7       6          2.62"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"building-a-preprocessing-recipe","dir":"","previous_headings":"Usage","what":"Building a preprocessing recipe","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"","code":"rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   # Assign sample ID role (not used as predictor)   update_role(id, new_role = \"id\") |>   # Convert long-format measurements to internal representation   step_measure_input_long(transmittance, location = vars(channel)) |>   # Apply Savitzky-Golay smoothing with first derivative   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   # Standard Normal Variate normalization   step_measure_snv() |>   # Convert back to wide format for modeling   step_measure_output_wide(prefix = \"nir_\")"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"preparing-and-applying-the-recipe","dir":"","previous_headings":"Usage","what":"Preparing and applying the recipe","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"","code":"# Prep learns any parameters from training data prepped <- prep(rec)  # Bake applies the transformations processed <- bake(prepped, new_data = NULL)  # Result is ready for modeling processed[1:5, 1:8] #> # A tibble: 5 × 8 #>      id water   fat protein  nir_01  nir_02  nir_03  nir_04 #>   <int> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1     1  60.5  22.5    16.7 -0.126  -0.110  -0.0928 -0.0745 #> 2     2  46    40.1    13.5  0.0184  0.0381  0.0601  0.0841 #> 3     3  71     8.4    20.5  0.105   0.114   0.125   0.136  #> 4     4  72.8   5.9    20.7  0.0716  0.0786  0.0871  0.0974 #> 5     5  58.3  25.5    15.5 -0.132  -0.118  -0.101  -0.0817"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"visualizing-the-preprocessing","dir":"","previous_headings":"Usage","what":"Visualizing the preprocessing","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"","code":"# Get data at intermediate step (before output conversion) rec_for_viz <- recipe(water + fat + protein ~ ., data = meats_long) |> update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>   step_measure_snv()  processed_long <- bake(prep(rec_for_viz), new_data = NULL)  # Extract and plot a few spectra library(tidyr) library(dplyr)  plot_data <- processed_long |>   slice(1:10) |>   mutate(sample_id = row_number()) |>   unnest(.measures)  ggplot(plot_data, aes(x = location, y = value, group = sample_id, color = factor(sample_id))) +   geom_line(alpha = 0.7) +   labs(     x = \"Channel\",     y = \"Preprocessed Signal\",     title = \"NIR Spectra After Preprocessing\",     subtitle = \"Savitzky-Golay first derivative + SNV normalization\",     color = \"Sample\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"analytical-validation-functions","dir":"","previous_headings":"","what":"Analytical Validation Functions","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"measure provides comprehensive suite functions analytical method validation, designed compatibility ICH Q2(R2), ISO 17025, similar regulatory frameworks.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"learning-more","dir":"","previous_headings":"","what":"Learning more","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"Getting Started - comprehensive introduction measure Preprocessing Techniques - Deep dive available preprocessing methods Analytical Validation - Calibration, uncertainty, method validation","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"included-datasets","dir":"","previous_headings":"Datasets","what":"Included Datasets","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"package includes datasets examples testing:","code":"# Load datasets data(meats_long) data(glucose_bioreactors)  # loads bioreactors_small and bioreactors_large data(hplc_chromatograms) data(sec_chromatograms) data(sec_calibration) data(maldi_spectra)"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"external-data-sources","dir":"","previous_headings":"Datasets","what":"External Data Sources","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"additional test data beyond ’s included measure, sources provide publicly available analytical measurement data: R Packages Spectral Data: Online Repositories: Mendeley Data - Search “spectroscopy”, “chromatography”, “mass spectrometry” Zenodo - Open science data repository Kaggle Datasets - Community-contributed datasets NIST Chemistry WebBook - Reference spectra (IR, MS, UV-Vis) SDBS - Spectral Database Organic Compounds (NMR, IR, MS) Domain-Specific Databases:","code":"# Example: Load NIRsoil from prospectr # install.packages(\"prospectr\") data(NIRsoil, package = \"prospectr\")"},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"related-packages","dir":"","previous_headings":"","what":"Related packages","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"measure builds tidymodels ecosystem: recipes - foundation preprocessing pipelines parsnip - Unified modeling interface workflows - Bundle preprocessing modeling tune - Hyperparameter tuning (works measure’s tunable steps!) spectral analysis R, might also find packages useful: prospectr - Spectral preprocessing functions ChemoSpec - Exploratory chemometrics mdatools - Multivariate data analysis","code":""},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"package active development. Contributions welcome! Please see contributing guidelines.","code":""},{"path":"https://jameshwade.github.io/measure/dev/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"A Recipes-Style Interface to Tidymodels for Analytical Measurements","text":"Please note measure project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/add_validation_section.html","id":null,"dir":"Reference","previous_headings":"","what":"Add or update a validation section — add_validation_section","title":"Add or update a validation section — add_validation_section","text":"Add update validation section","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/add_validation_section.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add or update a validation section — add_validation_section","text":"","code":"add_validation_section(report, section, data)"},{"path":"https://jameshwade.github.io/measure/dev/reference/add_validation_section.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add or update a validation section — add_validation_section","text":"report measure_validation_report object. section Section name. data Section data add.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/add_validation_section.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add or update a validation section — add_validation_section","text":"Updated measure_validation_report object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/add_validation_section.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add or update a validation section — add_validation_section","text":"","code":"report <- measure_validation_report(title = \"Test Report\") # Add custom section report <- add_validation_section(   report,   \"custom_study\",   list(results = data.frame(x = 1:3, y = 4:6)) )"},{"path":"https://jameshwade.github.io/measure/dev/reference/align_max_shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for alignment steps — align_max_shift","title":"Parameters for alignment steps — align_max_shift","text":"align_max_shift() controls maximum shift allowed alignment. align_segment_length() controls segment size COW alignment.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/align_max_shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for alignment steps — align_max_shift","text":"","code":"align_max_shift(range = c(1L, 50L), trans = NULL)  align_segment_length(range = c(10L, 100L), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/align_max_shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for alignment steps — align_max_shift","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/align_max_shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for alignment steps — align_max_shift","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/align_max_shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for alignment steps — align_max_shift","text":"","code":"align_max_shift() #> Maximum Alignment Shift (quantitative) #> Range: [1, 50] align_segment_length() #> Alignment Segment Length (quantitative) #> Range: [10, 100]"},{"path":"https://jameshwade.github.io/measure/dev/reference/all_pass.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if All Criteria Pass — all_pass","title":"Check if All Criteria Pass — all_pass","text":"convenience function check criteria assessment passed.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/all_pass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if All Criteria Pass — all_pass","text":"","code":"all_pass(assessment, na_pass = FALSE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/all_pass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if All Criteria Pass — all_pass","text":"assessment measure_assessment object measure_assess(). na_pass Logical. NA results count pass? Default FALSE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/all_pass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if All Criteria Pass — all_pass","text":"Logical: TRUE criteria passed, FALSE otherwise.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/all_pass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if All Criteria Pass — all_pass","text":"","code":"crit <- measure_criteria(cv = 15, rsd = 20) results <- list(cv = 10, rsd = 15) assessment <- measure_assess(results, crit) all_pass(assessment) #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/reference/augment.measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment Calibration Data — augment.measure_calibration","title":"Augment Calibration Data — augment.measure_calibration","text":"Add fitted values residuals calibration data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/augment.measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment Calibration Data — augment.measure_calibration","text":"","code":"# S3 method for class 'measure_calibration' augment(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/augment.measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment Calibration Data — augment.measure_calibration","text":"x measure_calibration object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/augment.measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment Calibration Data — augment.measure_calibration","text":"tibble original calibration data plus: .fitted: Fitted values .resid: Residuals .std_resid: Standardized residuals .hat: Leverage values .cooksd: Cook's distance","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Autoplot Methods for Measure Objects — autoplot-measure","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"Create ggplot2 visualizations spectral/chromatographic data stored measure objects.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"","code":"# S3 method for class 'measure_tbl' autoplot(object, ...)  # S3 method for class 'measure_list' autoplot(object, summary = FALSE, max_spectra = 50, alpha = 0.3, ...)  # S3 method for class 'recipe' autoplot(object, n_samples = 10, which = c(\"before_after\", \"summary\"), ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"object measure_tbl, measure_list, recipe object. ... Additional arguments passed specific plot types. summary Logical. TRUE, add mean +/- SD ribbon. Default FALSE. max_spectra Maximum number individual spectra plot. Default 50. Set NULL limit. alpha Transparency individual spectrum lines. Default 0.3. n_samples Number samples show /comparison. Default 10. comparison show: \"before_after\" (default) shows side--side /comparison, \"summary\" shows summary statistics (mean +/- SD) processed data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"ggplot2 object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"measure_tbl (single spectrum): Plots location vs value line measure_list (multiple spectra): Plots spectra optional summary ribbon Use summary = TRUE mean +/- SD ribbon Use max_spectra limit number individual lines recipe: Shows /comparison preprocessing Requires prepped recipe Use n_samples control number samples shown","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot-measure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Autoplot Methods for Measure Objects — autoplot-measure","text":"","code":"if (FALSE) { # \\dontrun{ library(ggplot2)  # Single spectrum spec <- new_measure_tbl(location = 1:100, value = sin(1:100 / 10) + rnorm(100, sd = 0.1)) autoplot(spec)  # Multiple spectra with summary rec <- recipe(water ~ ., data = meats_long) |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep() baked <- bake(rec, new_data = NULL) autoplot(baked$.measures, summary = TRUE)  # Recipe before/after comparison rec <- recipe(water ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_snv() |>   prep() autoplot(rec, n_samples = 10) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_bland_altman.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Bland-Altman Analysis — autoplot.measure_bland_altman","title":"Plot Bland-Altman Analysis — autoplot.measure_bland_altman","text":"Creates Bland-Altman plot showing differences vs means limits agreement.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_bland_altman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Bland-Altman Analysis — autoplot.measure_bland_altman","text":"","code":"# S3 method for class 'measure_bland_altman' autoplot(object, show_loa = TRUE, show_ci = FALSE, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_bland_altman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Bland-Altman Analysis — autoplot.measure_bland_altman","text":"object measure_bland_altman object. show_loa Show limits agreement? Default TRUE. show_ci Show confidence intervals LOA? Default FALSE. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_bland_altman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Bland-Altman Analysis — autoplot.measure_bland_altman","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","title":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","text":"Creates diagnostic plots calibration curve using ggplot2.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","text":"","code":"# S3 method for class 'measure_calibration' autoplot(object, type = c(\"curve\", \"residuals\", \"qq\", \"all\"), ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","text":"object measure_calibration object. type Type plot: \"curve\" (default): Calibration curve data points \"residuals\": Residuals vs concentration \"qq\": Normal Q-Q plot residuals \"\": diagnostic plots combined ... Additional arguments passed ggplot2 functions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Calibration Curve Diagnostics — autoplot.measure_calibration","text":"","code":"library(ggplot2) data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100),   response = c(0.5, 15.2, 35.8, 72.1, 148.3) ) cal <- measure_calibration_fit(data, response ~ nominal_conc) autoplot(cal)  autoplot(cal, type = \"residuals\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_control_chart.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Control Chart — autoplot.measure_control_chart","title":"Plot Control Chart — autoplot.measure_control_chart","text":"Creates control chart visualization showing data points, control limits, rule violations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_control_chart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Control Chart — autoplot.measure_control_chart","text":"","code":"# S3 method for class 'measure_control_chart' autoplot(object, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_control_chart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Control Chart — autoplot.measure_control_chart","text":"object measure_control_chart object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_control_chart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Control Chart — autoplot.measure_control_chart","text":"ggplot object showing control chart.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_deming_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method Comparison Regression — autoplot.measure_deming_regression","title":"Plot Method Comparison Regression — autoplot.measure_deming_regression","text":"Creates scatter plot regression line method comparison.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_deming_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method Comparison Regression — autoplot.measure_deming_regression","text":"","code":"# S3 method for class 'measure_deming_regression' autoplot(object, show_identity = TRUE, ...)  # S3 method for class 'measure_passing_bablok' autoplot(object, show_identity = TRUE, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_deming_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method Comparison Regression — autoplot.measure_deming_regression","text":"object measure_deming_regression measure_passing_bablok object. show_identity Show y = x identity line? Default TRUE. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_deming_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method Comparison Regression — autoplot.measure_deming_regression","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_linearity.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Linearity Assessment Results — autoplot.measure_linearity","title":"Plot Linearity Assessment Results — autoplot.measure_linearity","text":"Creates diagnostic plots linearity assessment.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_linearity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Linearity Assessment Results — autoplot.measure_linearity","text":"","code":"# S3 method for class 'measure_linearity' autoplot(object, type = c(\"fit\", \"residuals\"), ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_linearity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Linearity Assessment Results — autoplot.measure_linearity","text":"object linearity assessment result measure_linearity(). type Type plot: \"fit\" fitted vs actual, \"residuals\". ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_linearity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Linearity Assessment Results — autoplot.measure_linearity","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_matrix_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Matrix Effects — autoplot.measure_matrix_effect","title":"Plot Matrix Effects — autoplot.measure_matrix_effect","text":"Creates visualization matrix effects showing suppression/enhancement.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_matrix_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Matrix Effects — autoplot.measure_matrix_effect","text":"","code":"# S3 method for class 'measure_matrix_effect' autoplot(object, type = c(\"bar\", \"point\", \"forest\"), show_limits = TRUE, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_matrix_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Matrix Effects — autoplot.measure_matrix_effect","text":"object measure_matrix_effect object. type Plot type: \"bar\", \"point\", \"forest\". Default \"bar\". show_limits Show acceptable limits (80-120%)? Default TRUE. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_matrix_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Matrix Effects — autoplot.measure_matrix_effect","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_proficiency_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Proficiency Test Scores — autoplot.measure_proficiency_score","title":"Plot Proficiency Test Scores — autoplot.measure_proficiency_score","text":"Creates bar chart dot plot proficiency scores threshold lines.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_proficiency_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Proficiency Test Scores — autoplot.measure_proficiency_score","text":"","code":"# S3 method for class 'measure_proficiency_score' autoplot(object, type = c(\"bar\", \"point\"), ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_proficiency_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Proficiency Test Scores — autoplot.measure_proficiency_score","text":"object measure_proficiency_score object. type Plot type: \"bar\" \"point\". Default \"bar\". ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_proficiency_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Proficiency Test Scores — autoplot.measure_proficiency_score","text":"ggplot object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_uncertainty_budget.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","title":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","text":"Creates Pareto chart showing relative contribution uncertainty component combined uncertainty.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_uncertainty_budget.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","text":"","code":"# S3 method for class 'measure_uncertainty_budget' autoplot(object, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_uncertainty_budget.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","text":"object measure_uncertainty_budget object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_uncertainty_budget.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","text":"ggplot object showing Pareto chart.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/autoplot.measure_uncertainty_budget.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Uncertainty Budget — autoplot.measure_uncertainty_budget","text":"","code":"library(ggplot2) u1 <- uncertainty_component(\"Repeatability\", 0.05, type = \"A\", df = 9) u2 <- uncertainty_component(\"Calibrator\", 0.02, type = \"B\") u3 <- uncertainty_component(\"Temperature\", 0.03, type = \"B\") budget <- measure_uncertainty_budget(u1, u2, u3)  autoplot(budget)"},{"path":"https://jameshwade.github.io/measure/dev/reference/baseline_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for baseline correction steps — baseline_lambda","title":"Parameters for baseline correction steps — baseline_lambda","text":"baseline_lambda() controls smoothness penalty ALS baseline correction. baseline_asymmetry() controls asymmetry parameter ALS. baseline_degree() controls polynomial degree baseline fitting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/baseline_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for baseline correction steps — baseline_lambda","text":"","code":"baseline_lambda(range = c(2, 9), trans = scales::transform_log10())  baseline_asymmetry(range = c(0.001, 0.1), trans = NULL)  baseline_degree(range = c(1L, 6L), trans = NULL)  baseline_half_window(range = c(5L, 100L), trans = NULL)  baseline_span(range = c(0.1, 0.9), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/baseline_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for baseline correction steps — baseline_lambda","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/baseline_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for baseline correction steps — baseline_lambda","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/baseline_lambda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for baseline correction steps — baseline_lambda","text":"","code":"baseline_lambda() #> Baseline Smoothness (lambda) (quantitative) #> Transformer: log-10 [1e-100, Inf] #> Range (transformed scale): [2, 9] baseline_asymmetry() #> Baseline Asymmetry (p) (quantitative) #> Range: [0.001, 0.1] baseline_degree() #> Baseline Polynomial Degree (quantitative) #> Range: [1, 6] baseline_span() #> LOESS Span (quantitative) #> Range: [0.1, 0.9]"},{"path":"https://jameshwade.github.io/measure/dev/reference/bin_width.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for feature engineering and scatter correction — bin_width","title":"Parameters for feature engineering and scatter correction — bin_width","text":"bin_width() controls width bins spectral binning. emsc_degree() controls polynomial degree EMSC correction. osc_n_components() controls number orthogonal components OSC.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/bin_width.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for feature engineering and scatter correction — bin_width","text":"","code":"bin_width(range = c(1, 20), trans = NULL)  emsc_degree(range = c(0L, 4L), trans = NULL)  osc_n_components(range = c(1L, 10L), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/bin_width.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for feature engineering and scatter correction — bin_width","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/bin_width.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for feature engineering and scatter correction — bin_width","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/bin_width.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for feature engineering and scatter correction — bin_width","text":"","code":"bin_width() #> Bin Width (quantitative) #> Range: [1, 20] emsc_degree() #> EMSC Polynomial Degree (quantitative) #> Range: [0, 4] osc_n_components() #> Number of OSC Components (quantitative) #> Range: [1, 10]"},{"path":"https://jameshwade.github.io/measure/dev/reference/check_axis_consistency.html","id":null,"dir":"Reference","previous_headings":"","what":"Check axis consistency across samples — check_axis_consistency","title":"Check axis consistency across samples — check_axis_consistency","text":"Validates samples measure_list consistent axes (locations). important matrix operations assume aligned data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_axis_consistency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check axis consistency across samples — check_axis_consistency","text":"","code":"check_axis_consistency(   x,   tolerance = 1e-10,   action = c(\"error\", \"warn\", \"message\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/check_axis_consistency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check axis consistency across samples — check_axis_consistency","text":"x measure_list data frame measure column. tolerance Numeric tolerance location comparison. Default 1e-10. action validation fails: \"error\" (default), \"warn\", \"message\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_axis_consistency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check axis consistency across samples — check_axis_consistency","text":"Invisibly returns list : consistent: Logical indicating axes consistent reference_locations: reference locations (first sample) inconsistent_samples: Indices samples different axes max_deviation: Maximum deviation reference locations","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_axis_consistency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check axis consistency across samples — check_axis_consistency","text":"","code":"# Consistent axes specs <- new_measure_list(list(   new_measure_tbl(location = 1:10, value = rnorm(10)),   new_measure_tbl(location = 1:10, value = rnorm(10)) )) check_axis_consistency(specs)  # Inconsistent axes specs_bad <- new_measure_list(list(   new_measure_tbl(location = 1:10, value = rnorm(10)),   new_measure_tbl(location = 1:11, value = rnorm(11)) )) try(check_axis_consistency(specs_bad)) #> Error in check_axis_consistency(specs_bad) :  #>   1 of 2 samples have inconsistent axes #> ℹ Use `step_measure_resample()` or `step_measure_interpolate()` to align axes."},{"path":"https://jameshwade.github.io/measure/dev/reference/check_for_measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for Measure Columns — check_for_measure","title":"Check for Measure Columns — check_for_measure","text":"Validates data contains measure columns (columns class measure_list). Aborts informative error measure columns found.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_for_measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for Measure Columns — check_for_measure","text":"","code":"check_for_measure(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/check_for_measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for Measure Columns — check_for_measure","text":"x data frame tibble check.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_for_measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for Measure Columns — check_for_measure","text":"Invisibly returns names measure columns found.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Measure Recipe Structure — check_measure_recipe","title":"Check Measure Recipe Structure — check_measure_recipe","text":"Validates recipe properly structured measure operations. Checks common issues like missing input steps, incompatible column types, role conflicts.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Measure Recipe Structure — check_measure_recipe","text":"","code":"check_measure_recipe(recipe, strict = TRUE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Measure Recipe Structure — check_measure_recipe","text":"recipe recipe object validate. strict Logical. TRUE (default), returns errors tibble. FALSE, issues cli warnings returns recipe invisibly.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Measure Recipe Structure — check_measure_recipe","text":"strict = TRUE, returns tibble columns: level Severity: \"error\", \"warning\", \"info\" check Name check triggered message message Description issue strict = FALSE, returns recipe invisibly printing warnings.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check Measure Recipe Structure — check_measure_recipe","text":"following checks performed: Errors (cause failures): input step (step_measure_input_*) Output step input step Multiple input steps Warnings (may cause issues): output step (data stays internal format) Processing steps output step predictor columns identified Info (suggestions): Large number measurement columns (consider dimension reduction) ID column identified","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/check_measure_recipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Measure Recipe Structure — check_measure_recipe","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes)  # Check a properly structured recipe rec <- recipe(outcome ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_snv() |>   step_measure_output_wide()  check_measure_recipe(rec)  # Check a recipe with issues bad_rec <- recipe(outcome ~ ., data = my_data) |>   step_measure_snv()  # Missing input step!  check_measure_recipe(bad_rec) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/criteria_presets.html","id":null,"dir":"Reference","previous_headings":"","what":"Preset Acceptance Criteria — criteria_presets","title":"Preset Acceptance Criteria — criteria_presets","text":"Factory functions return commonly-used criteria sets analytical validation workflows.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/criteria_presets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preset Acceptance Criteria — criteria_presets","text":"","code":"criteria_bioanalytical(   cv_qc = 15,   cv_calibration = 20,   r_squared = 0.99,   recovery_range = c(80, 120),   accuracy_bias = 15 )  criteria_ich_q2(   cv_repeatability = 2,   cv_intermediate = 5,   recovery_range = c(98, 102),   r_squared = 0.999 )  criteria_bland_altman(   loa_width = NULL,   bias_max = NULL,   proportional_bias_p = 0.05 )  criteria_method_comparison(   slope_range = c(0.9, 1.1),   intercept_range = NULL,   r_squared = 0.95 )  criteria_proficiency_testing(max_z_score = 2, pct_satisfactory = 100)  criteria_matrix_effects(me_range = c(80, 120), me_cv = 15)  criteria_surrogate_recovery(surrogate_recovery = c(70, 130))"},{"path":"https://jameshwade.github.io/measure/dev/reference/criteria_presets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preset Acceptance Criteria — criteria_presets","text":"cv_qc Maximum allowable CV QC samples (default 15%, bioanalytical). cv_calibration Maximum allowable CV calibration replicates (default 20%). r_squared Minimum R-squared calibration curve. recovery_range Acceptable recovery range c(lower, upper). accuracy_bias Maximum allowable bias (default 15%). cv_repeatability Maximum allowable CV repeatability (default 2%, ICH Q2). cv_intermediate Maximum allowable CV intermediate precision (default 5%, ICH Q2). loa_width Maximum acceptable limits agreement width. bias_max Maximum acceptable mean bias. proportional_bias_p Significance level proportional bias test. slope_range Acceptable range regression slope (default c(0.9, 1.1)). intercept_range Acceptable range regression intercept. max_z_score Maximum acceptable absolute z-score. pct_satisfactory Minimum percentage satisfactory results. me_range Acceptable matrix effect range (default c(80, 120)). me_cv Maximum acceptable CV matrix effects. surrogate_recovery Acceptable surrogate recovery range.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/criteria_presets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preset Acceptance Criteria — criteria_presets","text":"measure_criteria object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/criteria_presets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preset Acceptance Criteria — criteria_presets","text":"","code":"# Default bioanalytical criteria criteria_bioanalytical() #> <measure_criteria> with 5 criteria #>   • QC CV <= 15% #>   • Calibration CV <= 20% #>   • R² >= 0.99 #>   • Recovery 80-120% #>   • Bias within +/-15%  # Custom thresholds criteria_bioanalytical(cv_qc = 20, r_squared = 0.98) #> <measure_criteria> with 5 criteria #>   • QC CV <= 20% #>   • Calibration CV <= 20% #>   • R² >= 0.98 #>   • Recovery 80-120% #>   • Bias within +/-15%"},{"path":"https://jameshwade.github.io/measure/dev/reference/criterion.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Acceptance Criterion — criterion","title":"Create an Acceptance Criterion — criterion","text":"Defines single acceptance criterion analytical validation. Criteria used measure_assess() produce pass/fail decisions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/criterion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Acceptance Criterion — criterion","text":"","code":"criterion(   name,   operator = c(\"<\", \"<=\", \">\", \">=\", \"==\", \"!=\", \"between\", \"outside\"),   threshold,   description = NULL,   priority = c(\"major\", \"critical\", \"minor\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/criterion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Acceptance Criterion — criterion","text":"name Character string naming criterion (e.g., \"cv_qc\", \"r_squared\"). operator Comparison operator: \"<\", \"<=\", \">\", \">=\", \"==\", \"!=\", \"\", \"outside\". threshold Numeric threshold value. \"\" \"outside\", provide length-2 vector c(lower, upper). description Optional human-readable description criterion. priority Optional priority level: \"critical\", \"major\", \"minor\". Affects failures reported.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/criterion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Acceptance Criterion — criterion","text":"measure_criterion object.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/criterion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Acceptance Criterion — criterion","text":"","code":"# QC coefficient of variation must be < 15% criterion(\"cv_qc\", \"<\", 15, description = \"QC CV < 15%\") #> <measure_criterion> #>   cv_qc < 15 #>   Priority: major #>   Description: QC CV < 15%  # R-squared must be >= 0.99 criterion(\"r_squared\", \">=\", 0.99) #> <measure_criterion> #>   r_squared >= 0.99 #>   Priority: major #>   Description: r_squared >= 0.99  # Recovery must be between 80% and 120% criterion(\"recovery\", \"between\", c(80, 120), priority = \"critical\") #> <measure_criterion> #>   recovery between  80120 [80, 120] #>   Priority: critical #>   Description: recovery in [80, 120]"},{"path":"https://jameshwade.github.io/measure/dev/reference/data-organization.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Organization and Role Assignment — data-organization","title":"Data Organization and Role Assignment — data-organization","text":"Functions automatically detecting column types analytical data assigning appropriate roles recipes.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/derivative_order.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for derivative steps — derivative_order","title":"Parameters for derivative steps — derivative_order","text":"derivative_order() controls order differentiation step_measure_derivative() (1 = first derivative, 2 = second derivative). derivative_gap() derivative_segment() control gap derivative (Norris-Williams) parameters step_measure_derivative_gap().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/derivative_order.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for derivative steps — derivative_order","text":"","code":"derivative_order(range = c(1L, 2L), trans = NULL)  derivative_gap(range = c(1L, 10L), trans = NULL)  derivative_segment(range = c(1L, 5L), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/derivative_order.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for derivative steps — derivative_order","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/derivative_order.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for derivative steps — derivative_order","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/derivative_order.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for derivative steps — derivative_order","text":"","code":"derivative_order() #> Derivative Order (quantitative) #> Range: [1, 2] derivative_gap() #> Derivative Gap (quantitative) #> Range: [1, 10] derivative_segment() #> Derivative Segment (quantitative) #> Range: [1, 5]"},{"path":"https://jameshwade.github.io/measure/dev/reference/diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostics and Visualization for Measure Data — diagnostics","title":"Diagnostics and Visualization for Measure Data — diagnostics","text":"Autoplot fortify methods visualizing spectral/chromatographic data recipe transformations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find measure columns in a data frame — find_measure_cols","title":"Find measure columns in a data frame — find_measure_cols","text":"Finds columns data frame contain measurement data (.e., class measure_list).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find measure columns in a data frame — find_measure_cols","text":"","code":"find_measure_cols(data)"},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find measure columns in a data frame — find_measure_cols","text":"data data frame.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find measure columns in a data frame — find_measure_cols","text":"Character vector column names containing measure data. Returns empty character vector measure columns found.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find measure columns in a data frame — find_measure_cols","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  result <- bake(rec, new_data = NULL) find_measure_cols(result)  # \".measures\" #> [1] \".measures\""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_nd_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","title":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","text":"Returns names columns contain measure_nd_list objects.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_nd_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","text":"","code":"find_measure_nd_cols(data)"},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_nd_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","text":"data data frame.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_nd_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","text":"Character vector column names.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_measure_nd_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find n-dimensional measure columns in a data frame — find_measure_nd_cols","text":"","code":"# After using step_measure_input_long with multiple location columns # find_measure_nd_cols(result)"},{"path":"https://jameshwade.github.io/measure/dev/reference/find_peaks_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find peaks columns in a data frame — find_peaks_cols","title":"Find peaks columns in a data frame — find_peaks_cols","text":"Find peaks columns data frame","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_peaks_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find peaks columns in a data frame — find_peaks_cols","text":"","code":"find_peaks_cols(data)"},{"path":"https://jameshwade.github.io/measure/dev/reference/find_peaks_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find peaks columns in a data frame — find_peaks_cols","text":"data data frame.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/find_peaks_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find peaks columns in a data frame — find_peaks_cols","text":"Character vector column names.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify-measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","title":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","text":"methods convert measure objects data frames suitable use ggplot2.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify-measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","text":"","code":"# S3 method for class 'measure_tbl' fortify(model, data = NULL, ...)  # S3 method for class 'measure_list' fortify(model, data = NULL, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify-measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","text":"model measure_tbl measure_list object. data Ignored. Present compatibility generic. ... Additional arguments (currently unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify-measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","text":"tibble columns location value (measure_tbl) location, value, sample (measure_list).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify-measure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Measure Objects to Data Frames for Plotting — fortify-measure","text":"","code":"if (FALSE) { # \\dontrun{ library(ggplot2)  # Single spectrum spec <- new_measure_tbl(location = 1:100, value = rnorm(100)) ggplot(fortify(spec), aes(location, value)) + geom_line()  # Multiple spectra (from recipe output) rec <- recipe(water ~ ., data = meats_long) |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep() baked <- bake(rec, new_data = NULL) ggplot(fortify(baked$.measures), aes(location, value, group = sample)) +   geom_line(alpha = 0.5) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify.measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Calibration Curve Data — fortify.measure_calibration","title":"Extract Calibration Curve Data — fortify.measure_calibration","text":"S3 method extract underlying data calibration object format suitable ggplot2.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify.measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Calibration Curve Data — fortify.measure_calibration","text":"","code":"# S3 method for class 'measure_calibration' fortify(model, data = NULL, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify.measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Calibration Curve Data — fortify.measure_calibration","text":"model measure_calibration object. data Ignored. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/fortify.measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Calibration Curve Data — fortify.measure_calibration","text":"data frame calibration data fitted values/residuals.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_failures.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Failed Criteria — get_failures","title":"Extract Failed Criteria — get_failures","text":"Returns criteria failed assessment.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_failures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Failed Criteria — get_failures","text":"","code":"get_failures(assessment)"},{"path":"https://jameshwade.github.io/measure/dev/reference/get_failures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Failed Criteria — get_failures","text":"assessment measure_assessment object measure_assess().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_failures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Failed Criteria — get_failures","text":"filtered measure_assessment tibble containing failures.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_failures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Failed Criteria — get_failures","text":"","code":"crit <- measure_criteria(cv = 15, rsd = 20) results <- list(cv = 18, rsd = 25)  # Both fail assessment <- measure_assess(results, crit) get_failures(assessment) #> <measure_assessment> [FAIL] #>   0 passed, 2 failed #>  #>   ✗ cv: 18 (<= 15) #>   ✗ rsd: 25 (<= 20)"},{"path":"https://jameshwade.github.io/measure/dev/reference/get_measure_col_ndim.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the dimensionality of a measure column — get_measure_col_ndim","title":"Get the dimensionality of a measure column — get_measure_col_ndim","text":"Returns number dimensions (1 measure_list, 2+ measure_nd_list) measure column data frame.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_measure_col_ndim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the dimensionality of a measure column — get_measure_col_ndim","text":"","code":"get_measure_col_ndim(data, col)"},{"path":"https://jameshwade.github.io/measure/dev/reference/get_measure_col_ndim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the dimensionality of a measure column — get_measure_col_ndim","text":"data data frame. col Character string naming measure column.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_measure_col_ndim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the dimensionality of a measure column — get_measure_col_ndim","text":"Integer indicating number dimensions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_measure_col_ndim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the dimensionality of a measure column — get_measure_col_ndim","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  result <- bake(rec, new_data = NULL) get_measure_col_ndim(result, \".measures\")  # 1 #> [1] 1"},{"path":"https://jameshwade.github.io/measure/dev/reference/get_validation_section.html","id":null,"dir":"Reference","previous_headings":"","what":"Get validation section data — get_validation_section","title":"Get validation section data — get_validation_section","text":"Get validation section data","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_validation_section.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get validation section data — get_validation_section","text":"","code":"get_validation_section(report, section)"},{"path":"https://jameshwade.github.io/measure/dev/reference/get_validation_section.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get validation section data — get_validation_section","text":"report measure_validation_report object. section Section name retrieve.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_validation_section.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get validation section data — get_validation_section","text":"section data, NULL found.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/get_validation_section.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get validation section data — get_validation_section","text":"","code":"report <- measure_validation_report(title = \"Test Report\") get_validation_section(report, \"calibration\")  # NULL #> NULL"},{"path":"https://jameshwade.github.io/measure/dev/reference/glance.measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Glance at Calibration Curve Summary — glance.measure_calibration","title":"Glance at Calibration Curve Summary — glance.measure_calibration","text":"Extract one-row summary statistics calibration curve.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glance.measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glance at Calibration Curve Summary — glance.measure_calibration","text":"","code":"# S3 method for class 'measure_calibration' glance(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/glance.measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glance at Calibration Curve Summary — glance.measure_calibration","text":"x measure_calibration object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glance.measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Glance at Calibration Curve Summary — glance.measure_calibration","text":"tibble columns: r_squared: Coefficient determination adj_r_squared: Adjusted R-squared sigma: Residual standard error df: Degrees freedom model_type: Model type (linear/quadratic) weights_type: Weighting scheme n_points: Number calibration points n_outliers: Number flagged outliers","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glance.measure_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Glance at Calibration Curve Summary — glance.measure_calibration","text":"","code":"data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100),   response = c(0.5, 15.2, 35.8, 72.1, 148.3) ) cal <- measure_calibration_fit(data, response ~ nominal_conc) glance(cal) #> # A tibble: 1 × 8 #>   r_squared adj_r_squared sigma    df model_type weights_type n_points #>       <dbl>         <dbl> <dbl> <int> <chr>      <chr>           <int> #> 1     1.000         1.000  1.26     3 linear     none                5 #> # ℹ 1 more variable: n_outliers <int>"},{"path":"https://jameshwade.github.io/measure/dev/reference/glucose_bioreactors.html","id":null,"dir":"Reference","previous_headings":"","what":"Raman Spectra Bioreactor Data — glucose_bioreactors","title":"Raman Spectra Bioreactor Data — glucose_bioreactors","text":"Kuhn Johnson (2013) used two data sets model glucose yeild large- small-scale bioreactors:","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glucose_bioreactors.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Raman Spectra Bioreactor Data — glucose_bioreactors","text":"Kuhn Johnson (2020), Feature Engineering Selection, Chapman Hall/CRC . https://bookdown.org/max/FES/ https://github.com/topepo/FES","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glucose_bioreactors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raman Spectra Bioreactor Data — glucose_bioreactors","text":"Two tibbles. , 2,651 columns whose names numbers measured assay values (names wave numbers). numeric column glucose outcome data, day number days bioreactor, batch_id reactor identifier (\"L\" large \"S\" small), batch_sample ID day.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glucose_bioreactors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Raman Spectra Bioreactor Data — glucose_bioreactors","text":"Fifteen small-scale (5 liters) bioreactors seeded cells monitored daily 14 days. Three large-scale bioreactors also seeded cells batch monitored daily 14 days. Samples collected day bioreactors glucose measured. goal create models data numerous small-scale bioreactors evaluate results can accurately predict happening large-scale bioreactors.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/glucose_bioreactors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raman Spectra Bioreactor Data — glucose_bioreactors","text":"","code":"data(glucose_bioreactors) dim(bioreactors_small) #> [1]  210 2655"},{"path":"https://jameshwade.github.io/measure/dev/reference/has_measure_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if data frame has measure column(s) — has_measure_col","title":"Check if data frame has measure column(s) — has_measure_col","text":"Checks whether data frame contains least one measure column. recommended way validate data step functions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_measure_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if data frame has measure column(s) — has_measure_col","text":"","code":"has_measure_col(data)"},{"path":"https://jameshwade.github.io/measure/dev/reference/has_measure_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if data frame has measure column(s) — has_measure_col","text":"data data frame.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_measure_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if data frame has measure column(s) — has_measure_col","text":"Invisibly returns names measure columns found. Throws error measure columns found.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_measure_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if data frame has measure column(s) — has_measure_col","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  result <- bake(rec, new_data = NULL) has_measure_col(result)  # TRUE (returns invisibly)"},{"path":"https://jameshwade.github.io/measure/dev/reference/has_validation_section.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if validation report has a section — has_validation_section","title":"Check if validation report has a section — has_validation_section","text":"Check validation report section","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_validation_section.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if validation report has a section — has_validation_section","text":"","code":"has_validation_section(report, section)"},{"path":"https://jameshwade.github.io/measure/dev/reference/has_validation_section.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if validation report has a section — has_validation_section","text":"report measure_validation_report object. section Section name check.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_validation_section.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if validation report has a section — has_validation_section","text":"Logical indicating section exists data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/has_validation_section.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if validation report has a section — has_validation_section","text":"","code":"report <- measure_validation_report(title = \"Test Report\") has_validation_section(report, \"calibration\")  # FALSE #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/reference/hplc_chromatograms.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated HPLC Chromatography Data — hplc_chromatograms","title":"Simulated HPLC Chromatography Data — hplc_chromatograms","text":"Simulated HPLC-UV chromatogram data demonstration chromatographic preprocessing peak analysis. dataset represents separation five phenolic compounds (caffeine, theobromine, catechin, epicatechin, quercetin) 20 samples varying concentrations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/hplc_chromatograms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated HPLC Chromatography Data — hplc_chromatograms","text":"tibble 30,020 observations 8 variables: sample_id Integer sample identifier (1-20) time_min Retention time minutes (0-15, 0.01 min resolution) absorbance_mAU UV absorbance signal milli-absorbance units caffeine_conc True caffeine concentration (mg/L) calibration theobromine_conc True theobromine concentration (mg/L) catechin_conc True catechin concentration (mg/L) epicatechin_conc True epicatechin concentration (mg/L) quercetin_conc True quercetin concentration (mg/L)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/hplc_chromatograms.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated HPLC Chromatography Data — hplc_chromatograms","text":"Simulated data generated measure package. See data-raw/generate_datasets.R generation script.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/hplc_chromatograms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated HPLC Chromatography Data — hplc_chromatograms","text":"chromatograms include realistic features : Gaussian peak shapes compound-specific widths Baseline drift Instrumental noise Small retention time variations runs Concentration-dependent peak heights dataset useful demonstrating: Baseline correction methods Peak detection integration Calibration curve construction Retention time alignment peaks appear approximately retention times: Caffeine: ~2.5 min Theobromine: ~4.2 min Catechin: ~6.8 min Epicatechin: ~9.1 min Quercetin: ~12.3 min","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/hplc_chromatograms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated HPLC Chromatography Data — hplc_chromatograms","text":"","code":"data(hplc_chromatograms)  # View structure str(hplc_chromatograms) #> tibble [30,020 × 8] (S3: tbl_df/tbl/data.frame) #>  $ sample_id       : int [1:30020] 1 1 1 1 1 1 1 1 1 1 ... #>  $ time_min        : num [1:30020] 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 ... #>  $ absorbance_mAU  : num [1:30020] 6.39 7.14 11.21 9.25 5.82 ... #>  $ caffeine_conc   : num [1:30020] 141 141 141 141 141 ... #>  $ theobromine_conc: num [1:30020] 115 115 115 115 115 ... #>  $ catechin_conc   : num [1:30020] 47.2 47.2 47.2 47.2 47.2 ... #>  $ epicatechin_conc: num [1:30020] 93.1 93.1 93.1 93.1 93.1 ... #>  $ quercetin_conc  : num [1:30020] 45.7 45.7 45.7 45.7 45.7 ...  # Get a single chromatogram library(dplyr) chrom_1 <- hplc_chromatograms |> filter(sample_id == 1)  # Plot (if ggplot2 available) if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   ggplot(chrom_1, aes(x = time_min, y = absorbance_mAU)) +     geom_line() +     labs(x = \"Retention Time (min)\", y = \"Absorbance (mAU)\",          title = \"HPLC Chromatogram\") }"},{"path":"https://jameshwade.github.io/measure/dev/reference/infer_axis_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer axis type from location values — infer_axis_type","title":"Infer axis type from location values — infer_axis_type","text":"Attempts infer type measurement axis based range characteristics location values. heuristic helps guide appropriate preprocessing choices.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/infer_axis_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer axis type from location values — infer_axis_type","text":"","code":"infer_axis_type(location)"},{"path":"https://jameshwade.github.io/measure/dev/reference/infer_axis_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer axis type from location values — infer_axis_type","text":"location Numeric vector location values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/infer_axis_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer axis type from location values — infer_axis_type","text":"Character string indicating inferred axis type: \"wavelength_nm\": Visible/NIR wavelengths (typically 300-2500 nm) \"wavenumber\": Mid-IR wavenumbers (typically 400-4000 cm^-1) \"retention_time\": Chromatography retention time (typically 0-60 min) \"mass_charge\": Mass spectrometry m/z (typically 50-2000+) \"ppm\": NMR chemical shift (typically -2 14 ppm) \"two_theta\": XRD diffraction angle (typically 5-90 degrees) \"temperature\": Thermal analysis (typically 20-1000 C) \"unknown\": determine axis type","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/infer_axis_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer axis type from location values — infer_axis_type","text":"","code":"# NIR wavelengths infer_axis_type(seq(1000, 2500, by = 2)) #> [1] \"wavelength_nm\"  # Mid-IR wavenumbers infer_axis_type(seq(4000, 400, by = -4)) #> [1] \"wavenumber\"  # Retention time (minutes) infer_axis_type(seq(0, 30, by = 0.01)) #> [1] \"retention_time\"  # NMR chemical shift infer_axis_type(seq(0, 12, by = 0.001)) #> [1] \"ppm\""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if Object is a Calibration Curve — is_measure_calibration","title":"Test if Object is a Calibration Curve — is_measure_calibration","text":"Test Object Calibration Curve","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if Object is a Calibration Curve — is_measure_calibration","text":"","code":"is_measure_calibration(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if Object is a Calibration Curve — is_measure_calibration","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if Object is a Calibration Curve — is_measure_calibration","text":"Logical: TRUE x measure_calibration object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if Object is a Calibration Curve — is_measure_calibration","text":"","code":"# After fitting a calibration curve data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100),   response = c(0.5, 15.2, 35.8, 72.1, 148.3) ) cal <- measure_calibration_fit(data, response ~ nominal_conc) is_measure_calibration(cal) #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is a measure list — is_measure_list","title":"Test if object is a measure list — is_measure_list","text":"Test object measure list","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is a measure list — is_measure_list","text":"","code":"is_measure_list(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is a measure list — is_measure_list","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is a measure list — is_measure_list","text":"Logical indicating x inherits measure_list.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is a measure list — is_measure_list","text":"","code":"# After using step_measure_input_*, the .measures column is a measure_list library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  result <- bake(rec, new_data = NULL) is_measure_list(result$.measures) #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is an n-dimensional measure list — is_measure_nd_list","title":"Test if object is an n-dimensional measure list — is_measure_nd_list","text":"Test object n-dimensional measure list","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is an n-dimensional measure list — is_measure_nd_list","text":"","code":"is_measure_nd_list(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is an n-dimensional measure list — is_measure_nd_list","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is an n-dimensional measure list — is_measure_nd_list","text":"Logical indicating x inherits measure_nd_list.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is an n-dimensional measure list — is_measure_nd_list","text":"","code":"# Create and test a measure_nd_list meas1 <- new_measure_nd_tbl(   location_1 = 1:5,   location_2 = rep(1, 5),   value = rnorm(5) ) ml <- new_measure_nd_list(list(meas1)) is_measure_nd_list(ml)  # TRUE #> [1] TRUE"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","title":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","text":"Test object n-dimensional measure tibble","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","text":"","code":"is_measure_nd_tbl(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","text":"Logical indicating x inherits measure_nd_tbl.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_nd_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is an n-dimensional measure tibble — is_measure_nd_tbl","text":"","code":"# Create a 2D measure tibble mt <- new_measure_nd_tbl(   location_1 = 1:10,   location_2 = rep(1:2, each = 5),   value = rnorm(10) ) is_measure_nd_tbl(mt)  # TRUE #> [1] TRUE  # Regular tibbles are not measure_nd_tbl is_measure_nd_tbl(tibble::tibble(x = 1:5))  # FALSE #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is a measure tibble — is_measure_tbl","title":"Test if object is a measure tibble — is_measure_tbl","text":"Test object measure tibble","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is a measure tibble — is_measure_tbl","text":"","code":"is_measure_tbl(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is a measure tibble — is_measure_tbl","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is a measure tibble — is_measure_tbl","text":"Logical indicating x inherits measure_tbl.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_measure_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is a measure tibble — is_measure_tbl","text":"","code":"# Create a measure tibble mt <- measure:::new_measure_tbl(location = 1:5, value = rnorm(5)) is_measure_tbl(mt) #> [1] TRUE  # Regular tibbles are not measure tibbles is_measure_tbl(tibble::tibble(location = 1:5, value = rnorm(5))) #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_peaks_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is a peaks list — is_peaks_list","title":"Test if object is a peaks list — is_peaks_list","text":"Test object peaks list","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_peaks_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is a peaks list — is_peaks_list","text":"","code":"is_peaks_list(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/is_peaks_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is a peaks list — is_peaks_list","text":"x Object test.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/is_peaks_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is a peaks list — is_peaks_list","text":"Logical.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/maldi_spectra.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","title":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","text":"Simulated MALDI-TOF (Matrix-Assisted Laser Desorption/Ionization Time--Flight) mass spectrometry data demonstration mass spectral preprocessing. dataset represents protein/peptide analysis four experimental groups four replicates .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/maldi_spectra.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","text":"tibble 304,016 observations 5 variables: sample_id Sample identifier combining group replicate group Experimental group (\"Control\", \"Treatment_A\", \"Treatment_B\", \"Treatment_C\") replicate Replicate number (1-4) mz Mass--charge ratio (m/z) Daltons (1000-20000 Da) intensity Signal intensity (arbitrary units)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/maldi_spectra.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","text":"Simulated data generated measure package. See data-raw/generate_datasets.R generation script.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/maldi_spectra.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","text":"MALDI-TOF soft ionization technique commonly used analyzing biomolecules proteins, peptides, polymers. technique provides mass--charge (m/z) ratios can used identification quantification. spectra include realistic features : Multiple peptide/protein peaks different m/z values Baseline variation Chemical noise Peak width proportional m/z (resolution effects) Replicate variation dataset useful demonstrating: Baseline correction methods Peak detection mass spectra Normalization samples Differential analysis groups group characteristic peak pattern: Control: Peptides m/z ~1200, 1450, 1800, 2200, 3500, 5800, 8400, 12000 Treatment_A: Peptides m/z ~1100, 1650, 2100, 2800, 4200, 6500, 9200, 14000 Treatment_B: Proteins m/z ~2500, 4000, 5500, 8000, 11000, 15000, 18000 Treatment_C: Peptides m/z ~1050, 1280, 1520, 1890, 2340, 2980, 3650, 4500 m/z resolution approximately 500 ppm (parts per million), typical linear MALDI-TOF instruments. Note simulated spectra include baseline noise minor peaks addition characteristic peaks listed .","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/maldi_spectra.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated MALDI-TOF Mass Spectrometry Data — maldi_spectra","text":"","code":"data(maldi_spectra)  # View structure str(maldi_spectra) #> tibble [304,016 × 5] (S3: tbl_df/tbl/data.frame) #>  $ sample_id: chr [1:304016] \"Control_1\" \"Control_1\" \"Control_1\" \"Control_1\" ... #>  $ group    : chr [1:304016] \"Control\" \"Control\" \"Control\" \"Control\" ... #>  $ replicate: int [1:304016] 1 1 1 1 1 1 1 1 1 1 ... #>  $ mz       : num [1:304016] 1000 1001 1002 1003 1004 ... #>  $ intensity: num [1:304016] 33.5 56.6 70.1 31.5 37.2 ...  # Get unique samples unique(maldi_spectra$sample_id) #>  [1] \"Control_1\"     \"Control_2\"     \"Control_3\"     \"Control_4\"     #>  [5] \"Treatment_A_1\" \"Treatment_A_2\" \"Treatment_A_3\" \"Treatment_A_4\" #>  [9] \"Treatment_B_1\" \"Treatment_B_2\" \"Treatment_B_3\" \"Treatment_B_4\" #> [13] \"Treatment_C_1\" \"Treatment_C_2\" \"Treatment_C_3\" \"Treatment_C_4\"  # Get one spectrum library(dplyr) spec_1 <- maldi_spectra |> filter(sample_id == \"Control_1\")  # Plot (if ggplot2 available) if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   ggplot(spec_1, aes(x = mz, y = intensity)) +     geom_line() +     labs(x = \"m/z (Da)\", y = \"Intensity\",          title = \"MALDI-TOF Mass Spectrum\") }   # Compare groups if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   # Get one replicate per group   comparison <- maldi_spectra |>     filter(replicate == 1)    ggplot(comparison, aes(x = mz, y = intensity, color = group)) +     geom_line(alpha = 0.7) +     facet_wrap(~group, ncol = 1) +     labs(x = \"m/z (Da)\", y = \"Intensity\",          title = \"MALDI-TOF Spectra by Group\") }"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":null,"dir":"Reference","previous_headings":"","what":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"measure package provides preprocessing steps analytical measurement data (spectroscopy, chromatography, etc.) within tidymodels framework.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"input-steps","dir":"Reference","previous_headings":"","what":"Input Steps","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Convert raw data measure's internal format: step_measure_input_wide(): data measurements columns step_measure_input_long(): data measurements rows","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"processing-steps","dir":"Reference","previous_headings":"","what":"Processing Steps","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Apply spectral preprocessing transformations: step_measure_savitzky_golay(): Smoothing derivatives step_measure_snv(): Standard Normal Variate normalization step_measure_msc(): Multiplicative Scatter Correction step_measure_map(): Custom transformations","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"sample-wise-normalization","dir":"Reference","previous_headings":"","what":"Sample-wise Normalization","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Normalize spectrum independently: step_measure_normalize_sum(): Divide sum step_measure_normalize_max(): Divide maximum step_measure_normalize_range(): Scale 0-1 range step_measure_normalize_vector(): L2 normalization step_measure_normalize_auc(): Divide area curve step_measure_normalize_peak(): Normalize region (tunable)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"variable-wise-scaling","dir":"Reference","previous_headings":"","what":"Variable-wise Scaling","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Scale across samples location (learns training data): step_measure_center(): Mean centering step_measure_scale_auto(): Z-score normalization step_measure_scale_pareto(): Pareto scaling step_measure_scale_range(): Range scaling step_measure_scale_vast(): VAST scaling","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"output-steps","dir":"Reference","previous_headings":"","what":"Output Steps","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Convert back modeling-ready format: step_measure_output_wide(): Back wide format step_measure_output_long(): Back long format","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"measure: A Recipes-Style Interface to Tidymodels for Analytical Measurements — measure-package","text":"Maintainer: James Wade github@jameshwade.com (ORCID) contributors: Max Kuhn max@posit.co (ORCID) [contributor]","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Accuracy Assessment — measure_accuracy","title":"Accuracy Assessment — measure_accuracy","text":"Calculates accuracy metrics including bias, recovery, confidence intervals method validation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accuracy Assessment — measure_accuracy","text":"","code":"measure_accuracy(   data,   measured_col,   reference_col,   group_col = NULL,   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Accuracy Assessment — measure_accuracy","text":"data data frame containing measured reference values. measured_col Name column containing measured values. reference_col Name column containing reference/nominal values. group_col Optional grouping column (e.g., concentration level). conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Accuracy Assessment — measure_accuracy","text":"measure_accuracy object containing: n: Number observations mean_measured: Mean measured values mean_reference: Mean reference values bias: Absolute bias (measured - reference) bias_pct: Relative bias percentage recovery: Recovery percentage (measured/reference * 100) recovery_ci_lower, recovery_ci_upper: Confidence interval recovery","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Accuracy Assessment — measure_accuracy","text":"Accuracy expresses closeness agreement measured value reference value. typically assessed using: Bias: Systematic difference reference value Recovery: Percentage reference value measured","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"ich-q-requirements","dir":"Reference","previous_headings":"","what":"ICH Q2 Requirements","title":"Accuracy Assessment — measure_accuracy","text":"Accuracy assessed minimum 3 concentration levels covering specified range (typically 80-120% target).","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Accuracy Assessment — measure_accuracy","text":"","code":"# Accuracy at multiple levels set.seed(123) data <- data.frame(   level = rep(c(\"low\", \"mid\", \"high\"), each = 5),   nominal = rep(c(10, 50, 100), each = 5),   measured = c(     rnorm(5, 10.2, 0.3),     rnorm(5, 49.5, 1.5),     rnorm(5, 101, 3)   ) )  result <- measure_accuracy(data, \"measured\", \"nominal\", group_col = \"level\") print(result) #> measure_accuracy #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Group: low  #>   n = 5  #>   Mean measured = 10.26  #>   Mean reference = 10  #>   Bias = 0.2581 ( 2.6 %) #>   Recovery = 103 % #>   Recovery 95% CI: [100%, 106%] #>  #> Group: mid  #>   n = 5  #>   Mean measured = 49.43  #>   Mean reference = 50  #>   Bias = -0.5665 ( -1.1 %) #>   Recovery = 99 % #>   Recovery 95% CI: [95%, 103%] #>  #> Group: high  #>   n = 5  #>   Mean measured = 101.9  #>   Mean reference = 100  #>   Bias = 1.924 ( 1.9 %) #>   Recovery = 102 % #>   Recovery 95% CI: [100%, 104%] #>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a function to measurement data along dimensions — measure_apply","title":"Apply a function to measurement data along dimensions — measure_apply","text":"Central dispatcher enables 1D preprocessing operations work n-dimensional measurement data. 1D data, applies function directly. nD data, slices along specified dimensions, applies function 1D slice, rebuilds nD structure.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a function to measurement data along dimensions — measure_apply","text":"","code":"measure_apply(x, fn, along = 1L, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a function to measurement data along dimensions — measure_apply","text":"x measure_tbl, measure_nd_tbl, measure_list, measure_nd_list object. fn function accepts measure_tbl returns measure_tbl. function signature fn(x, ...). along Integer vector specifying dimensions apply function along. 2D data, along = 1 applies along dimension 1 (e.g., time LC-DAD), treating dimension 2 slices independent. Default 1L (apply along first dimension). ... Additional arguments passed fn.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a function to measurement data along dimensions — measure_apply","text":"object class input, function applied 1D slice.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a function to measurement data along dimensions — measure_apply","text":"measure_apply() function workhorse making 1D preprocessing steps work nD data. handles: 1D data: Direct function application nD data: Slice-apply-rebuild pattern nD data, function extracts 1D slices along specified dimension(s), applies transformation function slice, reassembles result original nD structure.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_apply.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a function to measurement data along dimensions — measure_apply","text":"","code":"# Create a simple 2D measurement m2d <- new_measure_nd_tbl(   location_1 = rep(1:10, each = 3),   location_2 = rep(1:3, times = 10),   value = rnorm(30) )  # Define a simple smoothing function for 1D data smooth_1d <- function(x) {   x$value <- stats::filter(x$value, rep(1/3, 3), sides = 2)   x[!is.na(x$value), ] }  # Apply smoothing along dimension 1 result <- measure_apply(m2d, smooth_1d, along = 1)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_assess.html","id":null,"dir":"Reference","previous_headings":"","what":"Assess Data Against Acceptance Criteria — measure_assess","title":"Assess Data Against Acceptance Criteria — measure_assess","text":"Evaluates set values acceptance criteria returns detailed assessment table pass/fail status.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_assess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assess Data Against Acceptance Criteria — measure_assess","text":"","code":"measure_assess(data, criteria, action = c(\"return\", \"warn\", \"error\"))"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_assess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assess Data Against Acceptance Criteria — measure_assess","text":"data named list data frame containing values assess. Names must match criterion names. criteria measure_criteria() object defining acceptance criteria. action failure: \"return\" (default) returns assessment table, \"warn\" issues warning failures, \"error\" stops critical failures.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_assess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assess Data Against Acceptance Criteria — measure_assess","text":"tibble class measure_assessment containing: criterion: Name criterion value: observed value threshold: threshold value(s) operator: comparison operator pass: Logical indicating pass/fail priority: Priority level criterion description: Human-readable description","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_assess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assess Data Against Acceptance Criteria — measure_assess","text":"","code":"# Define criteria crit <- measure_criteria(   cv_qc = list(\"<\", 15),   r_squared = list(\">=\", 0.99),   recovery = list(\"between\", c(80, 120)) )  # Assess results results <- list(cv_qc = 12.5, r_squared = 0.995, recovery = 98.2) measure_assess(results, crit) #> <measure_assessment> [PASS] #>   3 passed, 0 failed #>  #>   ✓ cv_qc: 12.5 (< 15) #>   ✓ r_squared: 0.995 (>= 0.99) #>   ✓ recovery: 98.2 (between [80, 120])  # Assess with some failures results_bad <- list(cv_qc = 18.3, r_squared = 0.985, recovery = 75) measure_assess(results_bad, crit) #> <measure_assessment> [FAIL] #>   0 passed, 3 failed #>  #>   ✗ cv_qc: 18.3 (< 15) #>   ✗ r_squared: 0.985 (>= 0.99) #>   ✗ recovery: 75 (between [80, 120])"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_axis_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get axis information from measure data — measure_axis_info","title":"Get axis information from measure data — measure_axis_info","text":"Extracts metadata axis (location dimension) measure data, including range, spacing, direction, inferred axis type.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_axis_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get axis information from measure data — measure_axis_info","text":"","code":"measure_axis_info(x, sample = 1L)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_axis_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get axis information from measure data — measure_axis_info","text":"x measure_tbl, measure_list, data frame measure column. sample Integer index sample analyze (measure_list). Default 1.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_axis_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get axis information from measure data — measure_axis_info","text":"list : min, max: Range location values n_points: Number data points spacing: Median absolute spacing points direction: \"increasing\", \"decreasing\", \"mixed\" regular: Logical indicating spacing regular (within tolerance) axis_type: Inferred axis type (see infer_axis_type())","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_axis_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get axis information from measure data — measure_axis_info","text":"","code":"# NIR spectrum spec <- new_measure_tbl(   location = seq(1000, 2500, by = 2),   value = rnorm(751) ) measure_axis_info(spec) #> $min #> [1] 1000 #>  #> $max #> [1] 2500 #>  #> $n_points #> [1] 751 #>  #> $spacing #> [1] 2 #>  #> $direction #> [1] \"increasing\" #>  #> $regular #> [1] TRUE #>  #> $axis_type #> [1] \"wavelength_nm\" #>   # Chromatogram chrom <- new_measure_tbl(   location = seq(0, 30, by = 0.01),   value = rnorm(3001) ) measure_axis_info(chrom) #> $min #> [1] 0 #>  #> $max #> [1] 30 #>  #> $n_points #> [1] 3001 #>  #> $spacing #> [1] 0.01 #>  #> $direction #> [1] \"increasing\" #>  #> $regular #> [1] TRUE #>  #> $axis_type #> [1] \"retention_time\" #>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":null,"dir":"Reference","previous_headings":"","what":"Bland-Altman Method Comparison — measure_bland_altman","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"Performs Bland-Altman analysis compare two measurement methods. calculates mean bias, limits agreement, optionally tests proportional bias.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"","code":"measure_bland_altman(   data,   method1_col,   method2_col,   id_col = NULL,   conf_level = 0.95,   regression = c(\"none\", \"linear\", \"quadratic\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"data data frame containing paired measurements methods. method1_col Name column containing method 1 (reference) values. method2_col Name column containing method 2 (test) values. id_col Optional name column identifying paired observations. conf_level Confidence level intervals. Default 0.95. regression Test proportional bias: \"none\" (default): regression test \"linear\": Test linear trend bias \"quadratic\": Test quadratic trend","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"measure_bland_altman object containing: data: Tibble mean, difference, LOA observation statistics: List summary statistics (bias, SD, LOA, CIs) regression: Regression results requested (model, p-value)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"Bland-Altman plot shows difference methods mean. Key features: Mean bias: Average difference (systematic error) Limits agreement (LOA): Range containing 95% differences Proportional bias: Trend differences concentration","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"acceptance-criteria","dir":"Reference","previous_headings":"","what":"Acceptance Criteria","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"Methods typically considered interchangeable : Mean bias clinically/analytically insignificant LOA width acceptable intended use significant proportional bias","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_bland_altman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bland-Altman Method Comparison — measure_bland_altman","text":"","code":"# Compare two blood glucose meters set.seed(123) data <- data.frame(   patient_id = 1:30,   meter_A = rnorm(30, mean = 100, sd = 15),   meter_B = rnorm(30, mean = 102, sd = 16) )  ba <- measure_bland_altman(   data,   method1_col = \"meter_A\",   method2_col = \"meter_B\",   regression = \"linear\" )  print(ba) #> measure_bland_altman #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Bias Statistics: #>   n = 30  #>   Mean bias = 5.56  #>   SD of differences = 21.38  #>   95% CI for bias: [-2.423, 13.54] #>  #> Limits of Agreement: #>   Lower LOA = -36.34 (95% CI: [ -50.17 ,  -22.51 ]) #>   Upper LOA = 47.46 (95% CI: [ 33.63 ,  61.29 ]) #>   LOA Width = 83.8  #>  #> Proportional Bias Test: #>   Slope = -0.2281  #>   p-value = 0.6087  #>   Result: No significant proportional bias tidy(ba) #> # A tibble: 8 × 2 #>   statistic      value #>   <chr>          <dbl> #> 1 n              30    #> 2 mean_bias       5.56 #> 3 sd_diff        21.4  #> 4 lower_loa     -36.3  #> 5 upper_loa      47.5  #> 6 loa_width      83.8  #> 7 bias_ci_lower  -2.42 #> 8 bias_ci_upper  13.5   # Visualize ggplot2::autoplot(ba) #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibration Curve Object — measure_calibration","title":"Calibration Curve Object — measure_calibration","text":"calibration curve object stores fitted model, diagnostics, metadata quantitation workflows. Created measure_calibration_fit().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration.html","id":"structure","dir":"Reference","previous_headings":"","what":"Structure","title":"Calibration Curve Object — measure_calibration","text":"measure_calibration object list containing: model underlying fitted model (lm object) model_type Character: \"linear\" \"quadratic\" weights_type Character: weighting scheme used formula model formula data calibration data used fitting diagnostics List diagnostic statistics outliers Data frame flagged outliers () call original function call","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Calibration Curve — measure_calibration_fit","title":"Fit a Calibration Curve — measure_calibration_fit","text":"Fits weighted unweighted calibration curve quantitation. Supports linear quadratic models various weighting schemes.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Calibration Curve — measure_calibration_fit","text":"","code":"measure_calibration_fit(   data,   formula,   model = c(\"linear\", \"quadratic\"),   weights = c(\"none\", \"1/x\", \"1/x2\", \"1/y\", \"1/y2\"),   origin = FALSE,   outlier_method = c(\"none\", \"studentized\", \"cook\"),   outlier_threshold = NULL,   outlier_action = c(\"flag\", \"remove\"),   sample_type_col = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Calibration Curve — measure_calibration_fit","text":"data data frame containing calibration data. formula formula specifying model. left-hand side response variable, right-hand side concentration variable (e.g., response ~ nominal_conc). model Model type: \"linear\" (default) \"quadratic\". weights Weighting scheme: \"none\" (default): Unweighted regression \"1/x\": Weight 1/concentration \"1/x2\": Weight 1/concentration^2 \"1/y\": Weight 1/response \"1/y2\": Weight 1/response^2 numeric vector custom weights (must match data rows) origin Logical. TRUE, force curve origin (zero intercept). Default FALSE. outlier_method Method flagging outliers: \"none\" (default): outlier detection \"studentized\": Flag points |studentized residual| > outlier_threshold \"cook\": Flag points Cook's distance > outlier_threshold outlier_threshold Threshold outlier detection. Default 2.5 studentized residuals 1 Cook's distance. outlier_action outliers: \"flag\" (default): Flag include fit \"remove\": Remove fit (audit trail) sample_type_col Optional column name sample type. provided, rows sample_type == \"standard\" used fitting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Calibration Curve — measure_calibration_fit","text":"measure_calibration object containing fitted model, diagnostics, metadata.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"weighting","dir":"Reference","previous_headings":"","what":"Weighting","title":"Fit a Calibration Curve — measure_calibration_fit","text":"Weighting essential response variance changes concentration (heteroscedasticity). Common patterns: Constant CV: Use \"1/x2\" \"1/y2\" Constant absolute error: Use \"none\" Proportional error: Use \"1/x\" \"1/y\"","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"outlier-handling","dir":"Reference","previous_headings":"","what":"Outlier Handling","title":"Fit a Calibration Curve — measure_calibration_fit","text":"default, outliers flagged removed. follows principle \"flag, drop\" analytical data. removal enabled, removed points stored result audit purposes.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Calibration Curve — measure_calibration_fit","text":"","code":"# Simple linear calibration data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100, 200),   response = c(0.5, 15.2, 35.8, 72.1, 148.3, 295.7) ) cal <- measure_calibration_fit(data, response ~ nominal_conc) print(cal) #> <measure_calibration> #>   Model: linear #>   Weighting: none #>   Formula: response ~ nominal_conc #>   N points: 6 #>   R²: 0.99992  # Weighted calibration (1/x^2) cal_weighted <- measure_calibration_fit(   data,   response ~ nominal_conc,   weights = \"1/x2\" )  # Quadratic model cal_quad <- measure_calibration_fit(   data,   response ~ nominal_conc,   model = \"quadratic\" )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Concentrations from Calibration Curve — measure_calibration_predict","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"Uses fitted calibration curve predict concentrations responses.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"","code":"measure_calibration_predict(   object,   newdata,   interval = c(\"none\", \"confidence\", \"prediction\"),   level = 0.95,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"object measure_calibration object measure_calibration_fit(). newdata data frame containing response values predict . Must contain column name response variable calibration formula. interval Type interval calculate: \"none\" (default): Point estimates \"confidence\": Confidence intervals \"prediction\": Prediction intervals level Confidence level intervals (default 0.95). ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"tibble columns: .pred_conc: Predicted concentration .pred_lower: Lower bound (intervals requested) .pred_upper: Upper bound (intervals requested)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"inverse prediction (response -> concentration), function uses root-finding model quadratic. linear models, direct algebraic inversion used.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"interval-calculation","dir":"Reference","previous_headings":"","what":"Interval Calculation","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"Intervals calculated using delta method inverse prediction. quadratic models, intervals approximate.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Concentrations from Calibration Curve — measure_calibration_predict","text":"","code":"# Fit calibration curve cal_data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100),   response = c(0.5, 15.2, 35.8, 72.1, 148.3) ) cal <- measure_calibration_fit(cal_data, response ~ nominal_conc)  # Predict concentrations from new responses unknowns <- data.frame(response = c(45, 85, 120)) measure_calibration_predict(cal, unknowns) #> # A tibble: 3 × 1 #>   .pred_conc #>        <dbl> #> 1       30.6 #> 2       57.7 #> 3       81.4  # With prediction intervals measure_calibration_predict(cal, unknowns, interval = \"prediction\") #> # A tibble: 3 × 3 #>   .pred_conc .pred_lower .pred_upper #>        <dbl>       <dbl>       <dbl> #> 1       30.6        27.7        33.6 #> 2       57.7        54.8        60.7 #> 3       81.4        78.5        84.4"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Calibration Curve Performance — measure_calibration_verify","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"Evaluates performance calibration curve using verification samples (continuing calibration verification - CCV, independent QC samples). function assesses whether calibration remains valid analytical runs.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"","code":"measure_calibration_verify(   calibration,   verification_data,   nominal_col = \"nominal_conc\",   acceptance_pct = 15,   acceptance_pct_lloq = 20,   lloq = NULL,   sample_type_col = NULL,   criteria = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"calibration measure_calibration object measure_calibration_fit(). verification_data data frame containing verification samples known concentrations. nominal_col Name column containing nominal (known) concentrations. Default \"nominal_conc\". acceptance_pct Acceptance criterion percent deviation nominal. Default 15 (.e., ±15%). acceptance_pct_lloq Acceptance criterion samples lower limit quantitation (LLOQ). Default 20 (.e., ±20%). lloq Lower limit quantitation. Samples near level use acceptance_pct_lloq. Default NULL (use criterion ). sample_type_col Optional column indicating sample types. samples type containing \"qc\" \"ccv\" used specified. criteria Optional measure_criteria object custom acceptance criteria. provided, overrides acceptance_pct settings.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"measure_calibration_verify object (tibble) containing: Predicted concentrations Accuracy (%nominal) Deviation nominal (%) Pass/fail status sample Overall verification status","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"verification-workflow","dir":"Reference","previous_headings":"","what":"Verification Workflow","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"Calibration verification typically performed: beginning end analytical batches every N unknown samples (e.g., every 10) instrument performance question","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"acceptance-criteria","dir":"Reference","previous_headings":"","what":"Acceptance Criteria","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"Default criteria based bioanalytical guidelines: Standard samples: ±15% nominal LLOQ samples: ±20% nominal stringent applications (e.g., clinical chemistry), consider using ±10% providing custom criteria.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_calibration_verify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Calibration Curve Performance — measure_calibration_verify","text":"","code":"# Fit calibration cal_data <- data.frame(   nominal_conc = c(1, 5, 10, 50, 100, 500),   response = c(1.2, 5.8, 11.3, 52.1, 105.2, 498.7) ) cal <- measure_calibration_fit(cal_data, response ~ nominal_conc)  # Verify with QC samples qc_data <- data.frame(   sample_id = c(\"QC_Low\", \"QC_Mid\", \"QC_High\"),   nominal_conc = c(3, 75, 400),   response = c(3.3, 77.2, 385.1) )  verify_result <- measure_calibration_verify(cal, qc_data) print(verify_result) #>  #> ── Calibration Verification ──────────────────────────────────────────────────── #> ✖ Overall: FAIL (1/3 samples out of specification) #>  #> ── Sample Results ── #>  #> # A tibble: 3 × 8 #>   sample_id nominal_conc response predicted_conc accuracy_pct deviation_pct #>   <chr>            <dbl>    <dbl>          <dbl>        <dbl>         <dbl> #> 1 QC_Low               3      3.3           1.38         45.9       -54.1   #> 2 QC_Mid              75     77.2          75.6         101.          0.857 #> 3 QC_High            400    385.          385.           96.3        -3.73  #> # ℹ 2 more variables: acceptance_limit <dbl>, pass <lgl>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":null,"dir":"Reference","previous_headings":"","what":"Carryover Assessment — measure_carryover","title":"Carryover Assessment — measure_carryover","text":"Evaluates carryover analyzing blank samples run high-concentration samples.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Carryover Assessment — measure_carryover","text":"","code":"measure_carryover(   data,   response_col,   sample_type_col,   run_order_col,   blank_type = \"blank\",   high_type = \"high\",   threshold = 20,   lloq = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Carryover Assessment — measure_carryover","text":"data data frame containing run sequence blanks highs. response_col Name column containing response values. sample_type_col Name column identifying sample types. run_order_col Name column containing run order. blank_type Value identifying blank samples. Default \"blank\". high_type Value identifying high-concentration samples. Default \"high\". threshold Carryover threshold percentage LLOQ high response. Default 20 (meaning 20% LLOQ). lloq Optional LLOQ value threshold calculation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Carryover Assessment — measure_carryover","text":"measure_carryover object containing: blank_responses: Response values blanks high samples mean_blank: Mean blank response max_blank: Maximum blank response high_responses: High sample responses carryover_pct: Carryover percentage high LLOQ pass: Whether carryover within acceptable limits","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Carryover Assessment — measure_carryover","text":"Carryover appearance analyte blank sample due contamination previous high-concentration sample. typically assessed analyzing blank samples immediately highest calibration standard QC sample.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"acceptance-criteria-ich-m-","dir":"Reference","previous_headings":"","what":"Acceptance Criteria (ICH M10)","title":"Carryover Assessment — measure_carryover","text":"Carryover blank sample following high concentration exceed: 20% LLOQ (analyte) 5% internal standard response","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_carryover.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Carryover Assessment — measure_carryover","text":"","code":"# Carryover assessment data <- data.frame(   run_order = 1:10,   sample_type = c(\"std\", \"std\", \"std\", \"high\", \"blank\",                   \"qc\", \"qc\", \"high\", \"blank\", \"std\"),   response = c(100, 500, 1000, 5000, 5, 500, 510, 4900, 8, 100) )  result <- measure_carryover(   data,   response_col = \"response\",   sample_type_col = \"sample_type\",   run_order_col = \"run_order\",   lloq = 50 ) print(result) #> measure_carryover #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Evaluation: #>   High-blank pairs: 2  #>   Mean high response: 4950  #>   Mean blank response: 6.5  #>   Max blank response: 8  #>  #> Carryover: #>   Reference (LLOQ):50 #>   Carryover: 16 % of LLOQ  #>   Threshold: 20 % #>  #> Result: PASS"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_patterns.html","id":null,"dir":"Reference","previous_headings":"","what":"Common column naming patterns for analytical data — measure_column_patterns","title":"Common column naming patterns for analytical data — measure_column_patterns","text":"Named list regex patterns detecting measurement column types. Used measure_identify_columns() auto-detection. Users can extend modify patterns pass detection functions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_patterns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Common column naming patterns for analytical data — measure_column_patterns","text":"","code":"measure_column_patterns"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_patterns.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Common column naming patterns for analytical data — measure_column_patterns","text":"Named list regex patterns: wavenumber wn_ prefix IR wavenumber (cm^-1) wavelength nm_ prefix wavelength (nm) retention_time rt_ prefix chromatography retention time mz mz_ prefix mass--charge ratio (MS) ppm ppm_ prefix NMR chemical shift channel ch_ prefix numbered channels generic x_ prefix generic/unknown axis","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_patterns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Common column naming patterns for analytical data — measure_column_patterns","text":"","code":"# View default patterns measure_column_patterns #> $wavenumber #> [1] \"^wn_\" #>  #> $wavelength #> [1] \"^nm_\" #>  #> $retention_time #> [1] \"^rt_\" #>  #> $mz #> [1] \"^mz_\" #>  #> $ppm #> [1] \"^ppm_\" #>  #> $channel #> [1] \"^ch_\" #>  #> $generic #> [1] \"^x_\" #>   # Create custom patterns my_patterns <- c(measure_column_patterns, list(custom = \"^my_prefix_\"))"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Column Summary by Type — measure_column_summary","title":"Get Column Summary by Type — measure_column_summary","text":"Summarizes columns detected type, useful understanding structure analytical datasets.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Column Summary by Type — measure_column_summary","text":"","code":"measure_column_summary(data, patterns = measure_column_patterns)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Column Summary by Type — measure_column_summary","text":"data data frame analyze. patterns Named list regex patterns. Defaults measure_column_patterns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Column Summary by Type — measure_column_summary","text":"tibble summarizing detected type: type Column type n_columns Number columns type example_cols First 3 column names type","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_column_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Column Summary by Type — measure_column_summary","text":"","code":"df <- data.frame(   id = 1:5,   wn_1000 = rnorm(5), wn_1001 = rnorm(5), wn_1002 = rnorm(5),   concentration = rnorm(5) ) measure_column_summary(df) #> # A tibble: 2 × 3 #>   type       n_columns example_cols              #>   <chr>          <int> <chr>                     #> 1 wavenumber         3 wn_1000, wn_1001, wn_1002 #> 2 other              2 id, concentration"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Control Chart — measure_control_chart","title":"Generate Control Chart — measure_control_chart","text":"Creates control chart optional multi-rule (Westgard) violation detection.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Control Chart — measure_control_chart","text":"","code":"measure_control_chart(   data,   response_col,   order_col,   limits = NULL,   rules = c(\"1_3s\", \"2_2s\", \"R_4s\", \"4_1s\", \"10x\"),   group_col = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Control Chart — measure_control_chart","text":"data data frame containing QC measurements. response_col Name column containing QC values. order_col Name column containing run order/sequence. limits Optional measure_control_limits object. NULL, calculated data. rules Character vector Westgard rules apply. Default c(\"1_3s\", \"2_2s\", \"R_4s\", \"4_1s\", \"10x\"). group_col Optional grouping column.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Control Chart — measure_control_chart","text":"measure_control_chart object containing: data: input data added violation flags limits: control limits used violations: Summary rule violations rules_applied: rules checked","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"westgard-rules","dir":"Reference","previous_headings":"","what":"Westgard Rules","title":"Generate Control Chart — measure_control_chart","text":"function supports common Westgard multi-rules: 1:3s: One point beyond 3 sigma (action required) 2:2s: Two consecutive points beyond 2 sigma (warning) R:4s: Range two consecutive points > 4 sigma 4:1s: Four consecutive points beyond 1 sigma (side) 10x: Ten consecutive points side mean","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Generate Control Chart — measure_control_chart","text":"Violations flagged specific rule triggered Multiple rules can triggered point run considered \"control\" violations detected","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_chart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Control Chart — measure_control_chart","text":"","code":"# Generate control chart with Westgard rules set.seed(123) qc_data <- data.frame(   run_order = 1:50,   qc_value = c(rnorm(45, 100, 2), rnorm(5, 106, 2))  # Last 5 shifted ) chart <- measure_control_chart(qc_data, \"qc_value\", \"run_order\") print(chart) #> measure_control_chart #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Observations: 50  #> Rules applied: 1_3s, 2_2s, R_4s, 4_1s, 10x  #> Violations detected: 5  #>  #> Status: OUT OF CONTROL #>  #> Violation summary: #> # A tibble: 5 × 3 #>   run_order qc_value violation      #>       <int>    <dbl> <chr>          #> 1        46     104. 4:1s           #> 2        47     105. 4:1s 4:1s      #> 3        48     105. 4:1s 4:1s      #> 4        49     108. 2:2s 4:1s 4:1s #> 5        50     106. 2:2s 4:1s"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Control Limits — measure_control_limits","title":"Calculate Control Limits — measure_control_limits","text":"Calculates control limits quality control monitoring using Shewhart rules optionally EWMA CUSUM statistics.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Control Limits — measure_control_limits","text":"","code":"measure_control_limits(   data,   response_col,   group_col = NULL,   type = c(\"shewhart\", \"ewma\", \"cusum\"),   n_sigma = 3,   target = NULL,   lambda = 0.2,   k = 0.5,   h = 5 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Control Limits — measure_control_limits","text":"data data frame containing QC measurements. response_col Name column containing QC values. group_col Optional grouping column (e.g., different QC levels). type Type control chart: \"shewhart\" (default), \"ewma\", \"cusum\". n_sigma Number standard deviations control limits. Default 3. target Optional target value. NULL, calculated data mean. lambda EWMA smoothing parameter (0 < lambda <= 1). Default 0.2. k CUSUM slack parameter. Default 0.5 (sigma units). h CUSUM decision interval. Default 5 (sigma units).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Control Limits — measure_control_limits","text":"measure_control_limits object containing: center: Center line (target mean) lcl: Lower control limit ucl: Upper control limit lwl: Lower warning limit (2 sigma) uwl: Upper warning limit (2 sigma) sigma: Estimated standard deviation Additional statistics depending chart type","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"shewhart-charts","dir":"Reference","previous_headings":"","what":"Shewhart Charts","title":"Calculate Control Limits — measure_control_limits","text":"Classic control charts limits mean +/- n*sigma: UCL/LCL: Action limits (typically 3 sigma) UWL/LWL: Warning limits (typically 2 sigma)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"ewma-charts","dir":"Reference","previous_headings":"","what":"EWMA Charts","title":"Calculate Control Limits — measure_control_limits","text":"Exponentially weighted moving average, sensitive small shifts: Control limits narrow data collected Lambda parameter controls weight recent observations","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"cusum-charts","dir":"Reference","previous_headings":"","what":"CUSUM Charts","title":"Calculate Control Limits — measure_control_limits","text":"Cumulative sum chart detecting persistent shifts: Upper lower CUSUM statistics track cumulative deviations Decision interval h determines sensitivity","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_control_limits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Control Limits — measure_control_limits","text":"","code":"# Calculate Shewhart control limits set.seed(123) qc_data <- data.frame(   run_order = 1:30,   qc_value = rnorm(30, mean = 100, sd = 2) ) limits <- measure_control_limits(qc_data, \"qc_value\") print(limits) #> measure_control_limits: shewhart chart #> ────────────────────────────────────────────────────────────────────────────────  #>  #>   n = 30  #>   Center = 99.91  #>   Sigma = 1.962  #>   UCL (+3s) = 105.8  #>   UWL (+2s) = 103.8  #>   LWL (-2s) = 95.98  #>   LCL (-3s) = 94.02  #>   # EWMA control limits limits_ewma <- measure_control_limits(qc_data, \"qc_value\", type = \"ewma\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_criteria.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Set of Acceptance Criteria — measure_criteria","title":"Create a Set of Acceptance Criteria — measure_criteria","text":"Combines multiple criterion() objects criteria set use measure_assess().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_criteria.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Set of Acceptance Criteria — measure_criteria","text":"","code":"measure_criteria(..., .list = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_criteria.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Set of Acceptance Criteria — measure_criteria","text":"... criterion() objects named arguments converted criteria. Named arguments use format name = list(operator, threshold) name = threshold (assumes \"<=\"). .list Optional list criterion objects.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_criteria.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Set of Acceptance Criteria — measure_criteria","text":"measure_criteria object (list measure_criterion objects).","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_criteria.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Set of Acceptance Criteria — measure_criteria","text":"","code":"# Using criterion() objects measure_criteria(   criterion(\"cv_qc\", \"<\", 15),   criterion(\"r_squared\", \">=\", 0.99),   criterion(\"recovery\", \"between\", c(80, 120)) ) #> <measure_criteria> with 3 criteria #>   • cv_qc < 15 #>   • r_squared >= 0.99 #>   • recovery in [80, 120]  # Using shorthand notation measure_criteria(   cv_qc = list(\"<\", 15),   r_squared = list(\">=\", 0.99),   bias = list(\"between\", c(-10, 10)) ) #> <measure_criteria> with 3 criteria #>   • cv_qc < 15 #>   • r_squared >= 0.99 #>   • bias in [-10, 10]  # Simple threshold (assumes \"<=\") measure_criteria(   cv = 15,       # cv <= 15   rsd = 20       # rsd <= 20 ) #> <measure_criteria> with 2 criteria #>   • cv <= 15 #>   • rsd <= 20"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Deming Regression for Method Comparison — measure_deming_regression","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"Performs Deming regression compare two measurement methods measurement error. preferred ordinary least squares methods non-negligible error.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"","code":"measure_deming_regression(   data,   method1_col,   method2_col,   error_ratio = NULL,   method1_sd = NULL,   method2_sd = NULL,   bootstrap = FALSE,   bootstrap_n = 1000,   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"data data frame containing paired measurements. method1_col Name column method 1 (typically reference/comparator). method2_col Name column method 2 (typically test method). error_ratio Ratio error variances (var_method2 / var_method1). Default 1 (equal variances). Can estimated replicate data. method1_sd Optional known SD method 1. Used calculate error_ratio. method2_sd Optional known SD method 2. Used calculate error_ratio. bootstrap Use bootstrap confidence intervals? Default FALSE. bootstrap_n Number bootstrap samples. Default 1000. conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"measure_deming_regression object containing: coefficients: Tibble intercept slope estimates CIs statistics: List diagnostic statistics (RMSE, R-squared) data_summary: Summary input data bootstrap: Bootstrap results requested","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"error-ratio","dir":"Reference","previous_headings":"","what":"Error Ratio","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"error ratio (lambda) represents ratio error variances: lambda = var(method2) / var(method1) Common approaches: lambda = 1: Assume equal error variances Estimate replicates: Use SDs replicate measurements Estimate calibration: Use known method precision data","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"equivalent methods: Slope close 1 (proportional agreement) Intercept close 0 (constant bias) 95% CI slope includes 1 CI intercept includes 0, methods considered equivalent.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"mcr package available, used fitting. Otherwise, manual implementation used optional bootstrap CIs.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_deming_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deming Regression for Method Comparison — measure_deming_regression","text":"","code":"# Method comparison data data <- data.frame(   reference = c(5.2, 10.5, 15.8, 25.3, 50.1, 75.4, 100.2),   new_method = c(5.1, 10.8, 16.2, 25.9, 49.8, 76.1, 101.3) )  # Deming regression with bootstrap CIs result <- measure_deming_regression(   data,   method1_col = \"reference\",   method2_col = \"new_method\",   bootstrap = TRUE,   bootstrap_n = 500 ) #> Using default error ratio of 1. Provide `error_ratio` or SDs for more accurate #> results.  print(result) #> measure_deming_regression #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Coefficients: #> # A tibble: 2 × 4 #>   term      estimate ci_lower ci_upper #>   <chr>        <dbl>    <dbl>    <dbl> #> 1 intercept   0.0594   -0.359    0.447 #> 2 slope       1.01      0.988    1.03  #>  #> Statistics: #>   n = 7  #>   Error ratio = 1  #>   RMSE = 0.3508  #>   R² = 0.9999  #>  #> (Fitted using mcr package) tidy(result) #> # A tibble: 2 × 4 #>   term      estimate ci_lower ci_upper #>   <chr>        <dbl>    <dbl>    <dbl> #> 1 intercept   0.0594   -0.359    0.447 #> 2 slope       1.01      0.988    1.03"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_detect_drift.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Drift in Analytical Data — measure_detect_drift","title":"Detect Drift in Analytical Data — measure_detect_drift","text":"Detects significant drift feature responses across run order using trend tests /slope analysis.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_detect_drift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Drift in Analytical Data — measure_detect_drift","text":"","code":"measure_detect_drift(   data,   features,   run_order_col = \"run_order\",   sample_type_col = \"sample_type\",   qc_type = NULL,   method = c(\"slope\", \"mann_kendall\", \"both\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_detect_drift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Drift in Analytical Data — measure_detect_drift","text":"data data frame containing measurement data. features Character vector feature column names analyze. run_order_col Name run order column. sample_type_col Name sample type column. qc_type Value(s) identifying QC samples. provided, analysis restricted QC samples. method Detection method: \"slope\" (default): Linear regression slope test \"mann_kendall\": Mann-Kendall trend test \"\": methods","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_detect_drift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Drift in Analytical Data — measure_detect_drift","text":"tibble drift statistics feature: feature: Feature name slope: Regression slope (change per run) slope_pvalue: P-value slope != 0 percent_change: Total percent change run significant: Logical, TRUE drift statistically significant","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_detect_drift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Drift in Analytical Data — measure_detect_drift","text":"","code":"# Create data with drift data <- data.frame(   sample_type = rep(\"qc\", 20),   run_order = 1:20,   feature1 = 100 + (1:20) * 0.5 + rnorm(20, sd = 2),   feature2 = 50 + rnorm(20, sd = 1)  # No drift )  measure_detect_drift(data, c(\"feature1\", \"feature2\")) #> # A tibble: 2 × 5 #>   feature    slope slope_pvalue percent_change significant #>   <chr>      <dbl>        <dbl>          <dbl> <lgl>       #> 1 feature1 0.351       0.000331         6.34   TRUE        #> 2 feature2 0.00136     0.973            0.0519 FALSE"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimension names of an n-dimensional measurement — measure_dim_names","title":"Get dimension names of an n-dimensional measurement — measure_dim_names","text":"Returns semantic names dimension (e.g., \"wavelength\", \"retention_time\").","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimension names of an n-dimensional measurement — measure_dim_names","text":"","code":"measure_dim_names(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimension names of an n-dimensional measurement — measure_dim_names","text":"x measure_nd_tbl measure_nd_list object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimension names of an n-dimensional measurement — measure_dim_names","text":"Character vector dimension names, NULL set.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimension names of an n-dimensional measurement — measure_dim_names","text":"","code":"m2d <- new_measure_nd_tbl(   location_1 = 1:10,   location_2 = rep(1:2, each = 5),   value = rnorm(10),   dim_names = c(\"retention_time\", \"wavelength\") ) measure_dim_names(m2d) #> [1] \"retention_time\" \"wavelength\""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_units.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimension units of an n-dimensional measurement — measure_dim_units","title":"Get dimension units of an n-dimensional measurement — measure_dim_units","text":"Returns units dimension (e.g., \"nm\", \"min\").","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_units.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimension units of an n-dimensional measurement — measure_dim_units","text":"","code":"measure_dim_units(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_units.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimension units of an n-dimensional measurement — measure_dim_units","text":"x measure_nd_tbl measure_nd_list object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_units.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimension units of an n-dimensional measurement — measure_dim_units","text":"Character vector dimension units, NULL set.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_dim_units.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimension units of an n-dimensional measurement — measure_dim_units","text":"","code":"m2d <- new_measure_nd_tbl(   location_1 = 1:10,   location_2 = rep(1:2, each = 5),   value = rnorm(10),   dim_units = c(\"min\", \"nm\") ) measure_dim_units(m2d) #> [1] \"min\" \"nm\""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_fold.html","id":null,"dir":"Reference","previous_headings":"","what":"Fold 1D measurement back to n-dimensional — measure_fold","title":"Fold 1D measurement back to n-dimensional — measure_fold","text":"Reconstructs n-dimensional measurement 1D vector created measure_unfold(). Requires fold metadata attribute.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_fold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fold 1D measurement back to n-dimensional — measure_fold","text":"","code":"measure_fold(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_fold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fold 1D measurement back to n-dimensional — measure_fold","text":"x measure_tbl measure_list \"fold_info\" attribute.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_fold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fold 1D measurement back to n-dimensional — measure_fold","text":"measure_nd_tbl measure_nd_list original dimensional structure restored.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_fold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fold 1D measurement back to n-dimensional — measure_fold","text":"","code":"# Create, unfold, then fold back m2d <- new_measure_nd_tbl(   location_1 = rep(1:3, each = 4),   location_2 = rep(1:4, times = 3),   value = 1:12 )  m1d <- measure_unfold(m2d) m2d_restored <- measure_fold(m1d)  # Values are preserved all.equal(m2d$value, m2d_restored$value) #> [1] \"Mean relative difference: 0.4923077\""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":null,"dir":"Reference","previous_headings":"","what":"Gage R&R (Measurement System Analysis) — measure_gage_rr","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"Performs Gage Repeatability Reproducibility study assess measurement system variation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"","code":"measure_gage_rr(   data,   response_col,   part_col,   operator_col,   tolerance = NULL,   conf_level = 0.95,   k = 5.15 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"data data frame containing Gage R&R study data. response_col Name column containing measurements. part_col Name column identifying parts/samples. operator_col Name column identifying operators/analysts. tolerance Optional specification tolerance calculating %Study variation %Tolerance. conf_level Confidence level. Default 0.95. k Multiplier study variation calculation. Default 5.15 (99%).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"measure_gage_rr object containing: Variance components (Repeatability, Reproducibility, Part--Part) %Contribution component %Study Variation (using k * sigma) %Tolerance (tolerance provided) Number distinct categories (ndc)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"Gage R&R decomposes total measurement variation : Repeatability (EV): Equipment variation - variability repeated measurements operator part Reproducibility (AV): Appraiser variation - variability operators measuring parts Part--Part (PV): True variation parts","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"acceptance-criteria-typical-guidelines-","dir":"Reference","previous_headings":"","what":"Acceptance Criteria (typical guidelines)","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"%R&R < 10%: Measurement system acceptable %R&R 10-30%: Measurement system may acceptable depending application %R&R > 30%: Measurement system needs improvement number distinct categories (ndc) >= 5 capable measurement system.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_gage_rr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gage R&R (Measurement System Analysis) — measure_gage_rr","text":"","code":"# Gage R&R study with 10 parts, 3 operators, 2 replicates each set.seed(123) data <- expand.grid(   part = 1:10,   operator = c(\"A\", \"B\", \"C\"),   replicate = 1:2 ) data$measurement <- 50 +   (data$part - 5) * 2 +  # Part-to-part variation   ifelse(data$operator == \"A\", 0.5,          ifelse(data$operator == \"B\", -0.3, 0)) +  # Operator effect   rnorm(nrow(data), 0, 0.5)  # Repeatability  result <- measure_gage_rr(   data,   response_col = \"measurement\",   part_col = \"part\",   operator_col = \"operator\",   tolerance = 20 ) print(result) #> measure_gage_rr: Measurement System Analysis #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Study design: #>   Parts: 10  #>   Operators: 3  #>   Replicates: 2  #>  #> Variance Components: #>   Repeatability: 0.2381 (0.6% contribution) #>   Reproducibility: 0.1875 (0.5% contribution) #>   Total R&R: 0.4256 (1% contribution) #>   Part-to-Part: 36.28 (99% contribution) #>  #> % Study Variation: #>   Repeatability: 8% #>   Reproducibility: 7% #>   Total R&R: 11% #>   Part-to-Part: 99% #>  #> % Tolerance: #>   Repeatability: 13% #>   Reproducibility: 11% #>   Total R&R: 17% #>   Part-to-Part: 155% #>  #> Number of Distinct Categories (ndc): 13  #>  #> Assessment: #>   Measurement system MAY BE ACCEPTABLE (%R&R 10-30%)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_grid_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get grid information for an n-dimensional measurement — measure_grid_info","title":"Get grid information for an n-dimensional measurement — measure_grid_info","text":"Returns detailed information coordinate grid, including unique values per dimension, grid shape, regularity status.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_grid_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get grid information for an n-dimensional measurement — measure_grid_info","text":"","code":"measure_grid_info(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_grid_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get grid information for an n-dimensional measurement — measure_grid_info","text":"x measure_nd_tbl object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_grid_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get grid information for an n-dimensional measurement — measure_grid_info","text":"list components: ndim: Number dimensions dim_names: Semantic dimension names (set) dim_units: Dimension units (set) unique_values: List unique coordinate values per dimension shape: Integer vector unique value counts per dimension n_points: Total number data points is_regular: Whether grid regular has_na: Whether values NA","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_grid_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get grid information for an n-dimensional measurement — measure_grid_info","text":"","code":"m2d <- new_measure_nd_tbl(   location_1 = rep(seq(0, 10, by = 2), each = 4),   location_2 = rep(c(254, 280, 320, 350), times = 6),   value = rnorm(24),   dim_names = c(\"time\", \"wavelength\"),   dim_units = c(\"min\", \"nm\") ) measure_grid_info(m2d) #> $ndim #> [1] 2 #>  #> $dim_names #> [1] \"time\"       \"wavelength\" #>  #> $dim_units #> [1] \"min\" \"nm\"  #>  #> $unique_values #> $unique_values$dim_1 #> [1]  0  2  4  6  8 10 #>  #> $unique_values$dim_2 #> [1] 254 280 320 350 #>  #>  #> $shape #> dim_1 dim_2  #>     6     4  #>  #> $n_points #> [1] 24 #>  #> $is_regular #> [1] TRUE #>  #> $has_na #> [1] FALSE #>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Column Types in Analytical Data — measure_identify_columns","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"Automatically detects column types data frame based naming conventions common analytical chemistry. helps set recipes appropriate roles different column types.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"","code":"measure_identify_columns(data, patterns = measure_column_patterns)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"data data frame analyze. patterns Named list regex patterns column detection. Defaults measure_column_patterns. Custom patterns can provided named list names become detected type.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"tibble columns: column Column name type Detected type (pattern names, \"\" match) suggested_role Suggested recipe role based type n_values Number non-NA values class R class column","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"Column type detection uses following naming conventions: Columns matching pattern classified \"\" suggested either \"outcome\" (numeric), \"id\" (character/factor unique values), \"predictor\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_identify_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify Column Types in Analytical Data — measure_identify_columns","text":"","code":"# Wide format spectral data df <- data.frame(   sample_id = 1:5,   outcome = rnorm(5),   wn_1000 = rnorm(5),   wn_1001 = rnorm(5),   wn_1002 = rnorm(5) ) measure_identify_columns(df) #> # A tibble: 5 × 5 #>   column    type       suggested_role n_values class   #>   <chr>     <chr>      <chr>             <int> <chr>   #> 1 sample_id other      predictor             5 integer #> 2 outcome   other      outcome               5 numeric #> 3 wn_1000   wavenumber predictor             5 numeric #> 4 wn_1001   wavenumber predictor             5 numeric #> 5 wn_1002   wavenumber predictor             5 numeric  # Chromatography data df2 <- data.frame(   id = letters[1:3],   concentration = c(1.2, 2.3, 3.4),   rt_0.5 = rnorm(3),   rt_1.0 = rnorm(3),   rt_1.5 = rnorm(3) ) measure_identify_columns(df2) #> # A tibble: 5 × 5 #>   column        type           suggested_role n_values class     #>   <chr>         <chr>          <chr>             <int> <chr>     #> 1 id            other          id                    3 character #> 2 concentration other          outcome               3 numeric   #> 3 rt_0.5        retention_time predictor             3 numeric   #> 4 rt_1.0        retention_time predictor             3 numeric   #> 5 rt_1.5        retention_time predictor             3 numeric"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"Calculates intermediate precision statistics measurements performed varying conditions (different days, analysts, instruments).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"","code":"measure_intermediate_precision(   data,   response_col,   factors,   group_col = NULL,   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"data data frame containing measurements factor columns. response_col Name column containing response values. factors Character vector factor column names (e.g., c(\"day\", \"analyst\")). group_col Optional grouping column (e.g., concentration level). conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"measure_precision object containing variance components precision estimates: component: Name variance component variance: Estimated variance percent_variance: Percentage total variance sd: Standard deviation (square root variance) cv: Coefficient variation (%) component","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"Intermediate precision quantifies variability due different conditions within laboratory. typically includes: Different days Different analysts Different equipment (type) function uses one-way nested ANOVA approach estimate variance components. complex designs, consider using mixed effects models lme4 package.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_intermediate_precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intermediate Precision (Between-Run Precision) — measure_intermediate_precision","text":"","code":"# Intermediate precision across days set.seed(123) data <- data.frame(   day = rep(1:5, each = 6),   concentration = rnorm(30, mean = 100, sd = 3) +     rep(rnorm(5, 0, 2), each = 6)  # Day effect ) measure_intermediate_precision(data, \"concentration\", factors = \"day\") #> measure_precision: intermediate  #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Variance Components: #>   day: 0 (0%) #>   Residual: 9.311 (100%) #>  #> CV by component: #>   day: 0% #>   Residual: 3%"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_is_regular.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","title":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","text":"regular grid means combinations unique coordinate values exist exactly (.e., forms complete rectangular grid).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_is_regular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","text":"","code":"measure_is_regular(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_is_regular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","text":"x measure_nd_tbl object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_is_regular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","text":"Logical indicating measurement regular grid.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_is_regular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if an n-dimensional measurement has a regular grid — measure_is_regular","text":"","code":"# Regular grid (all combinations present) regular <- new_measure_nd_tbl(   location_1 = rep(1:3, each = 2),   location_2 = rep(1:2, times = 3),   value = rnorm(6) ) measure_is_regular(regular)  # TRUE #> [1] TRUE  # Irregular grid (missing combinations) irregular <- new_measure_nd_tbl(   location_1 = c(1, 1, 2, 3),   location_2 = c(1, 2, 1, 2),   value = rnorm(4) ) measure_is_regular(irregular)  # FALSE #> [1] FALSE"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":null,"dir":"Reference","previous_headings":"","what":"Linearity Assessment — measure_linearity","title":"Linearity Assessment — measure_linearity","text":"Assesses linearity method evaluating relationship response concentration across specified range.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linearity Assessment — measure_linearity","text":"","code":"measure_linearity(   data,   conc_col,   response_col,   method = c(\"regression\", \"residual\"),   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linearity Assessment — measure_linearity","text":"data data frame containing concentration response data. conc_col Name column containing concentrations. response_col Name column containing responses. method Linearity assessment method: \"regression\" (default): Linear regression diagnostics \"residual\": Residual analysis lack--fit test conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linearity Assessment — measure_linearity","text":"measure_linearity object containing: r_squared: Coefficient determination adj_r_squared: Adjusted R-squared slope: Regression slope CI intercept: Regression intercept CI residual_sd: Residual standard deviation lack_of_fit: Lack--fit test results (replicates exist) range: Concentration range evaluated","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linearity Assessment — measure_linearity","text":"Linearity demonstrates method produces results directly proportional analyte concentration within given range.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"assessment-criteria","dir":"Reference","previous_headings":"","what":"Assessment Criteria","title":"Linearity Assessment — measure_linearity","text":"R-squared >= 0.99 (typical many applications) Residuals randomly distributed around zero systematic pattern residual plots Lack--fit test significant (p > 0.05)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"ich-q-requirements","dir":"Reference","previous_headings":"","what":"ICH Q2 Requirements","title":"Linearity Assessment — measure_linearity","text":"Linearity evaluated across range least 5 concentration levels. Report regression equation, correlation coefficient, visual inspection residual plots.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_linearity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linearity Assessment — measure_linearity","text":"","code":"# Linearity assessment set.seed(123) data <- data.frame(   concentration = rep(c(10, 25, 50, 75, 100), each = 3),   response = rep(c(10, 25, 50, 75, 100), each = 3) * 1.5 + rnorm(15, 0, 2) )  result <- measure_linearity(data, \"concentration\", \"response\") print(result) #> measure_linearity #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Data: #>   n = 15 ( 5 levels ) #>   Range: 10 - 100  #>  #> Regression: #>   Slope = 1.493  #>     95% CI: [1.463, 1.523] #>   Intercept = 0.675  #>     95% CI: [-1.147, 2.497] #>  #> Fit Quality: #>   R-squared = 0.9989  #>   Adj. R-squared = 0.99882  #>   Residual SD = 1.737  #>   Residual CV = 2.2 % #>  #> Lack-of-Fit Test: #>   F = 0.877  #>   p-value = 0.4853  #>   Result: Not significant (linearity acceptable)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Limit of Detection (LOD) — measure_lod","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"Calculates limit detection using one several accepted methods. method used explicitly documented output.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"","code":"measure_lod(   data,   response_col,   method = c(\"blank_sd\", \"calibration\", \"sn\", \"precision\"),   conc_col = \"nominal_conc\",   sample_type_col = \"sample_type\",   calibration = NULL,   k = 3,   sn_col = NULL,   noise = NULL,   sn_threshold = 3,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"data data frame containing measurement data. response_col Name response column. method Method LOD calculation: \"blank_sd\": 3 * SD blank samples (requires sample_type == \"blank\") \"calibration\": 3.3 * sigma / slope calibration curve \"sn\": Signal--noise ratio method (requires sn_col noise estimate) \"precision\": Based acceptable precision low concentrations conc_col Name concentration column (calibration method). sample_type_col Name sample type column. Default \"sample_type\". calibration Optional measure_calibration object calibration method. k Multiplier SD. Default 3 LOD. sn_col Column containing S/N ratios (\"sn\" method). noise Noise estimate S/N calculation (alternative sn_col). sn_threshold S/N threshold LOD (default 3). ... Additional arguments passed method-specific calculations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"measure_lod object containing: value: LOD value method: Method used parameters: Method-specific parameters uncertainty: Uncertainty estimate (available)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"blank-sd-method","dir":"Reference","previous_headings":"","what":"Blank SD Method","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"LOD = mean(blank) + k * SD(blank) k typically 3. simple widely accepted approach.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"calibration-method","dir":"Reference","previous_headings":"","what":"Calibration Method","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"LOD = k * sigma / slope sigma residual standard error calibration curve slope calibration slope. k typically 3.3 LOD.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"signal-to-noise-method","dir":"Reference","previous_headings":"","what":"Signal-to-Noise Method","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"LOD concentration S/N = threshold (typically 3:1).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"precision-based-method","dir":"Reference","previous_headings":"","what":"Precision-Based Method","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"LOD lowest concentration precision (CV) meets specified criterion.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Limit of Detection (LOD) — measure_lod","text":"","code":"# Create sample data with blanks data <- data.frame(   sample_type = c(rep(\"blank\", 10), rep(\"standard\", 5)),   response = c(rnorm(10, mean = 0.5, sd = 0.1),                c(5, 15, 35, 70, 150)),   nominal_conc = c(rep(0, 10), c(10, 25, 50, 100, 200)) )  # LOD from blank SD measure_lod(data, \"response\", method = \"blank_sd\") #> <measure_lod> #>   Value: 0.6889 #>   Method: blank_sd #>   k: 3 #>   Uncertainty: 0.08057 #>   Parameters: #>     blank_mean: 0.4341 #>     blank_sd: 0.08493 #>     n_blanks: 10  # LOD from calibration curve cal <- measure_calibration_fit(   data[data$sample_type == \"standard\", ],   response ~ nominal_conc ) measure_lod(data, \"response\", method = \"calibration\", calibration = cal) #> <measure_lod> #>   Value: 7.71 #>   Method: calibration #>   k: 3 #>   Parameters: #>     sigma: 1.783 #>     slope: 0.7634"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod_loq.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate LOD and LOQ Together — measure_lod_loq","title":"Calculate LOD and LOQ Together — measure_lod_loq","text":"Convenience function calculate LOD LOQ using method.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod_loq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate LOD and LOQ Together — measure_lod_loq","text":"","code":"measure_lod_loq(   data,   response_col,   method = c(\"blank_sd\", \"calibration\", \"sn\", \"precision\"),   conc_col = \"nominal_conc\",   sample_type_col = \"sample_type\",   calibration = NULL,   k_lod = NULL,   k_loq = 10,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod_loq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate LOD and LOQ Together — measure_lod_loq","text":"data data frame containing measurement data. response_col Name response column. method Method LOD calculation: \"blank_sd\": 3 * SD blank samples (requires sample_type == \"blank\") \"calibration\": 3.3 * sigma / slope calibration curve \"sn\": Signal--noise ratio method (requires sn_col noise estimate) \"precision\": Based acceptable precision low concentrations conc_col Name concentration column (calibration method). sample_type_col Name sample type column. Default \"sample_type\". calibration Optional measure_calibration object calibration method. k_lod Multiplier LOD (default 3 3.3 calibration). k_loq Multiplier LOQ (default 10). ... Additional arguments passed method-specific calculations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod_loq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate LOD and LOQ Together — measure_lod_loq","text":"list components lod loq, respective limit object.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_lod_loq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate LOD and LOQ Together — measure_lod_loq","text":"","code":"data <- data.frame(   sample_type = c(rep(\"blank\", 10), rep(\"standard\", 5)),   response = c(rnorm(10, mean = 0.5, sd = 0.1),                c(5, 15, 35, 70, 150)),   nominal_conc = c(rep(0, 10), c(10, 25, 50, 100, 200)) )  limits <- measure_lod_loq(data, \"response\", method = \"blank_sd\") limits$lod #> <measure_lod> #>   Value: 0.752 #>   Method: blank_sd #>   k: 3 #>   Uncertainty: 0.06627 #>   Parameters: #>     blank_mean: 0.5424 #>     blank_sd: 0.06986 #>     n_blanks: 10 limits$loq #> <measure_loq> #>   Value: 1.241 #>   Method: blank_sd #>   k: 10 #>   Uncertainty: 0.2209 #>   Parameters: #>     blank_mean: 0.5424 #>     blank_sd: 0.06986 #>     n_blanks: 10"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Limit of Quantitation (LOQ) — measure_loq","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"Calculates limit quantitation using one several accepted methods. method used explicitly documented output.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"","code":"measure_loq(   data,   response_col,   method = c(\"blank_sd\", \"calibration\", \"sn\", \"precision\"),   conc_col = \"nominal_conc\",   sample_type_col = \"sample_type\",   calibration = NULL,   k = 10,   sn_col = NULL,   noise = NULL,   sn_threshold = 10,   precision_cv = 20,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"data data frame containing measurement data. response_col Name response column. method Method LOD calculation: \"blank_sd\": 3 * SD blank samples (requires sample_type == \"blank\") \"calibration\": 3.3 * sigma / slope calibration curve \"sn\": Signal--noise ratio method (requires sn_col noise estimate) \"precision\": Based acceptable precision low concentrations conc_col Name concentration column (calibration method). sample_type_col Name sample type column. Default \"sample_type\". calibration Optional measure_calibration object calibration method. k Multiplier SD. Default 10 LOQ. sn_col Column containing S/N ratios (\"sn\" method). noise Noise estimate S/N calculation (alternative sn_col). sn_threshold S/N threshold LOQ (default 10). precision_cv Maximum allowable CV LOQ (default 20%). ... Additional arguments passed method-specific calculations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"measure_loq object containing: value: LOQ value method: Method used parameters: Method-specific parameters uncertainty: Uncertainty estimate (available)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"blank-sd-method","dir":"Reference","previous_headings":"","what":"Blank SD Method","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"LOQ = mean(blank) + k * SD(blank) k typically 10. simple widely accepted approach.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"calibration-method","dir":"Reference","previous_headings":"","what":"Calibration Method","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"LOQ = k * sigma / slope sigma residual standard error calibration curve slope calibration slope. k typically 10 LOQ.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"signal-to-noise-method","dir":"Reference","previous_headings":"","what":"Signal-to-Noise Method","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"LOQ concentration S/N = threshold (typically 10:1).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"precision-based-method","dir":"Reference","previous_headings":"","what":"Precision-Based Method","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"LOQ lowest concentration precision (CV) <= specified criterion (typically 20% bioanalytical methods).","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_loq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Limit of Quantitation (LOQ) — measure_loq","text":"","code":"# Create sample data with blanks data <- data.frame(   sample_type = c(rep(\"blank\", 10), rep(\"standard\", 5)),   response = c(rnorm(10, mean = 0.5, sd = 0.1),                c(5, 15, 35, 70, 150)),   nominal_conc = c(rep(0, 10), c(10, 25, 50, 100, 200)) )  # LOQ from blank SD measure_loq(data, \"response\", method = \"blank_sd\") #> <measure_loq> #>   Value: 1.537 #>   Method: blank_sd #>   k: 10 #>   Uncertainty: 0.3326 #>   Parameters: #>     blank_mean: 0.4853 #>     blank_sd: 0.1052 #>     n_blanks: 10"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a Function to Each Sample's Measurements — measure_map","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"measure_map() applies function sample's measurement data. function intended exploration prototyping, production pipelines. reproducible preprocessing, use step_measure_map() instead.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"","code":"measure_map(   .data,   .f,   .cols = NULL,   ...,   verbosity = 1L,   .error_call = rlang::caller_env() )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a Function to Each Sample's Measurements — measure_map","text":".data data frame containing one measure_list columns. .f function formula apply sample's measurement tibble. function, used -. formula (e.g., ~ { .x$value <- log(.x$value); .x }), converted function using rlang::as_function(). .cols <tidy-select> Columns apply transformation . Defaults measure_list columns. ... Additional arguments passed .f. verbosity integer controlling output verbosity: 0: Silent - suppress messages output .f 1: Normal (default) - show output .f .error_call execution environment error reporting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"data frame specified measure columns transformed.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"intended-use-exploration-not-production","dir":"Reference","previous_headings":"","what":"Intended Use: Exploration, Not Production","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"function designed interactive exploration debugging:   Unlike recipe steps, transformations applied measure_map() : Automatically applied new data Bundled workflows Reproducible across sessions","code":"# Good: Prototyping a new transformation baked_data |>   measure_map(~ { .x$value <- my_experimental_fn(.x$value); .x })  # Better: Once it works, put it in a recipe step recipe(...) |>   step_measure_map(my_experimental_fn) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"function-requirements","dir":"Reference","previous_headings":"","what":"Function Requirements","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"function .f must: Accept tibble location value columns Return tibble location value columns change number rows","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a Function to Each Sample's Measurements — measure_map","text":"","code":"library(recipes)  # First, get data in internal format rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  baked_data <- bake(rec, new_data = NULL)  # Explore a custom transformation result <- measure_map(baked_data, ~ {   # Subtract the minimum value from each spectrum   .x$value <- .x$value - min(.x$value)   .x })  # Once you're happy with it, use step_measure_map() in your recipe: # recipe(...) |> #   step_measure_map(~ { .x$value <- .x$value - min(.x$value); .x })"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map_safely.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","title":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","text":"measure_map_safely() fault-tolerant version measure_map() captures errors instead stopping execution. useful exploring data may problematic samples.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map_safely.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","text":"","code":"measure_map_safely(   .data,   .f,   .cols = NULL,   ...,   .otherwise = NULL,   .error_call = rlang::caller_env() )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map_safely.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","text":".data data frame containing one measure_list columns. .f function formula apply sample's measurement tibble. function, used -. formula (e.g., ~ { .x$value <- log(.x$value); .x }), converted function using rlang::as_function(). .cols <tidy-select> Columns apply transformation . Defaults measure_list columns. ... Additional arguments passed .f. .otherwise Value use .f fails sample. Default NULL, keeps original (untransformed) measurement. .error_call execution environment error reporting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map_safely.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","text":"list two elements: result: data frame transformations applied successful errors: tibble columns column, sample, error","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_map_safely.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a Function Safely to Each Sample's Measurements — measure_map_safely","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  baked_data <- bake(rec, new_data = NULL)  # A function that might fail for some samples risky_transform <- function(x) {   if (any(x$value < 0)) stop(\"Negative values not allowed\")   x$value <- log(x$value)   x }  # Errors are captured, not thrown result <- measure_map_safely(baked_data, risky_transform)  # Check which samples failed if (nrow(result$errors) > 0) {   print(result$errors) }"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix Effect Analysis — measure_matrix_effect","title":"Matrix Effect Analysis — measure_matrix_effect","text":"Quantifies matrix effects (ion suppression/enhancement) comparing analyte response matrix versus neat solution. essential validating LC-MS/MS analytical methods matrix interference concern.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix Effect Analysis — measure_matrix_effect","text":"","code":"measure_matrix_effect(   data,   response_col,   sample_type_col,   matrix_level,   neat_level,   concentration_col = NULL,   analyte_col = NULL,   group_cols = NULL,   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix Effect Analysis — measure_matrix_effect","text":"data data frame containing response data. response_col Name column containing analyte responses. sample_type_col Name column indicating sample type (matrix vs neat/standard). matrix_level Value sample_type_col indicating matrix samples. neat_level Value sample_type_col indicating neat/standard samples. concentration_col Optional column concentration levels. provided, matrix effects calculated per concentration. analyte_col Optional column analyte names. provided, matrix effects calculated per analyte. group_cols Additional grouping columns (e.g., batch, matrix source). conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix Effect Analysis — measure_matrix_effect","text":"measure_matrix_effect object containing: results: Tibble matrix effect percentages per group statistics: Overall summary statistics raw_data: Data used calculations","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"matrix-effect-calculation","dir":"Reference","previous_headings":"","what":"Matrix Effect Calculation","title":"Matrix Effect Analysis — measure_matrix_effect","text":"Matrix effect (%) calculated : % = (response_in_matrix / response_in_neat) * 100 equivalently: % = 100 + ((response_in_matrix - response_in_neat) / response_in_neat) * 100","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Matrix Effect Analysis — measure_matrix_effect","text":"= 100%: matrix effect > 100%: Ion enhancement < 100%: Ion suppression","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"acceptance-criteria-typical-","dir":"Reference","previous_headings":"","what":"Acceptance Criteria (typical)","title":"Matrix Effect Analysis — measure_matrix_effect","text":"According ICH M10 FDA guidance: 80-120% (±20%) CV ≤15%","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"experimental-design","dir":"Reference","previous_headings":"","what":"Experimental Design","title":"Matrix Effect Analysis — measure_matrix_effect","text":"assess matrix effects: Prepare blank matrix (e.g., plasma) multiple sources Spike analyte post-extraction known concentration Compare analyte neat solvent concentration","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_matrix_effect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix Effect Analysis — measure_matrix_effect","text":"","code":"# Matrix effect study data me_data <- data.frame(   sample_type = rep(c(\"matrix\", \"neat\"), each = 6),   matrix_lot = rep(c(\"Lot1\", \"Lot2\", \"Lot3\", \"Lot1\", \"Lot2\", \"Lot3\"), 2),   concentration = rep(c(\"low\", \"high\"), each = 3, times = 2),   response = c(     # Matrix samples (some suppression)     9500, 9800, 9200, 48000, 49500, 47000,     # Neat samples     10000, 10000, 10000, 50000, 50000, 50000   ) )  me <- measure_matrix_effect(   me_data,   response_col = \"response\",   sample_type_col = \"sample_type\",   matrix_level = \"matrix\",   neat_level = \"neat\",   concentration_col = \"concentration\" )  print(me) #> measure_matrix_effect #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Overall Matrix Effect Summary: #>   Groups evaluated: 2  #>   Mean ME: 96 % #>   SD ME: 0.9 % #>   CV ME: 1 % #>   Range: 95 - 96 % #>  #> Effect Classification: #>   Ion suppression (ME < 100%): 2  #>   Ion enhancement (ME > 100%): 0  #>   Acceptable (80-120%): 2 / 2  tidy(me) #>   concentration n_matrix n_neat mean_matrix_response mean_neat_response #> 1           low        3      3              9500.00              10000 #> 2          high        3      3             48166.67              50000 #>   matrix_effect_pct me_ci_lower me_ci_upper interpretation #> 1          95.00000    87.54759    102.4524    suppression #> 2          96.33333    90.08172    102.5849    suppression"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_ndim.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of dimensions of a measurement — measure_ndim","title":"Get the number of dimensions of a measurement — measure_ndim","text":"Returns dimensionality measurement object. 1D measurements (measure_tbl), returns 1. n-dimensional measurements (measure_nd_tbl), returns number location dimensions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_ndim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of dimensions of a measurement — measure_ndim","text":"","code":"measure_ndim(x)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_ndim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of dimensions of a measurement — measure_ndim","text":"x measure_tbl, measure_nd_tbl, measure_list, measure_nd_list object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_ndim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of dimensions of a measurement — measure_ndim","text":"Integer indicating number dimensions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_ndim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the number of dimensions of a measurement — measure_ndim","text":"","code":"# 1D measurement m1d <- new_measure_tbl(location = 1:10, value = rnorm(10)) measure_ndim(m1d)  # 1 #> [1] 1  # 2D measurement m2d <- new_measure_nd_tbl(   location_1 = rep(1:5, each = 3),   location_2 = rep(1:3, times = 5),   value = rnorm(15) ) measure_ndim(m2d)  # 2 #> [1] 2"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_packs.html","id":null,"dir":"Reference","previous_headings":"","what":"List Registered Technique Packs — measure_packs","title":"List Registered Technique Packs — measure_packs","text":"Returns tibble registered technique packs, including core measure package.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_packs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Registered Technique Packs — measure_packs","text":"","code":"measure_packs()"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_packs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Registered Technique Packs — measure_packs","text":"tibble columns: name: Package name technique: Technique category (e.g., \"general\", \"SEC/GPC\") version: Package version description: Brief description","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_packs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Registered Technique Packs — measure_packs","text":"","code":"measure_packs() #> # A tibble: 1 × 4 #>   name    technique version    description                          #>   <chr>   <chr>     <chr>      <chr>                                #> 1 measure general   0.0.1.9001 Core measurement preprocessing steps"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":null,"dir":"Reference","previous_headings":"","what":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"Performs Passing-Bablok regression, non-parametric method comparing two analytical methods. robust outliers require normal distribution residuals.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"","code":"measure_passing_bablok(   data,   method1_col,   method2_col,   conf_level = 0.95,   alpha = 0.05 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"data data frame containing paired measurements. method1_col Name column method 1 (reference/comparator). method2_col Name column method 2 (test method). conf_level Confidence level intervals. Default 0.95. alpha Significance level CUSUM linearity test. Default 0.05.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"measure_passing_bablok object containing: coefficients: Tibble intercept slope estimates CIs linearity: CUSUM test results linearity assumption statistics: Summary statistics","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"method","dir":"Reference","previous_headings":"","what":"Method","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"Passing-Bablok regression: Calculates slopes pairs points Uses median slope estimate (robust outliers) Calculates intercept median slope Uses non-parametric confidence intervals","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"cusum-linearity-test","dir":"Reference","previous_headings":"","what":"CUSUM Linearity Test","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"Tests assumption linear relationship. significant (p < alpha), linear model may appropriate.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"equivalent methods: 95% CI slope includes 1 95% CI intercept includes 0","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"function requires mcr package. Install : install.packages(\"mcr\")","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_passing_bablok.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Passing-Bablok Regression for Method Comparison — measure_passing_bablok","text":"","code":"if (FALSE) { # \\dontrun{ # Requires mcr package data <- data.frame(   reference = c(5.2, 10.5, 15.8, 25.3, 50.1, 75.4, 100.2),   new_method = c(5.1, 10.8, 16.2, 25.9, 49.8, 76.1, 101.3) )  result <- measure_passing_bablok(   data,   method1_col = \"reference\",   method2_col = \"new_method\" )  print(result) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_plot_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Summary Statistics for Measure Data — measure_plot_summary","title":"Plot Summary Statistics for Measure Data — measure_plot_summary","text":"Create summary plot showing mean +/- standard deviation across samples measurement location.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_plot_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Summary Statistics for Measure Data — measure_plot_summary","text":"","code":"measure_plot_summary(data, measure_col = NULL, show_range = FALSE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_plot_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Summary Statistics for Measure Data — measure_plot_summary","text":"data data frame measure column (.measures). measure_col Name measure column. NULL, auto-detected. show_range Logical. TRUE, also show min/max range. Default FALSE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_plot_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Summary Statistics for Measure Data — measure_plot_summary","text":"ggplot2 object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_plot_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Summary Statistics for Measure Data — measure_plot_summary","text":"","code":"if (FALSE) { # \\dontrun{ rec <- recipe(water ~ ., data = meats_long) |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_snv() |>   prep()  baked <- bake(rec, new_data = NULL) measure_plot_summary(baked) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Proficiency Testing Scores — measure_proficiency_score","title":"Proficiency Testing Scores — measure_proficiency_score","text":"Calculates proficiency testing scores (z-scores, En scores, zeta scores) evaluating laboratory performance interlaboratory comparisons.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proficiency Testing Scores — measure_proficiency_score","text":"","code":"measure_proficiency_score(   data,   measured_col,   reference_col,   uncertainty_col = NULL,   reference_uncertainty_col = NULL,   score_type = c(\"z_score\", \"en_score\", \"zeta_score\"),   sigma = NULL,   group_col = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proficiency Testing Scores — measure_proficiency_score","text":"data data frame containing measurement data. measured_col Name column measured/reported values. reference_col Name column reference/assigned values. uncertainty_col Name column measurement uncertainties. Required En zeta scores. reference_uncertainty_col Name column reference value uncertainties. Optional En/zeta scores. score_type Type score calculate: \"z_score\" (default): (measured - reference) / sigma \"en_score\": (measured - reference) / sqrt(U_meas^2 + U_ref^2) \"zeta_score\": Similar En, correlated uncertainties sigma Standard deviation z-score calculation. NULL, estimated data. group_col Optional grouping column separate assessments.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proficiency Testing Scores — measure_proficiency_score","text":"measure_proficiency_score object containing: scores: Tibble individual scores flags statistics: Summary statistics counts","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"score-interpretation","dir":"Reference","previous_headings":"","what":"Score Interpretation","title":"Proficiency Testing Scores — measure_proficiency_score","text":"| |Score| | Status | Action | |———|—————|——–| | <= 2    | Satisfactory  | None   | | 2-3     | Questionable  | Review | | > 3     | Unsatisfactory| Investigate |","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"score-types","dir":"Reference","previous_headings":"","what":"Score Types","title":"Proficiency Testing Scores — measure_proficiency_score","text":"z-score: Uses fixed standard deviation (sigma), typically derived historical data consensus participants. En score: Uses expanded uncertainties lab result reference value. Appropriate uncertainties well-characterized. zeta score: Similar En, accounts potential correlation lab reference uncertainties.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_proficiency_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proficiency Testing Scores — measure_proficiency_score","text":"","code":"# Proficiency testing results from multiple labs pt_data <- data.frame(   lab_id = paste0(\"Lab_\", 1:10),   measured = c(99.2, 100.5, 98.8, 101.2, 97.5, 100.1, 99.8, 102.3, 100.6, 94.0),   assigned = rep(100, 10),   uncertainty = c(1.5, 2.0, 1.8, 1.6, 2.2, 1.9, 1.7, 2.1, 1.5, 2.0) )  # z-scores with known sigma z_result <- measure_proficiency_score(   pt_data,   measured_col = \"measured\",   reference_col = \"assigned\",   score_type = \"z_score\",   sigma = 2.5 )  print(z_result) #> measure_proficiency_score #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Score Type: z_score  #> Sigma: 2.5  #>  #> Results (n = 10 ): #>   Satisfactory (|z| ≤ 2): 9 ( 90 %) #>   Questionable (2 < |z| ≤ 3): 1  #>   Unsatisfactory (|z| > 3): 0  #>  #> Score Statistics: #>   Mean score: -0.24  #>   SD score: 0.925  #>   Max |score|: 2.4   # En scores using uncertainties en_result <- measure_proficiency_score(   pt_data,   measured_col = \"measured\",   reference_col = \"assigned\",   uncertainty_col = \"uncertainty\",   score_type = \"en_score\" )  print(en_result) #> measure_proficiency_score #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Score Type: en_score  #>  #> Results (n = 10 ): #>   Satisfactory (|z| ≤ 2): 9 ( 90 %) #>   Questionable (2 < |z| ≤ 3): 1  #>   Unsatisfactory (|z| > 3): 0  #>  #> Score Statistics: #>   Mean score: -0.291  #>   SD score: 1.16  #>   Max |score|: 3"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project n-dimensional measurement by aggregating across dimensions — measure_project","title":"Project n-dimensional measurement by aggregating across dimensions — measure_project","text":"Reduces dimensionality applying aggregation function across one dimensions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project n-dimensional measurement by aggregating across dimensions — measure_project","text":"","code":"measure_project(x, along, fn = mean, na_rm = TRUE, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project n-dimensional measurement by aggregating across dimensions — measure_project","text":"x measure_nd_tbl measure_nd_list object. along Integer character specifying dimension(s) aggregate across. Can use dimension numbers names. fn Aggregation function. Default mean. na_rm Logical. Remove NA values aggregation? Default TRUE. ... Additional arguments passed fn.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project n-dimensional measurement by aggregating across dimensions — measure_project","text":"measure_tbl, measure_nd_tbl, measure_list, measure_nd_list reduced dimensionality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project n-dimensional measurement by aggregating across dimensions — measure_project","text":"","code":"# Create 2D measurement (time x wavelength) m2d <- new_measure_nd_tbl(   location_1 = rep(1:5, each = 3),   location_2 = rep(c(254, 280, 320), times = 5),   value = rnorm(15, mean = 100),   dim_names = c(\"time\", \"wavelength\") )  # Project across wavelength (average spectrum at each time) time_trace <- measure_project(m2d, along = 2)  # Project across time (average time profile at each wavelength) wavelength_profile <- measure_project(m2d, along = 1)  # Use sum instead of mean total <- measure_project(m2d, along = 2, fn = sum)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_quality_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize measure data quality — measure_quality_summary","title":"Summarize measure data quality — measure_quality_summary","text":"Provides comprehensive quality summary measure data, including axis information validation results.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_quality_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize measure data quality — measure_quality_summary","text":"","code":"measure_quality_summary(x, verbose = TRUE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_quality_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize measure data quality — measure_quality_summary","text":"x measure_tbl, measure_list, data frame measure column. verbose Logical; TRUE, prints summary console. Default TRUE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_quality_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize measure data quality — measure_quality_summary","text":"Invisibly returns list containing axis info validation results.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_quality_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize measure data quality — measure_quality_summary","text":"","code":"specs <- new_measure_list(list(   new_measure_tbl(location = seq(1000, 2500, by = 2), value = rnorm(751)),   new_measure_tbl(location = seq(1000, 2500, by = 2), value = rnorm(751)) )) measure_quality_summary(specs) #>  #> ── Measure Data Quality Summary ── #>  #>  #>  #> ── Overview  #> • Samples: 2 #> • Points per sample: 751 #> • Axis range: 1000 to 2500 #> • Axis type: wavelength_nm #> • Direction: increasing #> • Regular spacing: Yes #> • Spacing: 2 #>  #>  #> ── Validation  #>   • ✔ monotonic: Axis is monotonic #>   • ✔ duplicates: No duplicate locations #>   • ✔ missing: No missing values #>   • ✔ spacing: Spacing is regular #>  #>  #> ── Consistency  #> ✔ All samples have consistent axes"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeatability (Within-Run Precision) — measure_repeatability","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"Calculates repeatability statistics replicate measurements performed identical conditions (operator, instrument, short time interval).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"","code":"measure_repeatability(data, response_col, group_col = NULL, conf_level = 0.95)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"data data frame containing replicate measurements. response_col Name column containing response values. group_col Optional name grouping column (e.g., concentration level). provided, repeatability calculated within group. conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"measure_precision object containing: mean: Mean replicates sd: Standard deviation cv: Coefficient variation (%) n: Number replicates se: Standard error ci_lower, ci_upper: Confidence interval mean","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"Repeatability represents precision method constant conditions short time interval. typically assessed using least 6 replicates sample concentration level interest. coefficient variation (CV) reported percentage: CV = 100 * SD / mean","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_repeatability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeatability (Within-Run Precision) — measure_repeatability","text":"","code":"# Simple repeatability from replicate measurements data <- data.frame(   sample_id = rep(\"QC1\", 10),   concentration = rnorm(10, mean = 100, sd = 2) ) measure_repeatability(data, \"concentration\") #> measure_precision: repeatability  #> ────────────────────────────────────────────────────────────────────────────────  #>   n = 10  #>   Mean = 99.38  #>   SD = 1.9  #>   CV = 1.9 % #>   95% CI: [98.02, 100.7]  # Repeatability at multiple concentration levels data <- data.frame(   level = rep(c(\"low\", \"mid\", \"high\"), each = 6),   concentration = c(     rnorm(6, 10, 0.5),     rnorm(6, 50, 2),     rnorm(6, 100, 4)   ) ) measure_repeatability(data, \"concentration\", group_col = \"level\") #> measure_precision: repeatability  #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Group: low  #>   n = 6  #>   Mean = 10.19  #>   SD = 0.2589  #>   CV = 2.5 % #>   95% CI: [9.915, 10.46] #>  #> Group: mid  #>   n = 6  #>   Mean = 49.33  #>   SD = 2.66  #>   CV = 5.4 % #>   95% CI: [46.54, 52.12] #>  #> Group: high  #>   n = 6  #>   Mean = 101.5  #>   SD = 4.006  #>   CV = 3.9 % #>   95% CI: [97.32, 105.7]"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproducibility (Between-Lab Precision) — measure_reproducibility","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"Calculates reproducibility statistics measurements performed different laboratories.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"","code":"measure_reproducibility(   data,   response_col,   lab_col,   group_col = NULL,   conf_level = 0.95 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"data data frame containing measurements multiple labs. response_col Name column containing response values. lab_col Name column identifying laboratory. group_col Optional grouping column (e.g., concentration level). conf_level Confidence level intervals. Default 0.95.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"measure_precision object containing: Within-lab variance (repeatability) -lab variance Total reproducibility variance Corresponding CV estimates","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"Reproducibility represents precision method performed different laboratories. includes within-lab (repeatability) -lab variance components.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_reproducibility.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproducibility (Between-Lab Precision) — measure_reproducibility","text":"","code":"# Reproducibility across laboratories set.seed(123) data <- data.frame(   lab_id = rep(c(\"Lab_A\", \"Lab_B\", \"Lab_C\"), each = 10),   concentration = rnorm(30, mean = 100, sd = 2) +     rep(c(0, 3, -2), each = 10)  # Lab bias ) measure_reproducibility(data, \"concentration\", lab_col = \"lab_id\") #> measure_precision: reproducibility  #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Variance Components: #>   lab_id: 9.442 (71%) #>   Residual: 3.805 (29%) #>  #> CV by component: #>   lab_id: 3.1% #>   Residual: 1.9%"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_sample_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Canonical Sample Types — measure_sample_types","title":"Canonical Sample Types — measure_sample_types","text":"allowed values sample_type column analytical workflows.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_sample_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canonical Sample Types — measure_sample_types","text":"","code":"measure_sample_types"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_sample_types.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Canonical Sample Types — measure_sample_types","text":"object class character length 5.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract slices from n-dimensional measurement — measure_slice","title":"Extract slices from n-dimensional measurement — measure_slice","text":"Fixes one dimensions specific coordinate values ranges, returning lower-dimensional result.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_slice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract slices from n-dimensional measurement — measure_slice","text":"","code":"measure_slice(x, ..., drop = TRUE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract slices from n-dimensional measurement — measure_slice","text":"x measure_nd_tbl measure_nd_list object. ... Named arguments specifying slice conditions. Names dimension numbers (e.g., dim_1 = 5) dimension names set (e.g., time = 5). Values can : single value: exact match numeric vector: match values function: applied coordinates, return logical drop Logical. TRUE (default), dimensions single value dropped result. FALSE, retained.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_slice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract slices from n-dimensional measurement — measure_slice","text":"measure_tbl, measure_nd_tbl, measure_list, measure_nd_list depending number remaining dimensions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_slice.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract slices from n-dimensional measurement — measure_slice","text":"","code":"# Create a 3D measurement (2 x 3 x 4) m3d <- new_measure_nd_tbl(   location_1 = rep(1:2, each = 12),   location_2 = rep(rep(1:3, each = 4), 2),   location_3 = rep(1:4, 6),   value = 1:24,   dim_names = c(\"sample\", \"time\", \"wavelength\") )  # Extract slice at sample = 1 slice_2d <- measure_slice(m3d, dim_1 = 1) measure_ndim(slice_2d)  # 2D #> [1] 2  # Extract at specific time points slice_subset <- measure_slice(m3d, dim_2 = c(1, 3))  # Use dimension names slice_wl <- measure_slice(m3d, wavelength = 2)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_standardize_sample_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize Sample Type Values — measure_standardize_sample_type","title":"Standardize Sample Type Values — measure_standardize_sample_type","text":"Converts non-standard sample type values canonical form using user-specified mapping. useful data uses different naming conventions (e.g., \"QC\", \"quality_control\", \"pooled_qc\").","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_standardize_sample_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize Sample Type Values — measure_standardize_sample_type","text":"","code":"measure_standardize_sample_type(   data,   col = \"sample_type\",   mapping = NULL,   unknown_action = c(\"error\", \"warn\", \"keep\", \"unknown\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_standardize_sample_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize Sample Type Values — measure_standardize_sample_type","text":"data data frame containing sample type column. col Name sample type column. Default \"sample_type\". mapping named list mapping canonical types vectors aliases. example: list(qc = c(\"QC\", \"quality_control\", \"pooled_qc\")). NULL, uses default case-insensitive matching. unknown_action values match mapping: \"error\" (default): Stop error \"warn\": Warn keep original value \"keep\": Silently keep original value \"unknown\": Convert \"unknown\"","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_standardize_sample_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize Sample Type Values — measure_standardize_sample_type","text":"data frame standardized sample_type values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_standardize_sample_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize Sample Type Values — measure_standardize_sample_type","text":"","code":"# Data with non-standard sample types data <- data.frame(   sample_id = 1:5,   sample_type = c(\"QC\", \"STD\", \"BLK\", \"UNK\", \"REF\") )  # Standardize with custom mapping measure_standardize_sample_type(   data,   mapping = list(     qc = c(\"QC\", \"qc\", \"quality_control\"),     standard = c(\"STD\", \"std\", \"cal\"),     blank = c(\"BLK\", \"blk\", \"blank\"),     unknown = c(\"UNK\", \"unk\", \"sample\"),     reference = c(\"REF\", \"ref\")   ) ) #>   sample_id sample_type #> 1         1          qc #> 2         2    standard #> 3         3       blank #> 4         4     unknown #> 5         5   reference"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_steps.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available Steps — measure_steps","title":"List Available Steps — measure_steps","text":"Returns tibble registered recipe steps measure loaded technique packs. Results can filtered pack, category, technique.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_steps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available Steps — measure_steps","text":"","code":"measure_steps(packs = NULL, categories = NULL, techniques = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_steps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Available Steps — measure_steps","text":"packs Character vector pack names include. NULL, includes packs. categories Character vector step categories include. NULL, includes categories. techniques Character vector techniques include. NULL, includes techniques.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_steps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Available Steps — measure_steps","text":"tibble columns: step_name: Function name (e.g., \"step_measure_baseline_als\") pack_name: Source package name category: Step category (e.g., \"baseline\", \"smoothing\") description: Brief description technique: Technique (e.g., \"general\", \"SEC/GPC\")","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_steps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available Steps — measure_steps","text":"","code":"# List all steps measure_steps() #> # A tibble: 96 × 5 #>    step_name                    pack_name category  description        technique #>    <chr>                        <chr>     <chr>     <chr>              <chr>     #>  1 step_measure_input_long      measure   io        Convert long data… general   #>  2 step_measure_input_wide      measure   io        Convert wide data… general   #>  3 step_measure_output_long     measure   io        Convert measure t… general   #>  4 step_measure_output_wide     measure   io        Convert measure t… general   #>  5 step_measure_savitzky_golay  measure   smoothing Savitzky-Golay sm… general   #>  6 step_measure_smooth_ma       measure   smoothing Moving average sm… general   #>  7 step_measure_smooth_median   measure   smoothing Median filter smo… general   #>  8 step_measure_smooth_gaussian measure   smoothing Gaussian smoothing general   #>  9 step_measure_smooth_wavelet  measure   smoothing Wavelet smoothing  general   #> 10 step_measure_filter_fourier  measure   smoothing Fourier filtering  general   #> # ℹ 86 more rows  # List only baseline correction steps measure_steps(categories = \"baseline\") #> # A tibble: 14 × 5 #>    step_name                     pack_name category description        technique #>    <chr>                         <chr>     <chr>    <chr>              <chr>     #>  1 step_measure_baseline_als     measure   baseline Asymmetric Least … general   #>  2 step_measure_baseline_poly    measure   baseline Polynomial baseli… general   #>  3 step_measure_baseline_rf      measure   baseline Robust fitting ba… general   #>  4 step_measure_baseline_custom  measure   baseline Custom baseline f… general   #>  5 step_measure_baseline_py      measure   baseline Python pybaseline… general   #>  6 step_measure_baseline_rolling measure   baseline Rolling ball base… general   #>  7 step_measure_baseline_airpls  measure   baseline AirPLS baseline    general   #>  8 step_measure_baseline_snip    measure   baseline SNIP baseline      general   #>  9 step_measure_baseline_arpls   measure   baseline arPLS baseline     general   #> 10 step_measure_baseline_tophat  measure   baseline Top-hat morpholog… general   #> 11 step_measure_baseline_morph   measure   baseline Morphological bas… general   #> 12 step_measure_baseline_minima  measure   baseline Local minima base… general   #> 13 step_measure_baseline_auto    measure   baseline Automatic baselin… general   #> 14 step_measure_baseline_gpc     measure   baseline GPC/SEC baseline … general    # List steps from a specific technique pack measure_steps(techniques = \"SEC/GPC\") #> # A tibble: 0 × 5 #> # ℹ 5 variables: step_name <chr>, pack_name <chr>, category <chr>, #> #   description <chr>, technique <chr>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Measurements Across Samples — measure_summarize","title":"Summarize Measurements Across Samples — measure_summarize","text":"measure_summarize() computes summary statistics measurement location across samples. useful understanding data, computing reference spectra, identifying outliers.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Measurements Across Samples — measure_summarize","text":"","code":"measure_summarize(   .data,   .cols = NULL,   .fns = list(mean = mean, sd = stats::sd),   na.rm = TRUE )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Measurements Across Samples — measure_summarize","text":".data data frame containing one measure_list columns. .cols <tidy-select> Columns summarize. Defaults measure_list columns. .fns named list summary functions. function accept numeric vector return single value. Default list(mean = mean, sd = sd). na.rm Logical. NA values removed? Default TRUE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Measurements Across Samples — measure_summarize","text":"tibble one row per measurement location columns summary statistic.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize Measurements Across Samples — measure_summarize","text":"function transform data; summarizes . Common uses: Mean spectrum: average spectrum across samples Reference spectrum: MSC-style corrections Variability: Standard deviation wavelength Quality control: Identify problematic wavelength regions","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_summarize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize Measurements Across Samples — measure_summarize","text":"","code":"library(recipes) library(ggplot2)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  baked_data <- bake(rec, new_data = NULL)  # Compute mean and SD at each wavelength summary_stats <- measure_summarize(baked_data) summary_stats #> # A tibble: 100 × 3 #>    location  mean    sd #>       <int> <dbl> <dbl> #>  1        1  2.81 0.411 #>  2        2  2.81 0.413 #>  3        3  2.81 0.416 #>  4        4  2.82 0.418 #>  5        5  2.82 0.421 #>  6        6  2.82 0.424 #>  7        7  2.83 0.426 #>  8        8  2.83 0.429 #>  9        9  2.83 0.432 #> 10       10  2.84 0.434 #> # ℹ 90 more rows  # Visualize mean spectrum with confidence band ggplot(summary_stats, aes(x = location)) +   geom_ribbon(aes(ymin = mean - sd, ymax = mean + sd), alpha = 0.3) +   geom_line(aes(y = mean)) +   labs(x = \"Channel\", y = \"Transmittance\", title = \"Mean Spectrum +/- 1 SD\")   # Custom summary functions measure_summarize(   baked_data,   .fns = list(     median = median,     q25 = function(x) quantile(x, 0.25),     q75 = function(x) quantile(x, 0.75)   ) ) #> # A tibble: 100 × 4 #>    location median   q25   q75 #>       <int>  <dbl> <dbl> <dbl> #>  1        1   2.75  2.51  3.01 #>  2        2   2.76  2.51  3.01 #>  3        3   2.76  2.51  3.01 #>  4        4   2.76  2.52  3.02 #>  5        5   2.76  2.52  3.03 #>  6        6   2.76  2.52  3.03 #>  7        7   2.76  2.52  3.04 #>  8        8   2.77  2.52  3.05 #>  9        9   2.77  2.52  3.05 #> 10       10   2.77  2.52  3.06 #> # ℹ 90 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":null,"dir":"Reference","previous_headings":"","what":"System Suitability Check — measure_system_suitability","title":"System Suitability Check — measure_system_suitability","text":"Performs system suitability tests QC reference samples verify instrument performance meets requirements.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"System Suitability Check — measure_system_suitability","text":"","code":"measure_system_suitability(   data,   metrics,   sample_type_col = NULL,   sst_type = \"sst\" )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"System Suitability Check — measure_system_suitability","text":"data data frame containing system suitability data. metrics Named list columns acceptance criteria. element list col, min, /max. sample_type_col Optional column identifying sample types. sst_type Value sample_type_col identifies SST samples.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"System Suitability Check — measure_system_suitability","text":"measure_sst object containing: results: Pass/fail status metric summary: Overall pass/fail summary statistics details: Individual sample results","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"System Suitability Check — measure_system_suitability","text":"System suitability testing (SST) verifies analytical system performing adequately , , run. Common metrics include: Peak resolution Retention time reproducibility Peak symmetry/tailing factor Signal--noise ratio Plate count","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_system_suitability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"System Suitability Check — measure_system_suitability","text":"","code":"# System suitability check sst_data <- data.frame(   sample_id = paste0(\"SST_\", 1:5),   resolution = c(2.1, 2.3, 2.2, 2.0, 2.1),   tailing = c(1.1, 1.0, 1.2, 1.1, 1.0),   plates = c(5200, 5100, 5300, 5000, 5150) )  result <- measure_system_suitability(   sst_data,   metrics = list(     resolution = list(col = \"resolution\", min = 2.0),     tailing = list(col = \"tailing\", max = 1.5),     plates = list(col = \"plates\", min = 5000)   ) ) print(result) #> measure_system_suitability #> ────────────────────────────────────────────────────────────────────────────────  #>  #> Samples evaluated: 5  #> Metrics checked: 3  #> Passed: 3 / 3  #>  #> Overall Status: PASS #>  #> Results: #> # A tibble: 3 × 11 #>   metric     column        n   mean      sd    cv min_spec max_spec observed_min #>   <chr>      <chr>     <int>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>        <dbl> #> 1 resolution resoluti…     5 2.14e0 1.14e-1  5.33        2     NA              2 #> 2 tailing    tailing       5 1.08e0 8.37e-2  7.75       NA      1.5            1 #> 3 plates     plates        5 5.15e3 1.12e+2  2.17     5000     NA           5000 #> # ℹ 2 more variables: observed_max <dbl>, pass <lgl>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick Uncertainty Calculation — measure_uncertainty","title":"Quick Uncertainty Calculation — measure_uncertainty","text":"convenience function returns just key uncertainty values without full budget object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick Uncertainty Calculation — measure_uncertainty","text":"","code":"measure_uncertainty(..., .list = NULL, k = 2)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick Uncertainty Calculation — measure_uncertainty","text":"... uncertainty_component() objects include budget. .list Optional list uncertainty components. k Coverage factor expanded uncertainty. Default 2 (approximately 95% coverage normal distribution).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick Uncertainty Calculation — measure_uncertainty","text":"named list : combined_u: Combined standard uncertainty expanded_U: Expanded uncertainty effective_df: Effective degrees freedom coverage_factor: Coverage factor used","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quick Uncertainty Calculation — measure_uncertainty","text":"","code":"u1 <- uncertainty_component(\"A\", 0.05, type = \"A\", df = 9) u2 <- uncertainty_component(\"B\", 0.03, type = \"B\")  measure_uncertainty(u1, u2) #> $combined_u #> [1] 0.05830952 #>  #> $expanded_U #> [1] 0.116619 #>  #> $effective_df #> [1] 16.6464 #>  #> $coverage_factor #> [1] 2 #>"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Uncertainty Budget — measure_uncertainty_budget","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"Combines multiple uncertainty components complete uncertainty budget following ISO GUM methodology. Calculates combined standard uncertainty, effective degrees freedom (Welch-Satterthwaite), expanded uncertainty.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"","code":"measure_uncertainty_budget(..., .list = NULL, k = 2, result_value = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"... uncertainty_component() objects include budget. .list Optional list uncertainty components. k Coverage factor expanded uncertainty. Default 2 (approximately 95% coverage normal distribution). result_value Optional. measurement result value, used calculating relative uncertainty.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"measure_uncertainty_budget object containing: components: List input uncertainty components combined_u: Combined standard uncertainty effective_df: Effective degrees freedom (Welch-Satterthwaite) coverage_factor: k value used expanded_U: Expanded uncertainty (k * combined_u) result_value: measurement result (provided) relative_u: Relative standard uncertainty (result provided)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"combined-standard-uncertainty","dir":"Reference","previous_headings":"","what":"Combined Standard Uncertainty","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"Calculated root sum squares contributions: $$u_c = \\sqrt{\\sum_i (c_i \\cdot u_i)^2}$$","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"welch-satterthwaite-effective-degrees-of-freedom","dir":"Reference","previous_headings":"","what":"Welch-Satterthwaite Effective Degrees of Freedom","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"$$\\nu_{eff} = \\frac{u_c^4}{\\sum_i \\frac{(c_i \\cdot u_i)^4}{\\nu_i}}$$ used determine appropriate coverage factor given confidence level.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"expanded-uncertainty","dir":"Reference","previous_headings":"","what":"Expanded Uncertainty","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"$$U = k \\cdot u_c$$ k=2, provides approximately 95% coverage.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_uncertainty_budget.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Uncertainty Budget — measure_uncertainty_budget","text":"","code":"# Create components u_repeat <- uncertainty_component(\"Repeatability\", 0.05, type = \"A\", df = 9) u_cal <- uncertainty_component(\"Calibrator\", 0.02, type = \"B\", df = 50) u_temp <- uncertainty_component(\"Temperature\", 0.03, type = \"B\")  # Create budget budget <- measure_uncertainty_budget(u_repeat, u_cal, u_temp, k = 2) print(budget) #> <measure_uncertainty_budget> #>   Components: 3 (1 Type A, 2 Type B) #>   Combined u: 0.06164 #>   Effective df: 21 #>   Coverage k: 2 #>   Expanded U: 0.1233  # With result value for relative uncertainty budget <- measure_uncertainty_budget(   u_repeat, u_cal, u_temp,   result_value = 10.5 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":null,"dir":"Reference","previous_headings":"","what":"Unfold n-dimensional measurement to 1D — measure_unfold","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"Converts n-dimensional measurement 1D vector flattening according specified dimension order. Stores metadata needed reconstruct original nD structure via measure_fold().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"","code":"measure_unfold(x, order = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"x measure_nd_tbl measure_nd_list object. order Integer vector specifying order dimensions unfolding. Default NULL, uses natural order (1, 2, ..., n). first dimension varies fastest.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"measure_tbl measure_list attribute \"fold_info\" containing metadata needed reconstruct nD structure.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"Unfolding useful : Applying 1D modeling techniques (PCA, PLS) nD data Exporting formats expect 1D vectors Visualization single trace fold metadata includes: ndim: Original number dimensions dim_names, dim_units: Original dimension metadata coordinates: original coordinate values dimension order: unfolding order used","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_unfold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unfold n-dimensional measurement to 1D — measure_unfold","text":"","code":"# Create a 2D measurement (3 x 4 grid) m2d <- new_measure_nd_tbl(   location_1 = rep(1:3, each = 4),   location_2 = rep(1:4, times = 3),   value = 1:12,   dim_names = c(\"time\", \"wavelength\") )  # Unfold to 1D m1d <- measure_unfold(m2d) m1d #> <measure_tbl [12 x 2]> #> # A tibble: 12 × 2 #>    location value #>       <int> <int> #>  1        1     1 #>  2        2     5 #>  3        3     9 #>  4        4     2 #>  5        5     6 #>  6        6    10 #>  7        7     3 #>  8        8     7 #>  9        9    11 #> 10       10     4 #> 11       11     8 #> 12       12    12  # Reconstruct m2d_restored <- measure_fold(m1d)"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Analytical Metadata — measure_validate_metadata","title":"Validate Analytical Metadata — measure_validate_metadata","text":"Validates data frame contains required metadata columns analytical workflows. function checks column presence, correct data types, valid values (e.g., sample_type levels).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Analytical Metadata — measure_validate_metadata","text":"","code":"measure_validate_metadata(   data,   require = NULL,   sample_types = measure_sample_types,   action = c(\"error\", \"warn\", \"message\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Analytical Metadata — measure_validate_metadata","text":"data data frame validate. require Character vector required columns. Common columns include: \"sample_type\": Sample classification (qc, standard, blank, unknown, reference) \"run_order\": Injection/measurement sequence (integer) \"batch_id\": Batch identifier (character/factor) \"nominal_conc\": Known concentration standards (numeric) \"sample_id\": Unique sample identifier \"analyst_id\", \"day\", \"instrument_id\": Precision study factors sample_types Allowed values sample_type column. Default measure_sample_types: \"qc\", \"standard\", \"blank\", \"unknown\", \"reference\". action validation fails: \"error\" (default): Stop informative error \"warn\": Issue warnings continue \"message\": Issue messages continue","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Analytical Metadata — measure_validate_metadata","text":"Invisibly returns list validation results: valid: Logical, TRUE checks passed checks: List individual check results data: original data (unchanged)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"canonical-columns","dir":"Reference","previous_headings":"","what":"Canonical Columns","title":"Validate Analytical Metadata — measure_validate_metadata","text":"Milestone 2 functions expect specific column names specific types:","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"sample-type-values","dir":"Reference","previous_headings":"","what":"Sample Type Values","title":"Validate Analytical Metadata — measure_validate_metadata","text":"sample_type column must contain values measure_sample_types: \"qc\": Quality control sample (pooled QC, system suitability) \"standard\": Calibration standard known concentration \"blank\": Blank sample (solvent, matrix blank) \"unknown\": Sample unknown concentration \"reference\": Reference material batch correction","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validate_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Analytical Metadata — measure_validate_metadata","text":"","code":"# Create sample analytical data data <- data.frame(   sample_id = paste0(\"S\", 1:10),   sample_type = c(\"qc\", \"standard\", \"standard\", \"unknown\", \"unknown\",                   \"unknown\", \"qc\", \"blank\", \"unknown\", \"qc\"),   run_order = 1:10,   batch_id = \"B001\",   nominal_conc = c(NA, 10, 50, NA, NA, NA, NA, 0, NA, NA),   response = rnorm(10, mean = 100) )  # Validate required columns measure_validate_metadata(data, require = c(\"sample_type\", \"run_order\"))  # Validate for calibration workflow measure_validate_metadata(   data,   require = c(\"sample_type\", \"nominal_conc\") )  # More lenient validation (warnings only) measure_validate_metadata(   data,   require = c(\"sample_type\", \"run_order\", \"missing_col\"),   action = \"warn\" ) #> Warning: Metadata validation issues: #> ! Missing required column(s): missing_col"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Analytical Method Validation Report — measure_validation_report","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"Creates structured validation report object collects results various validation studies (calibration, precision, accuracy, etc.) can rendered HTML, PDF, Word formats using standardized templates. function supports two major validation frameworks: ICH Q2(R2): International harmonized guidelines analytical validation USP <1225>: United States Pharmacopeia compendial validation procedures","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"","code":"measure_validation_report(   title = \"Analytical Method Validation Report\",   method_name = NULL,   method_description = NULL,   analyst = NULL,   reviewer = NULL,   lab = NULL,   date = Sys.Date(),   instrument = NULL,   software = NULL,   calibration = NULL,   lod_loq = NULL,   accuracy = NULL,   precision = NULL,   linearity = NULL,   range = NULL,   specificity = NULL,   robustness = NULL,   carryover = NULL,   system_suitability = NULL,   uncertainty = NULL,   method_comparison = NULL,   stability = NULL,   criteria = NULL,   conclusions = NULL,   references = NULL,   appendices = NULL,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"title Report title. Default: \"Analytical Method Validation Report\" method_name Name analytical method validated. method_description Brief description method (technique, analyte, matrix). analyst Name analyst(s) performing validation. reviewer Name reviewer (optional). lab Laboratory name identifier. date Date validation study. Default: current date. instrument Instrument details (name, model, serial number). software Software used data acquisition/processing. calibration measure_calibration object measure_calibration_fit(). lod_loq LOD/LOQ results measure_lod(), measure_loq(), measure_lod_loq(). Can single object list. accuracy Accuracy results measure_accuracy(). precision list containing precision study results: repeatability: measure_repeatability() intermediate: measure_intermediate_precision() reproducibility: measure_reproducibility() (optional) linearity Linearity results measure_linearity(). range list lower upper validated range limits, results supporting range determination. specificity User-provided specificity/selectivity assessment. Can text, data frame interference results, list. robustness User-provided robustness study results. Can text, data frame, structured results. carryover Carryover results measure_carryover(). system_suitability System suitability results measure_system_suitability(). uncertainty Uncertainty budget measure_uncertainty_budget(). method_comparison Method comparison results (Bland-Altman, Deming, Passing-Bablok) corresponding functions. stability User-provided stability data (solution stability, freeze-thaw, etc.). criteria measure_criteria object defining acceptance criteria, named list criteria objects different sections. conclusions User-provided conclusions text list summary recommendations. references Character vector references cited. appendices Named list additional content include appendices. ... Additional metadata include report.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"measure_validation_report object containing: metadata: Report metadata (title, analyst, date, etc.) sections: Named list validation results section criteria: Acceptance criteria used provenance: Data provenance computational environment info call: function call","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"workflow","dir":"Reference","previous_headings":"","what":"Workflow","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"Run individual validation studies using measure functions Collect results validation report object Render desired format using render_validation_report()","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"supported-validation-characteristics-ich-q-","dir":"Reference","previous_headings":"","what":"Supported Validation Characteristics (ICH Q2)","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"Specificity/Selectivity: Ability assess analyte presence interferences Linearity: Proportional response concentration range Range: Validated concentration interval Accuracy: Closeness true value (trueness) Precision: Repeatability, intermediate precision, reproducibility Detection Limit (LOD): Lowest detectable amount Quantitation Limit (LOQ): Lowest quantifiable amount acceptable precision/accuracy Robustness: Capacity remain unaffected small method variations","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"data-provenance","dir":"Reference","previous_headings":"","what":"Data Provenance","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"report automatically captures: R version package versions Date/time report generation Function calls used generate section","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/measure_validation_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Analytical Method Validation Report — measure_validation_report","text":"","code":"# Create sample validation data set.seed(123) cal_data <- data.frame(   nominal_conc = rep(c(1, 5, 10, 25, 50, 100), each = 3),   response = c(1, 5, 10, 25, 50, 100) * 1000 +     rnorm(18, sd = 50),   sample_type = \"standard\" )  # Fit calibration cal_fit <- measure_calibration_fit(   cal_data,   formula = response ~ nominal_conc,   weights = \"1/x\" )  # Calculate LOD/LOQ (requires sample_type column) blank_data <- data.frame(   response = rnorm(10, mean = 50, sd = 15),   sample_type = \"blank\" ) lod_result <- measure_lod(blank_data, response_col = \"response\")  # Create precision data precision_data <- data.frame(   concentration = rep(c(10, 50, 100), each = 6),   replicate = rep(1:6, 3),   response = c(     rnorm(6, 10000, 200),     rnorm(6, 50000, 800),     rnorm(6, 100000, 1500)   ) ) repeatability <- measure_repeatability(   precision_data,   response_col = \"response\",   group_col = \"concentration\" )  # Create validation report report <- measure_validation_report(   title = \"Validation of HPLC Method for Compound X\",   method_name = \"HPLC-UV Assay\",   method_description = \"Reversed-phase HPLC with UV detection at 254 nm\",   analyst = \"J. Smith\",   lab = \"Analytical Development Lab\",   calibration = cal_fit,   lod_loq = lod_result,   precision = list(repeatability = repeatability),   conclusions = \"Method meets all acceptance criteria for intended use.\" )  print(report) #>  #> ── Validation Report ─────────────────────────────────────────────────────────── #> Title: Validation of HPLC Method for Compound X #> Method: HPLC-UV Assay #> Analyst: J. Smith #> Lab: Analytical Development Lab #> Date: 2026-01-01 #>  #>  #> ── Validation Sections ── #>  #> ℹ Calibration #> ℹ LOD/LOQ #> ℹ Precision #>  #>  #> ── Conclusions ── #>  #> Method meets all acceptance criteria for intended use. #>  #>  #> ── Provenance ── #>  #> Generated: 2026-01-01 14:26:02.656987 #> R version: 4.5.2 #> measure version: 0.0.1.9001 #>  #> ℹ Use `render_validation_report()` to generate document"},{"path":"https://jameshwade.github.io/measure/dev/reference/meats_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Fat, water and protein content of meat samples — meats_long","title":"Fat, water and protein content of meat samples — meats_long","text":"\"data recorded Tecator Infratec Food Feed Analyzer working wavelength range 850 - 1050 nm Near Infrared Transmission (NIT) principle. sample contains finely chopped pure meat different moisture, fat protein contents.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/meats_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fat, water and protein content of meat samples — meats_long","text":"meats_long tibble","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/meats_long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fat, water and protein content of meat samples — meats_long","text":"results data used publication want mention instrument company name (Tecator) publication.  addition, please send preprint article Karin Thente, Tecator AB, Box 70, S-263 21 Hoganas, Sweden data available public domain responsibility original data source. data can redistributed long permission note attached.\" \"meat sample data consists 100 channel spectrum absorbances contents moisture (water), fat protein.  absorbance -log10 transmittance measured spectrometer. three contents, measured percent, determined analytic chemistry.\" Included meats data transformed long format ","code":"modeldata::meats |>   rowid_to_column(var = \"id\") |>   pivot_longer(cols = starts_with(\"x_\"),                names_to = \"channel\",                values_to = \"transmittance\") |>   mutate(channel = str_extract(channel, \"[:digit:]+\") |> as.integer())"},{"path":"https://jameshwade.github.io/measure/dev/reference/meats_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fat, water and protein content of meat samples — meats_long","text":"","code":"data(meats_long) str(meats_long) #> tibble [21,500 × 6] (S3: tbl_df/tbl/data.frame) #>  $ id           : int [1:21500] 1 1 1 1 1 1 1 1 1 1 ... #>  $ water        : num [1:21500] 60.5 60.5 60.5 60.5 60.5 60.5 60.5 60.5 60.5 60.5 ... #>  $ fat          : num [1:21500] 22.5 22.5 22.5 22.5 22.5 22.5 22.5 22.5 22.5 22.5 ... #>  $ protein      : num [1:21500] 16.7 16.7 16.7 16.7 16.7 16.7 16.7 16.7 16.7 16.7 ... #>  $ channel      : int [1:21500] 1 2 3 4 5 6 7 8 9 10 ... #>  $ transmittance: num [1:21500] 2.62 2.62 2.62 2.62 2.62 ..."},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new measure list — new_measure_list","title":"Create a new measure list — new_measure_list","text":"Constructor creating collection measurements suitable use list column data frame. element measure_tbl tibble location value columns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new measure list — new_measure_list","text":"","code":"new_measure_list(x = list())"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new measure list — new_measure_list","text":"x list measure_tbl objects tibbles location value columns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new measure list — new_measure_list","text":"list class measure_list.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new measure list — new_measure_list","text":"","code":"# Create individual spectra spec1 <- new_measure_tbl(location = 1:10, value = rnorm(10)) spec2 <- new_measure_tbl(location = 1:10, value = rnorm(10))  # Combine into a measure_list specs <- new_measure_list(list(spec1, spec2)) specs #> A measure_list with 2 measurements #> Sizes: 10, 10 (10-10 points)"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new n-dimensional measure list — new_measure_nd_list","title":"Create a new n-dimensional measure list — new_measure_nd_list","text":"Constructor creating collection n-dimensional measurements suitable use list column data frame. element measure_nd_tbl tibble location_* value columns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new n-dimensional measure list — new_measure_nd_list","text":"","code":"new_measure_nd_list(x = list())"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new n-dimensional measure list — new_measure_nd_list","text":"x list measure_nd_tbl objects tibbles location_* value columns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new n-dimensional measure list — new_measure_nd_list","text":"list class measure_nd_list.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new n-dimensional measure list — new_measure_nd_list","text":"","code":"# Create individual 2D measurements meas1 <- new_measure_nd_tbl(   location_1 = rep(1:5, each = 3),   location_2 = rep(1:3, times = 5),   value = rnorm(15) ) meas2 <- new_measure_nd_tbl(   location_1 = rep(1:5, each = 3),   location_2 = rep(1:3, times = 5),   value = rnorm(15) )  # Combine into a measure_nd_list meas_list <- new_measure_nd_list(list(meas1, meas2)) meas_list #> A measure_nd_list with 2 measurements (2D) #> Sizes: 15, 15 (15-15 points)"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","title":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","text":"Constructor creating single n-dimensional measurement object containing location coordinates (e.g., wavelength, retention time) values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","text":"","code":"new_measure_nd_tbl(..., value = double(), dim_names = NULL, dim_units = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","text":"... Named location vectors. Names follow pattern location_1, location_2, etc. must numeric vector length. value Numeric vector measurement values (e.g., absorbance, intensity, signal). Must length location vectors. dim_names Optional character vector semantic dimension names (e.g., c(\"wavelength\", \"retention_time\")). dim_units Optional character vector dimension units (e.g., c(\"nm\", \"min\")).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","text":"tibble class measure_nd_tbl containing location_1, location_2, ..., location_n, value columns. Attributes include ndim, dim_names, dim_units, dim_order.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_nd_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new n-dimensional measure tibble — new_measure_nd_tbl","text":"","code":"# Create a 2D measurement (e.g., LC-UV: retention time x wavelength) meas_2d <- new_measure_nd_tbl(   location_1 = rep(seq(0, 10, length.out = 5), each = 3),   location_2 = rep(c(254, 280, 320), times = 5),   value = rnorm(15),   dim_names = c(\"retention_time\", \"wavelength\"),   dim_units = c(\"min\", \"nm\") ) meas_2d #> <measure_nd_tbl [15 x 3] retention_time x wavelength> #> <measure_tbl [15 x 3]> #> # A tibble: 15 × 3 #>    location_1 location_2   value #>         <dbl>      <dbl>   <dbl> #>  1        0          254 -0.710  #>  2        0          280  0.257  #>  3        0          320 -0.247  #>  4        2.5        254 -0.348  #>  5        2.5        280 -0.952  #>  6        2.5        320 -0.0450 #>  7        5          254 -0.785  #>  8        5          280 -1.67   #>  9        5          320 -0.380  #> 10        7.5        254  0.919  #> 11        7.5        280 -0.575  #> 12        7.5        320  0.608  #> 13       10          254 -1.62   #> 14       10          280 -0.0556 #> 15       10          320  0.519"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new measure tibble — new_measure_tbl","title":"Create a new measure tibble — new_measure_tbl","text":"Constructor creating single measurement object containing location (e.g., wavelength, retention time) value pairs.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new measure tibble — new_measure_tbl","text":"","code":"new_measure_tbl(location = double(), value = double())"},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new measure tibble — new_measure_tbl","text":"location Numeric vector measurement locations (e.g., wavelengths, wavenumbers, retention times). value Numeric vector measurement values (e.g., absorbance, intensity, signal).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new measure tibble — new_measure_tbl","text":"tibble class measure_tbl containing location value columns.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/new_measure_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new measure tibble — new_measure_tbl","text":"","code":"# Create a simple spectrum spec <- new_measure_tbl(   location = seq(1000, 1100, by = 10),   value = sin(seq(1000, 1100, by = 10) / 50) ) spec #> <measure_tbl [11 x 2]> #> # A tibble: 11 × 2 #>    location    value #>       <dbl>    <dbl> #>  1     1000  0.913   #>  2     1010  0.976   #>  3     1020  1.000   #>  4     1030  0.984   #>  5     1040  0.929   #>  6     1050  0.837   #>  7     1060  0.711   #>  8     1070  0.557   #>  9     1080  0.381   #> 10     1090  0.190   #> 11     1100 -0.00885"},{"path":"https://jameshwade.github.io/measure/dev/reference/outlier_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for quality control steps — outlier_threshold","title":"Parameters for quality control steps — outlier_threshold","text":"outlier_threshold() controls threshold outlier detection (standard deviation Mahalanobis distance units).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/outlier_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for quality control steps — outlier_threshold","text":"","code":"outlier_threshold(range = c(2, 5), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/outlier_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for quality control steps — outlier_threshold","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/outlier_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for quality control steps — outlier_threshold","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/outlier_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for quality control steps — outlier_threshold","text":"","code":"outlier_threshold() #> Outlier Threshold (quantitative) #> Range: [2, 5]"},{"path":"https://jameshwade.github.io/measure/dev/reference/peak_location_min.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for peak normalization — peak_location_min","title":"Parameters for peak normalization — peak_location_min","text":"peak_location_min() peak_location_max() define bounds reference region peak normalization. specified units location values measurement data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/peak_location_min.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for peak normalization — peak_location_min","text":"","code":"peak_location_min(range = c(0, 100), trans = NULL)  peak_location_max(range = c(0, 100), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/peak_location_min.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for peak normalization — peak_location_min","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/peak_location_min.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for peak normalization — peak_location_min","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/peak_location_min.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for peak normalization — peak_location_min","text":"","code":"peak_location_min() #> Peak Region Lower Bound (quantitative) #> Range: [0, 100] peak_location_max() #> Peak Region Upper Bound (quantitative) #> Range: [0, 100]"},{"path":"https://jameshwade.github.io/measure/dev/reference/plot_measure_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","title":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","text":"Visualize effect different preprocessing recipes side--side. Useful comparing different parameter settings preprocessing strategies.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/plot_measure_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","text":"","code":"plot_measure_comparison(..., data = NULL, n_samples = 5, summary_only = FALSE)"},{"path":"https://jameshwade.github.io/measure/dev/reference/plot_measure_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","text":"... Named recipe objects compare. must prepped recipe. data Data apply recipes . NULL, uses training data first recipe. n_samples Number samples show. Default 5. summary_only TRUE, show summary statistics (mean +/- SD). Default FALSE shows individual spectra.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/plot_measure_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","text":"ggplot2 object faceted comparison.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/plot_measure_comparison.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Multiple Preprocessing Recipes — plot_measure_comparison","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes) library(ggplot2)  # Compare SNV vs MSC preprocessing base_rec <- recipe(water ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel))  snv_rec <- base_rec |>   step_measure_snv() |>   prep()  msc_rec <- base_rec |>   step_measure_msc() |>   prep()  plot_measure_comparison(   \"SNV\" = snv_rec,   \"MSC\" = msc_rec,   n_samples = 10 ) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/print.measure_validation_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a Validation Report — print.measure_validation_report","title":"Print a Validation Report — print.measure_validation_report","text":"Displays formatted summary validation report object, including metadata, section status, conclusions, provenance information.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/print.measure_validation_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a Validation Report — print.measure_validation_report","text":"","code":"# S3 method for class 'measure_validation_report' print(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/print.measure_validation_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a Validation Report — print.measure_validation_report","text":"x measure_validation_report object. ... Additional arguments (currently ignored).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/print.measure_validation_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a Validation Report — print.measure_validation_report","text":"Invisibly returns input object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/print.measure_validation_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a Validation Report — print.measure_validation_report","text":"","code":"report <- measure_validation_report(   title = \"Test Report\",   method_name = \"HPLC Assay\",   analyst = \"J. Smith\" ) print(report) #>  #> ── Validation Report ─────────────────────────────────────────────────────────── #> Title: Test Report #> Method: HPLC Assay #> Analyst: J. Smith #> Date: 2026-01-01 #>  #>  #> ── Provenance ── #>  #> Generated: 2026-01-01 14:26:04.539741 #> R version: 4.5.2 #> measure version: 0.0.1.9001 #>  #> ℹ Use `render_validation_report()` to generate document"},{"path":"https://jameshwade.github.io/measure/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics augment, glance, tidy, tunable","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_pack.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Technique Pack — register_measure_pack","title":"Register a Technique Pack — register_measure_pack","text":"Registers external technique pack measure package. function called .onLoad() function technique pack packages.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_pack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Technique Pack — register_measure_pack","text":"","code":"register_measure_pack(pack_name, technique, version = NULL, description = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_pack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Technique Pack — register_measure_pack","text":"pack_name Package name (e.g., \"measure.sec\"). Use pkgname .onLoad() portability. technique Technique name (e.g., \"SEC/GPC\", \"FTIR\", \"Raman\"). version Package version. NULL, attempts retrieve installed package. description Brief description technique pack.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_pack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Register a Technique Pack — register_measure_pack","text":"Invisible TRUE.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_pack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register a Technique Pack — register_measure_pack","text":"","code":"if (FALSE) { # \\dontrun{ # In a technique pack's R/zzz.R file: .onLoad <- function(libname, pkgname) {   if (requireNamespace(\"measure\", quietly = TRUE)) {     measure::register_measure_pack(       pack_name = pkgname,       technique = \"SEC/GPC\",       description = \"Size Exclusion Chromatography\"     )   } } } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a Step from a Technique Pack — register_measure_step","title":"Register a Step from a Technique Pack — register_measure_step","text":"Registers recipe step measure package. function called .onLoad() function technique pack packages registering pack register_measure_pack().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a Step from a Technique Pack — register_measure_step","text":"","code":"register_measure_step(   step_name,   pack_name,   category = \"processing\",   description = \"\",   technique = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a Step from a Technique Pack — register_measure_step","text":"step_name Full step function name (e.g., \"step_sec_mw_averages\"). pack_name Source package name. Use pkgname .onLoad(). category Step category (e.g., \"preprocessing\", \"calculation\"). description Brief description step . technique Technique name. NULL, inherits registered pack.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Register a Step from a Technique Pack — register_measure_step","text":"Invisible TRUE.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Register a Step from a Technique Pack — register_measure_step","text":"Registration idempotent: calling function multiple times pack_name step_name update rather duplicate entry.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/register_measure_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register a Step from a Technique Pack — register_measure_step","text":"","code":"if (FALSE) { # \\dontrun{ # In a technique pack's R/zzz.R file: measure::register_measure_step(   step_name = \"step_sec_mw_averages\",   pack_name = pkgname,   category = \"calculation\",   description = \"Calculate Mn, Mw, Mz, dispersity\" ) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Render a Validation Report to Document Format — render_validation_report","title":"Render a Validation Report to Document Format — render_validation_report","text":"Renders measure_validation_report object HTML, PDF, Word format using standardized Quarto templates. Templates follow either ICH Q2(R2) USP <1225> validation report structures.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render a Validation Report to Document Format — render_validation_report","text":"","code":"render_validation_report(   report,   output_file = NULL,   output_format = c(\"html\", \"pdf\", \"docx\"),   template = c(\"ich_q2\", \"usp_1225\"),   output_dir = \".\",   include_plots = TRUE,   include_raw_data = FALSE,   open = interactive(),   quiet = FALSE,   ... )"},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render a Validation Report to Document Format — render_validation_report","text":"report measure_validation_report object created measure_validation_report(). output_file Output file path. NULL, uses report title appropriate extension. output_format Output format: \"html\" (default), \"pdf\", \"docx\". PDF requires LaTeX installation (e.g., TinyTeX). template Template style: \"ich_q2\" (default) ICH Q2(R2) layout, \"usp_1225\" USP <1225> compendial layout. output_dir Directory output file. Default: current directory. include_plots Logical; include diagnostic plots? Default: TRUE. include_raw_data Logical; include raw data tables appendix? Default: FALSE. open Logical; open rendered document? Default: TRUE interactive sessions. quiet Logical; suppress Quarto rendering messages? Default: FALSE. ... Additional arguments passed quarto::quarto_render().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Render a Validation Report to Document Format — render_validation_report","text":"Invisibly returns path rendered document.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"template-styles","dir":"Reference","previous_headings":"","what":"Template Styles","title":"Render a Validation Report to Document Format — render_validation_report","text":"ICH Q2(R2) Template (template = \"ich_q2\"): Organized validation characteristic (specificity, linearity, etc.) Includes performance-based lifecycle considerations Structured regulatory submission USP <1225> Template (template = \"usp_1225\"): Compendial validation structure Category-based organization (, II, III, IV) Emphasis system suitability","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Render a Validation Report to Document Format — render_validation_report","text":"HTML output: Requires quarto package PDF output: Requires quarto package LaTeX (TinyTeX recommended) DOCX output: Requires quarto package Install Quarto https://quarto.org/docs/get-started/. Install TinyTeX quarto::quarto_install_tinytex().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/render_validation_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Render a Validation Report to Document Format — render_validation_report","text":"","code":"if (FALSE) { # \\dontrun{ # Create a validation report (see measure_validation_report examples) report <- measure_validation_report(   title = \"Method Validation Report\",   method_name = \"HPLC Assay\",   analyst = \"J. Smith\" )  # Render to HTML with ICH Q2 template render_validation_report(report, output_format = \"html\")  # Render to PDF with USP template render_validation_report(   report,   output_format = \"pdf\",   template = \"usp_1225\",   output_file = \"validation_report.pdf\" )  # Render to Word for editing render_validation_report(report, output_format = \"docx\") } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/required_pkgs.recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Set package dependencies — required_pkgs.step_measure_align_dtw","title":"Set package dependencies — required_pkgs.step_measure_align_dtw","text":"Set package dependencies","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/required_pkgs.recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set package dependencies — required_pkgs.step_measure_align_dtw","text":"","code":"# S3 method for class 'step_measure_align_dtw' required_pkgs(x, ...)  # S3 method for class 'step_measure_align_ptw' required_pkgs(x, ...)  # S3 method for class 'step_measure_augment_noise' required_pkgs(x, ...)  # S3 method for class 'step_measure_augment_shift' required_pkgs(x, ...)  # S3 method for class 'step_measure_augment_scale' required_pkgs(x, ...)  # S3 method for class 'step_measure_integrals' required_pkgs(x, ...)  # S3 method for class 'step_measure_ratios' required_pkgs(x, ...)  # S3 method for class 'step_measure_moments' required_pkgs(x, ...)  # S3 method for class 'step_measure_bin' required_pkgs(x, ...)  # S3 method for class 'step_measure_mw_averages' required_pkgs(x, ...)  # S3 method for class 'step_measure_mw_fractions' required_pkgs(x, ...)  # S3 method for class 'step_measure_mw_distribution' required_pkgs(x, ...)  # S3 method for class 'step_measure_resample' required_pkgs(x, ...)  # S3 method for class 'step_measure_savitzky_golay' required_pkgs(x, ...)  # S3 method for class 'step_measure_emsc' required_pkgs(x, ...)  # S3 method for class 'step_measure_osc' required_pkgs(x, ...)  # S3 method for class 'step_measure_smooth_wavelet' required_pkgs(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/required_pkgs.recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set package dependencies — required_pkgs.step_measure_align_dtw","text":"x step object. ... used.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"SEC/GPC Calibration Standards Summary — sec_calibration","title":"SEC/GPC Calibration Standards Summary — sec_calibration","text":"Summary information polystyrene calibration standards used sec_chromatograms. Contains known molecular weights peak retention times needed construct calibration curve.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_calibration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SEC/GPC Calibration Standards Summary — sec_calibration","text":"tibble 5 observations 3 variables: standard Standard name (e.g., \"PS_1k\") mw Known molecular weight g/mol peak_time Peak elution time minutes","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_calibration.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SEC/GPC Calibration Standards Summary — sec_calibration","text":"Simulated data generated measure package. See data-raw/generate_datasets.R generation script.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_calibration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SEC/GPC Calibration Standards Summary — sec_calibration","text":"calibration curve SEC/GPC relates log(MW) retention time. simulated data: log10(MW) = 9.5 - 0.35 * time","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SEC/GPC Calibration Standards Summary — sec_calibration","text":"","code":"data(sec_calibration)  # View calibration data sec_calibration #> # A tibble: 5 × 3 #>   standard     mw peak_time #>   <chr>     <dbl>     <dbl> #> 1 PS_1k      1000      18.6 #> 2 PS_5k      5000      16.6 #> 3 PS_20k    20000      14.9 #> 4 PS_100k  100000      12.9 #> 5 PS_500k  500000      10.9  # Create calibration curve (if ggplot2 available) if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   ggplot(sec_calibration, aes(x = peak_time, y = log10(mw))) +     geom_point(size = 3) +     geom_smooth(method = \"lm\", se = FALSE) +     labs(x = \"Peak Retention Time (min)\", y = \"log10(MW)\",          title = \"SEC Calibration Curve\") } #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_chromatograms.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","title":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","text":"Simulated Size Exclusion Chromatography (SEC) / Gel Permeation Chromatography (GPC) data demonstration molecular weight analysis. dataset includes narrow polystyrene calibration standards polymer samples broad molecular weight distributions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_chromatograms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","text":"tibble 7,510 observations 6 variables: sample_id Sample identifier (standard polymer name) sample_type Either \"standard\" \"sample\" elution_time Elution/retention time minutes ri_signal Refractive index detector signal (arbitrary units) known_mw Known weight-average molecular weight (g/mol) known_dispersity Known dispersity (Mw/Mn); ~1.05 standards","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_chromatograms.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","text":"Simulated data generated measure package. See data-raw/generate_datasets.R generation script.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_chromatograms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","text":"SEC/GPC separates molecules hydrodynamic size, larger molecules eluting smaller ones. allows determination molecular weight distributions averages (Mn, Mw, Mz, dispersity). dataset useful demonstrating: Baseline correction chromatography Calibration curve construction using standards Molecular weight calculations (step_measure_mw_averages) Molecular weight distribution analysis dataset contains: Calibration Standards (narrow dispersity polystyrene): PS_1k: 1,000 g/mol PS_5k: 5,000 g/mol PS_20k: 20,000 g/mol PS_100k: 100,000 g/mol PS_500k: 500,000 g/mol Polymer Samples (broad distribution): Polymer_A Polymer_E varying Mw dispersity calibration relationship follows: log10(MW) = 9.5 - 0.35 * time","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/sec_chromatograms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated SEC/GPC Chromatography Data — sec_chromatograms","text":"","code":"data(sec_chromatograms)  # View structure str(sec_chromatograms) #> tibble [7,510 × 6] (S3: tbl_df/tbl/data.frame) #>  $ sample_id       : chr [1:7510] \"PS_1k\" \"PS_1k\" \"PS_1k\" \"PS_1k\" ... #>  $ sample_type     : chr [1:7510] \"standard\" \"standard\" \"standard\" \"standard\" ... #>  $ elution_time    : num [1:7510] 5 5.02 5.04 5.06 5.08 5.1 5.12 5.14 5.16 5.18 ... #>  $ ri_signal       : num [1:7510] 1.63 2.29 2.95 1.89 1.97 ... #>  $ known_mw        : num [1:7510] 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ... #>  $ known_dispersity: num [1:7510] 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 ...  # Separate standards and samples library(dplyr) standards <- sec_chromatograms |> filter(sample_type == \"standard\") samples <- sec_chromatograms |> filter(sample_type == \"sample\")  # Plot standards (if ggplot2 available) if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   ggplot(standards, aes(x = elution_time, y = ri_signal, color = sample_id)) +     geom_line() +     labs(x = \"Elution Time (min)\", y = \"RI Signal\",          title = \"SEC Calibration Standards\",          color = \"Standard\") }"},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Measure Roles in a Recipe — set_measure_roles","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"Batch assign roles columns based detected types explicit patterns. convenience wrapper around recipes::update_role() common analytical data patterns.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"","code":"set_measure_roles(   recipe,   id_cols = NULL,   blank_cols = NULL,   qc_cols = NULL,   standard_cols = NULL,   metadata_cols = NULL,   measure_cols = NULL )"},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"recipe recipe object. id_cols Column(s) assign \"id\" role. Accepts tidyselect. blank_cols Column(s) assign \"blank\" role. Accepts tidyselect. qc_cols Column(s) assign \"qc\" role. Accepts tidyselect. standard_cols Column(s) assign \"standard\" role. Accepts tidyselect. metadata_cols Column(s) assign \"metadata\" role. Accepts tidyselect. measure_cols Column(s) assign \"measure\" role. Accepts tidyselect.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"Updated recipe object roles assigned.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"Common roles analytical chemistry workflows:","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/set_measure_roles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set Measure Roles in a Recipe — set_measure_roles","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes)  # Basic role assignment rec <- recipe(outcome ~ ., data = my_data) |>   set_measure_roles(     id_cols = sample_id,     metadata_cols = c(batch, operator)   )  # With QC and blank identification by column name patterns rec <- recipe(outcome ~ ., data = my_data) |>   set_measure_roles(     id_cols = sample_id,     blank_cols = starts_with(\"blank_\"),     qc_cols = starts_with(\"qc_\")   ) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/smooth_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for smoothing steps — smooth_window","title":"Parameters for smoothing steps — smooth_window","text":"smooth_window() controls window size moving average median smoothing. smooth_sigma() controls standard deviation Gaussian smoothing. fourier_cutoff() controls frequency cutoff Fourier filtering.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/smooth_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for smoothing steps — smooth_window","text":"","code":"smooth_window(range = c(3L, 21L), trans = NULL)  smooth_sigma(range = c(0.5, 5), trans = NULL)  fourier_cutoff(range = c(0.01, 0.5), trans = NULL)  despike_threshold(range = c(2, 10), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/smooth_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for smoothing steps — smooth_window","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/smooth_window.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameters for smoothing steps — smooth_window","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/smooth_window.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for smoothing steps — smooth_window","text":"","code":"smooth_window() #> Smoothing Window Size (quantitative) #> Range: [3, 21] smooth_sigma() #> Gaussian Sigma (quantitative) #> Range: [0.5, 5] fourier_cutoff() #> Fourier Cutoff Frequency (quantitative) #> Range: [0.01, 0.5]"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Transmittance to Absorbance — step_measure_absorbance","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"step_measure_absorbance() creates specification recipe step converts transmittance values absorbance using Beer-Lambert law.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"","code":"step_measure_absorbance(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_absorbance\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"step applies Beer-Lambert law transformation: $$= -\\log_{10}(T)$$ \\(T\\) transmittance \\(\\) absorbance. Important: Transmittance values range (0, 1] (0, 100]. Zero negative values produce -Inf NaN warning. measurement locations preserved unchanged.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_absorbance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Transmittance to Absorbance — step_measure_absorbance","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_absorbance() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation Optimized Warping Alignment — step_measure_align_cow","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"step_measure_align_cow() creates specification recipe step aligns spectra using Correlation Optimized Warping (COW). method uses piecewise linear warping correct non-linear shifts.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"","code":"step_measure_align_cow(   recipe,   measures = NULL,   reference = c(\"mean\", \"median\", \"first\"),   segment_length = 30L,   slack = 1L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_align_cow\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"recipe recipe object. measures optional character vector measure column names. reference determine reference: \"mean\" (default, mean spectrum training), \"median\" (median spectrum training), \"first\" (first sample). segment_length Length segment warping. Default 30. Tunable via align_segment_length(). slack Maximum compression/expansion per segment points. Default 1. slack 1 means segment can shrink expand 1 point. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"Correlation Optimized Warping (COW) divides signals segments uses dynamic programming find optimal piecewise linear warping maximizes correlation reference spectrum. Key parameters: segment_length: Controls resolution warping. Smaller segments allow local corrections increase computation. slack: Controls much segment can stretch compress. Larger values allow flexibility may introduce artifacts. pure R implementation based Nielsen et al. (1998).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"Nielsen, N.P.V., Carstensen, J.M., Smedsgaard, J. (1998). Aligning single multiple wavelength chromatographic profiles chemometric data analysis using correlation optimised warping. Journal Chromatography , 805, 17-35.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_cow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation Optimized Warping Alignment — step_measure_align_cow","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_align_cow(segment_length = 20, slack = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamic Time Warping Alignment — step_measure_align_dtw","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"step_measure_align_dtw() creates specification recipe step aligns spectra using Dynamic Time Warping (DTW). method can handle non-linear distortions x-axis.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"","code":"step_measure_align_dtw(   recipe,   measures = NULL,   reference = c(\"mean\", \"median\", \"first\"),   window_type = c(\"none\", \"sakoechiba\", \"slantedband\"),   window_size = 10L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_align_dtw\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"recipe recipe object. measures optional character vector measure column names. reference determine reference: \"mean\" (default): Use mean spectrum training \"median\": Use median spectrum training \"first\": Use first sample window_type Windowing constraint DTW. One \"none\" (default), \"sakoechiba\", \"slantedband\". window_size Window size constrained DTW. Default 10. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"DTW finds optimal non-linear alignment two sequences minimizing distance measure allowing warping time/x-axis. useful : Chromatographic peak alignment Correcting non-linear retention time shifts Aligning spectra complex distortions Requires dtw package installed.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_dtw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dynamic Time Warping Alignment — step_measure_align_dtw","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_align_dtw() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Time Warping Alignment — step_measure_align_ptw","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"step_measure_align_ptw() creates specification recipe step aligns spectra using Parametric Time Warping (PTW). method uses polynomial warping functions correct shifts distortions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"","code":"step_measure_align_ptw(   recipe,   measures = NULL,   reference = c(\"mean\", \"median\", \"first\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_align_ptw\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"recipe recipe object. measures optional character vector measure column names. reference determine reference: \"mean\" (default, mean spectrum training), \"median\" (median spectrum training), \"first\" (first sample). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"Parametric Time Warping optimizes polynomial warping coefficients maximize correlation sample reference spectrum. corrects smooth, continuous distortions x-axis. Requires ptw package installed.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"Eilers, P.H.C. (2004). Parametric Time Warping. Analytical Chemistry, 76(2), 404-411.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_ptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric Time Warping Alignment — step_measure_align_ptw","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_align_ptw() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Align to Reference Spectrum — step_measure_align_reference","title":"Align to Reference Spectrum — step_measure_align_reference","text":"step_measure_align_reference() creates specification recipe step aligns spectra user-provided reference spectrum using cross-correlation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Align to Reference Spectrum — step_measure_align_reference","text":"","code":"step_measure_align_reference(   recipe,   measures = NULL,   ref_spectrum,   max_shift = 10L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_align_reference\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Align to Reference Spectrum — step_measure_align_reference","text":"recipe recipe object. measures optional character vector measure column names. ref_spectrum numeric vector containing reference spectrum. Must length measurement spectra. max_shift Maximum shift (points) consider. Default 10. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Align to Reference Spectrum — step_measure_align_reference","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Align to Reference Spectrum — step_measure_align_reference","text":"Similar step_measure_align_shift(), uses externally provided reference spectrum instead computing one training data. useful known standard calibration spectrum.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Align to Reference Spectrum — step_measure_align_reference","text":"","code":"library(recipes)  # Create a reference spectrum (in practice, this would be from calibration) ref <- rep(1, 100)  # placeholder  # Note: This example would need matching spectrum lengths to work if (FALSE) { # \\dontrun{ rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_align_reference(ref_spectrum = ref) |>   prep() } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift Alignment via Cross-Correlation — step_measure_align_shift","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"step_measure_align_shift() creates specification recipe step aligns spectra finding optimal shift using cross-correlation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"","code":"step_measure_align_shift(   recipe,   measures = NULL,   max_shift = 10L,   reference = c(\"mean\", \"median\", \"first\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_align_shift\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"recipe recipe object. measures optional character vector measure column names. max_shift Maximum shift (points) consider. Default 10. Tunable via align_max_shift(). reference determine reference: \"mean\" (default): Use mean spectrum training \"median\": Use median spectrum training \"first\": Use first sample role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"step corrects small linear shifts spectra, can occur due : Wavelength calibration drift Sample positioning differences Temperature effects instrument optimal shift found maximizing cross-correlation spectrum reference. shifting, edge values filled constant extrapolation.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_align_shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shift Alignment via Cross-Correlation — step_measure_align_shift","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_align_shift(max_shift = 5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Random Noise to Measurements — step_measure_augment_noise","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"step_measure_augment_noise() creates specification recipe step adds controlled random noise spectral data data augmentation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"","code":"step_measure_augment_noise(   recipe,   sd = 0.01,   distribution = c(\"gaussian\", \"uniform\"),   relative = TRUE,   measures = NULL,   role = NA,   trained = FALSE,   skip = TRUE,   id = recipes::rand_id(\"measure_augment_noise\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"recipe recipe object. sd Standard deviation noise. relative = TRUE (default), relative signal range (0.01 = 1% range). relative = FALSE, absolute noise level. distribution Noise distribution: \"gaussian\" (default) \"uniform\". relative Logical. TRUE (default), sd relative signal range. measures optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? Default TRUE, meaning augmentation applies training. id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"Data augmentation adds variability training data improve model robustness. Adding noise simulates measurement uncertainty helps models generalize better. Default behavior (skip = TRUE): augmentation applied prep() training data. bake() called new data, step skipped. Reproducibility: noise deterministic based row content, input always produces augmented output within session.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_noise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Random Noise to Measurements — step_measure_augment_noise","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_augment_noise(sd = 0.02) |>   prep()  # Noise only applied to training data bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Intensity Scaling — step_measure_augment_scale","title":"Random Intensity Scaling — step_measure_augment_scale","text":"step_measure_augment_scale() creates specification recipe step applies random intensity scaling scale invariance training.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Intensity Scaling — step_measure_augment_scale","text":"","code":"step_measure_augment_scale(   recipe,   range = c(0.9, 1.1),   measures = NULL,   role = NA,   trained = FALSE,   skip = TRUE,   id = recipes::rand_id(\"measure_augment_scale\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Intensity Scaling — step_measure_augment_scale","text":"recipe recipe object. range numeric vector length 2 specifying range scaling factors. Default c(0.9, 1.1), meaning 90%-110% original. measures optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? Default TRUE. id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Intensity Scaling — step_measure_augment_scale","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Intensity Scaling — step_measure_augment_scale","text":"step multiplies spectrum values random scaling factor sampled uniformly specified range. helps models become robust variations signal intensity. Common use cases: Simulating concentration variations Compensating detector sensitivity differences Making models robust sample preparation variability Default behavior (skip = TRUE): scaling applied training. predicting new data, step skipped.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_scale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Intensity Scaling — step_measure_augment_scale","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_augment_scale(range = c(0.8, 1.2)) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Random X-axis Shifts — step_measure_augment_shift","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"step_measure_augment_shift() creates specification recipe step applies random shifts along x-axis shift invariance training.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"","code":"step_measure_augment_shift(   recipe,   max_shift = 1,   measures = NULL,   role = NA,   trained = FALSE,   skip = TRUE,   id = recipes::rand_id(\"measure_augment_shift\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"recipe recipe object. max_shift Maximum shift amount location units. actual shift uniformly sampled [-max_shift, max_shift]. measures optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? Default TRUE. id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"step adds random x-axis shifts help models become invariant small retention time wavelength shifts. particularly useful chromatographic data peak positions may vary slightly. spectrum interpolated shifted positions using linear interpolation. Values outside original range use boundary values. Default behavior (skip = TRUE): shift applied training. predicting new data, step skipped.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_augment_shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Random X-axis Shifts — step_measure_augment_shift","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_augment_shift(max_shift = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"step_measure_baseline_airpls() creates specification recipe step applies airPLS baseline correction. method automatically adjusts weights based difference signal fitted baseline.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"","code":"step_measure_baseline_airpls(   recipe,   measures = NULL,   lambda = 1e+05,   max_iter = 50L,   tol = 0.001,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_airpls\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"recipe recipe object. measures optional character vector measure column names. lambda Smoothness parameter. Higher values produce smoother baselines. Default 1e5. Tunable via baseline_lambda(). max_iter Maximum number iterations. Default 50. tol Convergence tolerance weight changes. Default 1e-3. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"airPLS (Adaptive Iteratively Reweighted Penalized Least Squares) improvement standard ALS automatically adapts asymmetry parameter based residuals. Key features: need manually set asymmetry parameter Good signals varying baseline curvature Robust different peak heights","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"Zhang, Z.M., Chen, S., & Liang, Y.Z. (2010). Baseline correction using adaptive iteratively reweighted penalized least squares. Analyst, 135, 1138-1146.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_airpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adaptive Iteratively Reweighted Penalized Least Squares Baseline — step_measure_baseline_airpls","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_airpls(lambda = 1e5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":null,"dir":"Reference","previous_headings":"","what":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"step_measure_baseline_als() creates specification recipe step applies Asymmetric Least Squares baseline correction measurement data. ALS iteratively fits smooth baseline giving less weight points baseline (peaks).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"","code":"step_measure_baseline_als(   recipe,   measures = NULL,   lambda = 1e+06,   p = 0.01,   max_iter = 20L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_als\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. lambda Smoothness parameter (2nd derivative constraint). Higher values produce smoother baselines. Default 1e6. Typical range 1e3 1e9. Tunable via baseline_lambda(). p Asymmetry parameter controlling weight positive residuals. Values near 0 (e.g., 0.001-0.05) work well spectra peaks baseline. Default 0.01. Tunable via baseline_asymmetry(). max_iter Maximum number iterations. Default 20. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"Asymmetric Least Squares (ALS) baseline correction uses Whittaker smoother asymmetric weights fit baseline follows lower envelope spectrum. algorithm iteratively: 1 . Fits smooth baseline using penalized least squares 2. Calculates residuals (spectrum - baseline) 3. Assigns weights: p positive residuals (peaks), 1-p negative 4. Repeats convergence max iterations smoothness controlled lambda, penalizes second derivative baseline. Larger lambda produces smoother baselines. ALS particularly effective : NIR/IR spectroscopy broad baseline drift Raman spectroscopy fluorescence background UV-Vis spectroscopy scattering effects selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"tidy() step, tibble columns terms, lambda, p, id returned.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"tuning","dir":"Reference","previous_headings":"","what":"Tuning","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"step parameters can tuned: lambda: Use baseline_lambda() (log10 scale recommended) p: Use baseline_asymmetry()","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"Eilers, P.H.C. Boelens, H.F.M. (2005). Baseline Correction Asymmetric Least Squares Smoothing. Leiden University Medical Centre report.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_als.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Asymmetric Least Squares (ALS) Baseline Correction — step_measure_baseline_als","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_als(lambda = 1e6, p = 0.01) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"step_measure_baseline_arpls() creates specification recipe step applies arPLS baseline correction using asymmetric weighting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"","code":"step_measure_baseline_arpls(   recipe,   measures = NULL,   lambda = 1e+05,   ratio = 0.001,   max_iter = 50L,   tol = 0.001,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_arpls\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"recipe recipe object. measures optional character vector measure column names. lambda Smoothing parameter. Larger values produce smoother baselines. Default 1e5. ratio Asymmetric weighting ratio. Default 0.001. max_iter Maximum number iterations. Default 50. tol Convergence tolerance. Default 1e-3. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"arPLS algorithm uses asymmetric least squares ratio-based weighting scheme. robust peak interference works well signals varying baseline curvature. Reference: Baek et al. (2015), Analyst 140, 250-257","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_arpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Asymmetrically Reweighted Penalized Least Squares Baseline Correction — step_measure_baseline_arpls","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_arpls(lambda = 1e5) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"step_measure_baseline_auto() creates specification recipe step automatically selects applies best baseline correction method based signal characteristics.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"","code":"step_measure_baseline_auto(   recipe,   measures = NULL,   methods = c(\"rolling\", \"airpls\", \"snip\", \"tophat\", \"minima\"),   role = NA,   trained = FALSE,   selected_method = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_auto\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"recipe recipe object. measures optional character vector measure column names. methods Character vector methods consider. Default includes available methods. role used. trained Logical indicating step trained. selected_method method selected training (internal). skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"step analyzes signal characteristics (noise level, baseline curvature, peak density) training selects appropriate baseline correction method. selected method applied consistently baking. Method selection heuristics: High noise, smooth baseline: rolling ball Complex curvature: airPLS arPLS Sharp peaks: SNIP top-hat Simple baseline: polynomial minima","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_auto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic Baseline Correction Method Selection — step_measure_baseline_auto","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_auto() |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"step_measure_baseline_custom() creates specification recipe step applies user-provided function baseline correction. allows flexible, custom baseline estimation algorithms.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"","code":"step_measure_baseline_custom(   recipe,   .fn,   ...,   subtract = TRUE,   measures = NULL,   tunable = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_custom\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"recipe recipe object. step added sequence operations recipe. .fn function formula baseline estimation. function accept measure_tbl (tibble location value columns) return numeric vector baseline values length input. Formulas converted functions via rlang::as_function(), .x represents measure_tbl. ... Additional arguments passed .fn. captured quosures evaluated bake time. subtract TRUE (default), baseline subtracted signal. FALSE, baseline values replace original values (useful extracting baselines). measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. tunable optional named list specifying arguments ... tunable. element list pkg, fun, optionally range. See Details. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"step allows use baseline estimation algorithm providing custom function. function receives measure_tbl object (tibble location value columns) return numeric vector estimated baseline values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"function-contract","dir":"Reference","previous_headings":"","what":"Function Contract","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"function : Accept measure_tbl first argument Return numeric vector length nrow(measure_tbl) Handle NA values appropriately","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"formula-interface","dir":"Reference","previous_headings":"","what":"Formula Interface","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"can use formula instead function. formula converted function .x represents measure_tbl:","code":"# These are equivalent: step_measure_baseline_custom(.fn = function(x) mean(x$value)) step_measure_baseline_custom(.fn = ~ mean(.x$value))"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"tunability","dir":"Reference","previous_headings":"","what":"Tunability","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"make parameters tunable dials, provide tunable argument:   selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":"step_measure_baseline_custom(   .fn = ~ stats::loess(.x$value ~ .x$location, span = span)$fitted,   span = 0.5,   tunable = list(     span = list(pkg = \"dials\", fun = \"degree\", range = c(0.1, 0.9))   ) )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"tidy() step, tibble columns terms, subtract, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_custom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Custom Baseline Correction with User-Provided Function — step_measure_baseline_custom","text":"","code":"library(recipes)  # Simple polynomial baseline using a function poly_baseline <- function(x) {   fit <- lm(x$value ~ poly(x$location, 2))   predict(fit) }  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_custom(.fn = poly_baseline) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows  # Using formula interface with additional parameters rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_custom(     .fn = ~ stats::loess(.x$value ~ .x$location, span = span)$fitted,     span = 0.5   ) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":null,"dir":"Reference","previous_headings":"","what":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"step_measure_baseline_gpc() creates specification recipe step applies baseline correction optimized Gel Permeation Chromatography (GPC) Size Exclusion Chromatography (SEC) data. method estimates baseline interpolating baseline regions start end chromatogram. step superseded measure.sec::step_sec_baseline(). new code, recommend using measure.sec package provides complete SEC/GPC analysis functionality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"","code":"step_measure_baseline_gpc(   recipe,   measures = NULL,   left_frac = 0.05,   right_frac = 0.05,   method = \"linear\",   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_gpc\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. left_frac Fraction points beginning use left baseline region. Default 0.05 (first 5% data points). right_frac Fraction points end use right baseline region. Default 0.05 (last 5% data points). method Method baseline estimation. One : \"linear\" (default): Linear interpolation left right means \"median\": Uses median baseline regions (robust outliers) \"spline\": Smooth spline baseline regions role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"GPC/SEC chromatograms typically distinct baseline regions beginning end polymer elutes. step leverages characteristic : 1 2. Computing representative baseline value region (mean median) 3. Interpolating values estimate full baseline 4. Subtracting estimated baseline signal left_frac right_frac parameters control much chromatogram considered \"baseline\". Choose values : Include flat, signal-free regions Exclude polymer peaks system peaks large enough average noise Unlike general-purpose baseline methods like ALS polynomial fitting, approach specifically designed characteristic shape GPC/SEC chromatograms computationally fast. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"tidy() step, tibble columns terms, left_frac, right_frac, method, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_gpc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GPC/SEC Baseline Correction — step_measure_baseline_gpc","text":"","code":"library(recipes)  # Using meats_long as example (works on any measurement data) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_gpc(left_frac = 0.1, right_frac = 0.1) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"step_measure_baseline_minima() creates specification recipe step estimates baseline interpolating local minima.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"","code":"step_measure_baseline_minima(   recipe,   measures = NULL,   window_size = 50L,   method = c(\"spline\", \"linear\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_minima\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"recipe recipe object. measures optional character vector measure column names. window_size Window size finding local minima. Default 50. method Interpolation method: \"linear\" \"spline\". Default \"spline\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"method finds local minima within specified windows, interpolates create baseline estimate. intuitive works well baseline points clearly identifiable local minima.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_minima.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Minima Interpolation Baseline Correction — step_measure_baseline_minima","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_minima(window_size = 30, method = \"spline\") |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":null,"dir":"Reference","previous_headings":"","what":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"step_measure_baseline_morph() creates specification recipe step applies iterative morphological baseline correction using erosion dilation operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"","code":"step_measure_baseline_morph(   recipe,   measures = NULL,   half_window = 50L,   iterations = 10L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_morph\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"recipe recipe object. measures optional character vector measure column names. half_window Half-window size structuring element. Default 50. iterations Number erosion-dilation iterations. Default 10. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"method applies iterative morphological operations (erosion followed dilation) estimate baseline. Multiple iterations can help refine baseline estimate complex signals.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_morph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Iterative Morphological Baseline Correction — step_measure_baseline_morph","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_morph(half_window = 30, iterations = 5) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial Baseline Correction — step_measure_baseline_poly","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"step_measure_baseline_poly() creates specification recipe step applies polynomial baseline correction measurement data. method fits polynomial spectrum, optionally iterative peak exclusion.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"","code":"step_measure_baseline_poly(   recipe,   measures = NULL,   degree = 2L,   max_iter = 0L,   threshold = 1.5,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_poly\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. degree Polynomial degree baseline fitting. Default 2 (quadratic). Higher degrees fit complex baselines risk overfitting. Tunable via baseline_degree(). max_iter Maximum number iterations peak exclusion. Default 0 (iteration, fit polynomial points). Set positive integer iteratively exclude points fitted baseline. threshold Number standard deviations baseline point excluded iterative fitting. Default 1.5. used max_iter > 0. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"Polynomial baseline correction fits polynomial function spectrum subtracts . effective removing smooth, curved baselines caused instrumental drift, scattering, slowly varying effects. max_iter > 0, algorithm uses iterative peak exclusion: Fit polynomial points Calculate residuals (spectrum - baseline) Exclude points residual > threshold * SD(residuals) Refit polynomial remaining points Repeat convergence max_iter reached iterative approach prevents peaks pulling baseline estimate. Degree selection: degree = 1: Linear baseline (simple drift) degree = 2: Quadratic (common, handles gentle curvature) degree = 3-5: Higher-order (complex baselines, use cautiously) selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"tidy() step, tibble columns terms, degree, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_poly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polynomial Baseline Correction — step_measure_baseline_poly","text":"","code":"library(recipes)  # Simple polynomial baseline (no iteration) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_poly(degree = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows  # With iterative peak exclusion rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_poly(degree = 3, max_iter = 5, threshold = 2) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"step_measure_baseline_py() creates specification recipe step applies baseline correction using Python pybaselines library, provides 50+ baseline correction algorithms.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"","code":"step_measure_baseline_py(   recipe,   method = \"asls\",   ...,   subtract = TRUE,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_py\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"recipe recipe object. step added sequence operations recipe. method pybaselines method use. Common methods include: Whittaker methods: \"asls\", \"iasls\", \"airpls\", \"arpls\", \"drpls\", \"psalsa\" Polynomial methods: \"poly\", \"modpoly\", \"imodpoly\", \"loess\", \"quant_reg\" Morphological: \"mor\", \"imor\", \"rolling_ball\", \"tophat\" Spline: \"pspline_asls\", \"pspline_airpls\", \"mixture_model\" Smooth: \"snip\", \"swima\", \"noise_median\" Classification: \"dietrich\", \"golotvin\", \"fastchrom\" See pybaselines documentation full list. ... Additional arguments passed pybaselines method. Common parameters include: lam: Smoothness parameter Whittaker methods (default varies method) p: Asymmetry parameter ALS methods (default ~0.01) poly_order: Polynomial degree polynomial methods half_window: Window size morphological methods max_half_window: Maximum window SNIP method subtract TRUE (default), baseline subtracted signal. FALSE, baseline values replace original values (useful extracting baselines). measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"step provides access comprehensive pybaselines Python library, implements 50 baseline correction algorithms across several categories:","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"whittaker-methods","dir":"Reference","previous_headings":"","what":"Whittaker Methods","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"Based penalized least squares asymmetric weights: asls: Asymmetric Least Squares (good general-purpose method) iasls: Improved ALS automatic smoothness selection airpls: Adaptive iteratively reweighted penalized least squares arpls: Asymmetrically reweighted penalized least squares psalsa: Peaked Signal's Asymmetric Least Squares Algorithm","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"polynomial-methods","dir":"Reference","previous_headings":"","what":"Polynomial Methods","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"Fit polynomials baseline regions: poly: Simple polynomial fitting modpoly: Modified polynomial (iterative) imodpoly: Improved modified polynomial loess: Local regression (LOESS)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"morphological-methods","dir":"Reference","previous_headings":"","what":"Morphological Methods","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"Based mathematical morphology: mor: Morphological opening imor: Improved morphological rolling_ball: Rolling ball algorithm tophat: Top-hat transform","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"step requires reticulate package Python pybaselines installed. Install pybaselines :   selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":"reticulate::py_require(\"pybaselines\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"tidy() step, tibble columns terms, method, subtract, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_py.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Python-Based Baseline Correction via pybaselines — step_measure_baseline_py","text":"","code":"if (FALSE) { # measure:::.pybaselines_available() library(recipes)  # Asymmetric Least Squares baseline correction rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_py(method = \"asls\", lam = 1e6, p = 0.01) |>   prep()  bake(rec, new_data = NULL)  # Using SNIP algorithm rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_py(method = \"snip\", max_half_window = 40) |>   prep() }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust Fitting Baseline Correction — step_measure_baseline_rf","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"step_measure_baseline_rf() creates specification recipe step applies robust fitting baseline correction measurement data. method uses local regression iterative reweighting fit baseline resistant peaks.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"","code":"step_measure_baseline_rf(   recipe,   measures = NULL,   span = 2/3,   maxit = c(5L, 5L),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_rf\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. span Controls amount smoothing. fraction data used computing fitted value. Default 2/3. Smaller values produce less smooth baselines follow local features closely. maxit length-2 integer vector specifying number iterations robust fit. first value asymmetric weighting function, second symmetric weighting. Default c(5, 5). role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"Robust fitting baseline correction uses local polynomial regression (LOESS/LOWESS) iterative reweighting estimate baseline. algorithm uses asymmetric weights initial iterations -weight peaks, symmetric weights final smoothing. method particularly effective : Spectra peaks varying widths Data baseline shape well-described polynomial Situations peaks influence baseline estimate span parameter controls trade-smoothness local adaptation: Larger span (e.g., 0.8): Smoother baseline, may miss local variations Smaller span (e.g., 0.3): local adaptation, may overfit selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"tidy() step, tibble columns terms, span, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust Fitting Baseline Correction — step_measure_baseline_rf","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_rf(span = 0.5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":null,"dir":"Reference","previous_headings":"","what":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"step_measure_baseline_rolling() creates specification recipe step applies rolling ball baseline correction. morphological approach \"rolls\" ball specified radius along underside spectrum.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"","code":"step_measure_baseline_rolling(   recipe,   measures = NULL,   window_size = 100,   smoothing = 50,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_rolling\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"recipe recipe object. measures optional character vector measure column names. window_size diameter rolling ball number points. Default 100. smoothing Additional smoothing window applied baseline. Default 50. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"rolling ball algorithm simulates rolling ball specified radius along underside spectrum. Points ball touches become baseline. effective : Chromatographic baselines Spectra gradual drift Data peaks narrower baseline features","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_rolling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rolling Ball Baseline Correction — step_measure_baseline_rolling","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_rolling(window_size = 50) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":null,"dir":"Reference","previous_headings":"","what":"SNIP Baseline Correction — step_measure_baseline_snip","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"step_measure_baseline_snip() creates specification recipe step applies SNIP (Statistics-sensitive Non-linear Iterative Peak-clipping) baseline correction.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"","code":"step_measure_baseline_snip(   recipe,   measures = NULL,   iterations = 40L,   decreasing = TRUE,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_snip\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"recipe recipe object. measures optional character vector measure column names. iterations Number clipping iterations. iterations produce lower baselines. Default 40. decreasing Logical. TRUE (default), iterations decrease iterations 1. FALSE, uses fixed window size. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"SNIP robust baseline estimation algorithm originally developed gamma-ray spectroscopy. works iteratively replacing point minimum average neighbors increasing distances. algorithm particularly effective : Spectra sharp peaks slowly varying baseline X-ray fluorescence diffraction Mass spectrometry","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"Ryan, C.G., et al. (1988). SNIP, statistics-sensitive background treatment quantitative analysis PIXE spectra geoscience applications. Nuclear Instruments Methods Physics Research B, 34, 396-402.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_snip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SNIP Baseline Correction — step_measure_baseline_snip","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_snip(iterations = 30) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":null,"dir":"Reference","previous_headings":"","what":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"step_measure_baseline_tophat() creates specification recipe step applies top-hat morphological baseline correction.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"","code":"step_measure_baseline_tophat(   recipe,   measures = NULL,   half_window = 50L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_baseline_tophat\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"recipe recipe object. measures optional character vector measure column names. half_window Half-window size structuring element. Default 50. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"top-hat transform morphological operation extracts bright features (peaks) dark background. computed difference original signal morphological opening. effective chromatography sharp, well-defined peaks smooth baseline.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_baseline_tophat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Top-Hat Morphological Baseline Correction — step_measure_baseline_tophat","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_baseline_tophat(half_window = 30) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Reference-Based Batch Correction — step_measure_batch_reference","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"step_measure_batch_reference() creates specification recipe step corrects batch effects using reference samples. simpler alternative ComBat-style correction require heavy dependencies.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"","code":"step_measure_batch_reference(   recipe,   ...,   batch_col = \"batch_id\",   sample_type_col = \"sample_type\",   reference_type = \"reference\",   method = c(\"median_ratio\", \"mean_ratio\", \"median_center\", \"mean_center\"),   target_batch = NULL,   min_ref = 2,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_batch_reference\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"recipe recipe object. ... One selector functions choose feature columns. batch_col Name column containing batch identifiers. sample_type_col Name column containing sample type. reference_type Value(s) sample_type_col identify reference samples use batch correction. Default \"reference\". method Correction method: \"median_ratio\" (default): Scale ratio reference medians \"mean_ratio\": Scale ratio reference means \"median_center\": Center batches common median \"mean_center\": Center batches common mean target_batch batch use reference. Default first batch (alphabetically). Can also \"global\" use global reference median/mean. min_ref Minimum number reference samples per batch. Default 2. role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"correction-methods","dir":"Reference","previous_headings":"","what":"Correction Methods","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"Median/Mean Ratio: Multiplies samples batch : target_reference / batch_reference preserves relative differences within batches aligning batch centers. Median/Mean Center: Subtracts difference batch reference target reference. appropriate log-transformed data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"reference-samples","dir":"Reference","previous_headings":"","what":"Reference Samples","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"Reference samples identical samples run batch (e.g., pooled QC, reference material). step error batch lacks sufficient reference samples.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_batch_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reference-Based Batch Correction — step_measure_batch_reference","text":"","code":"library(recipes)  # Data with batch effects data <- data.frame(   sample_id = paste0(\"S\", 1:20),   sample_type = rep(c(\"reference\", \"unknown\", \"unknown\", \"unknown\", \"reference\"), 4),   batch_id = rep(c(\"B1\", \"B1\", \"B2\", \"B2\"), 5),   feature1 = c(rep(100, 10), rep(120, 10)) + rnorm(20, sd = 5),  # Batch effect   feature2 = c(rep(50, 10), rep(45, 10)) + rnorm(20, sd = 2) )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_batch_reference(feature1, feature2, batch_col = \"batch_id\") |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":null,"dir":"Reference","previous_headings":"","what":"Spectral Binning — step_measure_bin","title":"Spectral Binning — step_measure_bin","text":"step_measure_bin() creates specification recipe step reduces spectrum fewer points averaging within bins.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spectral Binning — step_measure_bin","text":"","code":"step_measure_bin(   recipe,   n_bins = NULL,   bin_width = NULL,   method = c(\"mean\", \"sum\", \"median\", \"max\"),   measures = NULL,   role = NA,   trained = FALSE,   bin_breaks = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_bin\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spectral Binning — step_measure_bin","text":"recipe recipe object. n_bins Number bins (mutually exclusive bin_width). bin_width Width bin location units (mutually exclusive n_bins). method Aggregation method: \"mean\" (default), \"sum\", \"median\", \"max\". measures optional character vector measure column names. role used (modifies existing data). trained Logical indicating step trained. bin_breaks computed bin breaks (training). skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spectral Binning — step_measure_bin","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spectral Binning — step_measure_bin","text":"step reduces number points spectrum dividing x-axis bins aggregating values within bin. result replaces .measures column binned data. useful : Reducing data dimensionality Decreasing noise averaging Speeding downstream processing Aligning data different resolutions bin boundaries determined prep() training data stored consistent application new data.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_bin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spectral Binning — step_measure_bin","text":"","code":"library(recipes)  # Bin to 20 points rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_bin(n_bins = 20) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7  [20 × 2] #>  2     2  46    40.1    13.5  [20 × 2] #>  3     3  71     8.4    20.5  [20 × 2] #>  4     4  72.8   5.9    20.7  [20 × 2] #>  5     5  58.3  25.5    15.5  [20 × 2] #>  6     6  44    42.7    13.7  [20 × 2] #>  7     7  44    42.7    13.7  [20 × 2] #>  8     8  69.3  10.6    19.3  [20 × 2] #>  9     9  61.4  19.9    17.7  [20 × 2] #> 10    10  61.4  19.9    17.7  [20 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply X-Axis Calibration — step_measure_calibrate_x","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"step_measure_calibrate_x() creates specification recipe step transforms x-axis (location) values using calibration function calibration data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"","code":"step_measure_calibrate_x(   recipe,   calibration,   from = \"x\",   to = \"y\",   method = \"spline\",   extrapolate = FALSE,   measures = NULL,   role = NA,   trained = FALSE,   cal_fn = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_calibrate_x\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"recipe recipe object. step added sequence operations recipe. calibration calibration apply. Can : data.frame columns specified function takes location values returns calibrated values Column name calibration data.frame containing original x values. Default \"x\". Column name calibration data.frame containing calibrated values. Default \"y\". method Interpolation method using calibration data.frame: \"linear\": Linear interpolation \"spline\" (default): Cubic spline interpolation extrapolate Logical. TRUE, allow extrapolation outside calibration range. FALSE (default), values outside range return NA linear interpolation use spline extrapolation. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. cal_fn calibration function created training. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"X-axis calibration commonly used convert raw measurement units physically meaningful values. Common examples include: GPC/SEC: Convert retention time molecular weight (via log MW) Mass spectrometry: Apply m/z calibration corrections Spectroscopy: Convert pixel channel numbers wavelength/wavenumber calibration can provided either: Calibration data: data.frame known x→y mappings. step build interpolation function prep(). Calibration function: function directly transforms x values. Warning: step modifies location column. Subsequent steps see calibrated values. Make sure calibration appropriate data range. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"tidy() step, tibble columns terms, method, extrapolate, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_x.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply X-Axis Calibration — step_measure_calibrate_x","text":"","code":"library(recipes)  # Example: GPC molecular weight calibration # Calibration standards: retention_time -> log(MW) gpc_cal <- data.frame(   retention_time = c(10, 12, 14, 16, 18),   log_mw = c(6.5, 5.8, 5.0, 4.2, 3.5) )  # Note: meats_long doesn't have retention time, this is illustrative rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_calibrate_x(     calibration = function(x) log10(x + 1),  # Example transformation     method = \"spline\"   )  # With calibration data # rec <- recipe(...) |> #   step_measure_calibrate_x( #     calibration = gpc_cal, #     from = \"retention_time\", #     to = \"log_mw\", #     method = \"spline\" #   )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"step_measure_calibrate_y() creates specification recipe step applies response factor calibration function y-axis (value) values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"","code":"step_measure_calibrate_y(   recipe,   response_factor = 1,   calibration = NULL,   measures = NULL,   role = NA,   trained = FALSE,   cal_fn = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_calibrate_y\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"recipe recipe object. step added sequence operations recipe. response_factor numeric value multiply values . Default 1.0 (change). simple scalar calibration. calibration optional calibration function takes value(s) returns calibrated value(s). provided, takes precedence response_factor. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. cal_fn calibration function apply (built prep). skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"Y-axis calibration used convert raw signal intensities quantitative values. Common examples include: Chromatography: Apply detector response factors Spectroscopy: Apply molar absorptivity corrections Mass spectrometry: Apply ionization efficiency corrections Simple mode: Use response_factor multiply values constant. Complex mode: Use calibration provide function non-linear calibration curves (e.g., fitting standards). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"tidy() step, tibble columns terms, response_factor, has_calibration, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_calibrate_y.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Y-Axis Calibration (Response Factor) — step_measure_calibrate_y","text":"","code":"library(recipes)  # Simple response factor rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_calibrate_y(response_factor = 2.5)  # With calibration function (e.g., log transform) rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_calibrate_y(calibration = function(x) log10(x + 0.001))"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Centering — step_measure_center","title":"Mean Centering — step_measure_center","text":"step_measure_center() creates specification recipe step subtracts mean measurement location (column-wise centering). means computed training data applied new data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Centering — step_measure_center","text":"","code":"step_measure_center(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   learned_params = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_center\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Centering — step_measure_center","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_params named list containing learned means locations measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Centering — step_measure_center","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean Centering — step_measure_center","text":"Mean centering fundamental preprocessing step multivariate analysis methods like PCA PLS. removes average signal measurement location. data matrix \\(X\\) samples rows measurement locations columns, transformation : $$X_{centered} = X - \\bar{X}$$ \\(\\bar{X}\\) column-wise mean computed training data. means learned prep() training data stored use applying transformation new data bake(). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Mean Centering — step_measure_center","text":"tidy() step training, tibble learned means location returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Centering — step_measure_center","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_center() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":null,"dir":"Reference","previous_headings":"","what":"Align Multiple Channels to a Common Grid — step_measure_channel_align","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"step_measure_channel_align() creates specification recipe step aligns multiple measurement channels common location grid.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"","code":"step_measure_channel_align(   recipe,   ...,   method = c(\"union\", \"intersection\", \"reference\"),   reference = 1L,   interpolation = c(\"linear\", \"spline\", \"constant\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_channel_align\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"recipe recipe object. ... One selector functions choose measure columns. empty, measure columns used. method determine common grid: \"union\" (default): Use unique locations channels \"intersection\": Use locations present channels \"reference\": Use grid reference channel reference method = \"reference\", channel use reference. Can column name (character) column index (integer). Default 1 (first channel). interpolation Interpolation method missing values: \"linear\" (default): Linear interpolation \"spline\": Cubic spline interpolation \"constant\": Nearest neighbor (constant) role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"Multi-channel analytical instruments (e.g., LC-DAD, SEC multiple detectors) often produce measurements slightly different location grids channel. step aligns channels common grid, enabling: Direct comparison channels Channel combination ratio calculations Modeling consistent feature dimensions","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"grid-methods","dir":"Reference","previous_headings":"","what":"Grid Methods","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"Union: Creates grid containing unique locations channels. Values interpolated channels data. Intersection: Uses locations channels data. interpolation needed may lose data edges. Reference: Uses one channel's grid target. channels interpolated match.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_align.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Align Multiple Channels to a Common Grid — step_measure_channel_align","text":"","code":"library(recipes) library(tibble)  # Create sample multi-channel data df <- tibble(   id = rep(1:3, each = 10),   time_uv = rep(seq(0, 9, by = 1), 3),   absorbance_uv = rnorm(30, 100, 10),   time_ri = rep(seq(0.5, 9.5, by = 1), 3),   absorbance_ri = rnorm(30, 50, 5),   concentration = rep(c(10, 25, 50), each = 10) )  # Ingest as separate channels, then align rec <- recipe(concentration ~ ., data = df) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(absorbance_uv, location = vars(time_uv)) |>   step_measure_input_long(absorbance_ri, location = vars(time_ri)) |>   step_measure_channel_align(method = \"union\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Multiple Channels — step_measure_channel_combine","title":"Combine Multiple Channels — step_measure_channel_combine","text":"step_measure_channel_combine() creates specification recipe step combines multiple measurement channels single representation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Multiple Channels — step_measure_channel_combine","text":"","code":"step_measure_channel_combine(   recipe,   ...,   strategy = c(\"stack\", \"concat\", \"weighted_sum\", \"mean\"),   weights = NULL,   output_col = \".measures\",   remove_original = TRUE,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_channel_combine\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Multiple Channels — step_measure_channel_combine","text":"recipe recipe object. ... One selector functions choose measure columns. empty, measure columns used. strategy combine channels: \"stack\": Stack channels nD measurement channel dimension \"concat\": Concatenate channels single 1D measurement \"weighted_sum\": Compute weighted sum across channels \"mean\": Average across channels (equal weights) weights strategy = \"weighted_sum\", numeric vector weights. Must length number channels. Default equal weights. output_col Name output measure column. Default \".measures\". remove_original Logical. original channel columns removed? Default TRUE. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Multiple Channels — step_measure_channel_combine","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine Multiple Channels — step_measure_channel_combine","text":"aligning multiple channels common grid step_measure_channel_align(), step combines downstream analysis. choice strategy depends analysis goal:","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"strategies","dir":"Reference","previous_headings":"","what":"Strategies","title":"Combine Multiple Channels — step_measure_channel_combine","text":"stack: Creates n-dimensional measurement channel becomes dimension. Useful multi-way analysis (PARAFAC, Tucker). concat: Concatenates channels end--end single long vector. Useful PLS models expect 1D input. weighted_sum: Computes weighted combination channel values location. Useful channels fused single signal. mean: Simple average across channels (special case weighted_sum).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Combine Multiple Channels — step_measure_channel_combine","text":"Channels must aligned grid combining. Use step_measure_channel_align() first grids differ.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_combine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine Multiple Channels — step_measure_channel_combine","text":"","code":"library(recipes) library(tibble)  # Create sample multi-channel data (already aligned) df <- tibble(   id = rep(1:3, each = 10),   time = rep(seq(0, 9, by = 1), 3),   uv = rnorm(30, 100, 10),   ri = rnorm(30, 50, 5),   concentration = rep(c(10, 25, 50), each = 10) )  # Ingest and combine with stacking rec <- recipe(concentration ~ ., data = df) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(uv, location = vars(time)) |>   step_measure_input_long(ri, location = vars(time)) |>   step_measure_channel_combine(strategy = \"stack\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Ratios Between Channels — step_measure_channel_ratio","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"step_measure_channel_ratio() creates specification recipe step computes ratios pairs measurement channels.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"","code":"step_measure_channel_ratio(   recipe,   numerator,   denominator,   output_prefix = \"ratio_\",   epsilon = 1e-10,   log_transform = FALSE,   remove_original = FALSE,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_channel_ratio\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"recipe recipe object. numerator Column name(s) numerator channel(s). denominator Column name(s) denominator channel(s). Must length numerator (paired ratios). output_prefix Prefix output column names. Default \"ratio_\". epsilon Small value added denominator avoid division zero. Default 1e-10. log_transform Logical. ratio log-transformed? Default FALSE. remove_original Logical. original channel columns removed? Default FALSE. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"Channel ratios useful analytical chemistry : Normalization: UV/RI ratios normalize concentration variations Identification: Characteristic ratios help identify compounds Quality control: Ratio stability indicates system performance","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"output-columns","dir":"Reference","previous_headings":"","what":"Output Columns","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"numerator/denominator pair, creates new measure column named {output_prefix}{numerator}_{denominator} (e.g., \"ratio_uv_ri\").","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"log-transform","dir":"Reference","previous_headings":"","what":"Log Transform","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"log_transform = TRUE, computes log(numerator / denominator) can useful : Normalizing skewed distributions Converting multiplicative relationships additive Working absorbance ratios","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"Channels must aligned grid computing ratios. Use step_measure_channel_align() first grids differ.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_channel_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Ratios Between Channels — step_measure_channel_ratio","text":"","code":"library(recipes) library(tibble)  # Create sample multi-channel data df <- tibble(   id = rep(1:3, each = 10),   time = rep(seq(0, 9, by = 1), 3),   uv = rnorm(30, 100, 10),   ri = rnorm(30, 50, 5),   concentration = rep(c(10, 25, 50), each = 10) )  # Compute UV/RI ratio rec <- recipe(concentration ~ ., data = df) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(uv, location = vars(time)) |>   step_measure_input_long(ri, location = vars(time)) |>   step_measure_channel_ratio(numerator = \"uv\", denominator = \"ri\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple Finite Difference Derivatives — step_measure_derivative","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"step_measure_derivative() creates specification recipe step computes derivatives using simple finite differences.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"","code":"step_measure_derivative(   recipe,   order = 1L,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_derivative\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"recipe recipe object. step added sequence operations recipe. order order derivative (1 2). Default 1 (first derivative). measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"step computes derivatives using forward finite differences: $$\\frac{dy}{dx} \\approx \\frac{y_{+1} - y_i}{x_{+1} - x_i}$$ derivative order, spectrum length reduced 1. First derivative: n-1 points Second derivative: n-2 points location values updated left point difference. Note: smoothed derivatives, consider using step_measure_savitzky_golay() differentiation_order > 0 instead.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple Finite Difference Derivatives — step_measure_derivative","text":"","code":"library(recipes)  # First derivative rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_derivative(order = 1) |>   prep()  # Second derivative rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_derivative(order = 2) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":null,"dir":"Reference","previous_headings":"","what":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"step_measure_derivative_gap() creates specification recipe step computes gap derivatives using Norris-Williams method.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"","code":"step_measure_derivative_gap(   recipe,   gap = 2L,   segment = 1L,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_derivative_gap\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"recipe recipe object. step added sequence operations recipe. gap gap size (number points skip side). Default 2. derivative point computed points -gap +gap. segment segment size averaging. Default 1 (averaging). greater 1, multiple points averaged side computing difference. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"Gap derivatives compute difference points separated gap: $$\\frac{dy}{dx} \\approx \\frac{y_{+g} - y_{-g}}{x_{+g} - x_{-g}}$$ \\(g\\) gap size. segment > 1, Norris-Williams method used, averages segment points side computing difference. spectrum length reduced 2 * gap points. Gap derivatives often used NIR chemometrics alternative Savitzky-Golay derivatives less smoothing desired.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_derivative_gap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gap (Norris-Williams) Derivatives — step_measure_derivative_gap","text":"","code":"library(recipes)  # Gap derivative with gap=2 rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_derivative_gap(gap = 2) |>   prep()  # Norris-Williams with gap=3, segment=2 rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_derivative_gap(gap = 3, segment = 2) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Spikes and Outliers from Measurements — step_measure_despike","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"step_measure_despike() creates specification recipe step detects removes spikes (sudden, brief outliers) measurement data. Spikes common artifacts spectroscopy (cosmic rays Raman, detector glitches) chromatography (electrical noise).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"","code":"step_measure_despike(   recipe,   measures = NULL,   window = 5L,   threshold = 5,   method = c(\"interpolate\", \"median\", \"mean\"),   max_width = 3L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_despike\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"recipe recipe object. measures optional character vector measure column names. window window size local statistics. Must odd integer least 3. Default 5. Tunable via smooth_window(). threshold threshold multiplier spike detection. Points deviating threshold * MAD local median flagged. Default 5. Tunable via despike_threshold(). method replace detected spikes. One \"interpolate\" (default, linear interpolation neighbors), \"median\" (replace local median), \"mean\" (replace local mean). max_width Maximum width (points) spike. Consecutive outliers wider considered spikes. Default 3. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"Spike detection uses robust local statistic approach: point, calculate local median MAD (Median Absolute Deviation) within sliding window Flag points |value - local_median| > threshold * MAD Group consecutive flagged points spike regions spike region narrower max_width, replace specified method MAD scaled 1.4826 consistent standard deviation normally distributed data. approach robust : Median MAD affected spikes threshold adapts local noise levels max_width parameter prevents removing genuine peaks","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_despike.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Spikes and Outliers from Measurements — step_measure_despike","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_despike(threshold = 5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Trend from Measurements — step_measure_detrend","title":"Remove Trend from Measurements — step_measure_detrend","text":"step_measure_detrend() creates specification recipe step removes polynomial trend measurement data. useful removing drift, offset, slowly varying background effects.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Trend from Measurements — step_measure_detrend","text":"","code":"step_measure_detrend(   recipe,   measures = NULL,   degree = 1L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_detrend\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Trend from Measurements — step_measure_detrend","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. degree Polynomial degree trend fitting. Default 1 (linear detrending). Use 0 remove mean (centering). role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Trend from Measurements — step_measure_detrend","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove Trend from Measurements — step_measure_detrend","text":"Detrending removes polynomial trend spectrum. simpler baseline correction methods like ALS robust fitting, effective : Linear drift (degree = 1): Instrumental drift, temperature effects Offset removal (degree = 0): Centers spectrum zero mean Curved trends (degree = 2+): Gradual curvature scattering Unlike step_measure_baseline_poly(), detrending fits polynomial points without iterative peak exclusion. makes faster appropriate : trend dominant feature (peaks) want preserve peak structure removing background Processing time-series process data drift selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Remove Trend from Measurements — step_measure_detrend","text":"tidy() step, tibble columns terms, degree, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_detrend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Trend from Measurements — step_measure_detrend","text":"","code":"library(recipes)  # Linear detrending rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_detrend(degree = 1) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows  # Mean centering only (degree = 0) rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_detrend(degree = 0) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":null,"dir":"Reference","previous_headings":"","what":"Dilution Factor Correction — step_measure_dilution_correct","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"step_measure_dilution_correct() creates specification recipe step corrects concentration values applying dilution factors. essential samples diluted preparation need back-calculated original concentrations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"","code":"step_measure_dilution_correct(   recipe,   ...,   dilution_col = \"dilution_factor\",   operation = c(\"multiply\", \"divide\"),   handle_zero = c(\"error\", \"warn\", \"skip\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_dilution_correct\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"recipe recipe object. ... One selector functions choose feature columns (concentration values) correct. empty, numeric columns (excluding metadata columns) selected. dilution_col Name column containing dilution factors. Default \"dilution_factor\". operation apply dilution factor: \"multiply\" (default): concentration * dilution_factor (back-calculate diluted original concentration) \"divide\": concentration / dilution_factor (apply dilution) handle_zero handle zero dilution factors: \"error\" (default): Stop error \"warn\": Warn set result NA \"skip\": Silently set result NA role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"dilution-factor-interpretation","dir":"Reference","previous_headings":"","what":"Dilution Factor Interpretation","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"dilution factor represents much sample diluted: factor 1 means dilution (undiluted) factor 2 means 1:2 dilution (1 part sample + 1 part diluent) factor 10 means 1:10 dilution","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"back-calculation","dir":"Reference","previous_headings":"","what":"Back-Calculation","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"using operation = \"multiply\" (default): original_concentration = measured_concentration * dilution_factor corrects dilution get true concentration original sample.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"when-to-use","dir":"Reference","previous_headings":"","what":"When to Use","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"Use step quantitation (calibration) samples diluted bring concentrations within calibration range.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_dilution_correct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dilution Factor Correction — step_measure_dilution_correct","text":"","code":"library(recipes)  # Example: samples diluted to fit calibration range data <- data.frame(   sample_id = paste0(\"S\", 1:6),   dilution_factor = c(1, 2, 5, 10, 1, 1),   analyte = c(50, 45, 42, 48, 51, 49)  # Measured after dilution )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_dilution_correct(     analyte,     dilution_col = \"dilution_factor\",     operation = \"multiply\"   ) |>   prep()  # Back-calculated concentrations bake(rec, new_data = NULL) #> # A tibble: 6 × 3 #>   sample_id dilution_factor analyte #>   <chr>               <dbl>   <dbl> #> 1 S1                      1      50 #> 2 S2                      2      90 #> 3 S3                      5     210 #> 4 S4                     10     480 #> 5 S5                      1      51 #> 6 S6                      1      49 # S1: 50*1=50, S2: 45*2=90, S3: 42*5=210, S4: 48*10=480"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Drift Correction — step_measure_drift_linear","title":"Linear Drift Correction — step_measure_drift_linear","text":"step_measure_drift_linear() creates specification recipe step corrects linear signal drift across run order using QC reference samples. simpler alternative LOESS drift approximately linear.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Drift Correction — step_measure_drift_linear","text":"","code":"step_measure_drift_linear(   recipe,   ...,   run_order_col = \"run_order\",   sample_type_col = \"sample_type\",   qc_type = \"qc\",   apply_to = c(\"all\", \"unknown\"),   min_qc = 3,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_drift_linear\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Drift Correction — step_measure_drift_linear","text":"recipe recipe object. ... One selector functions choose feature columns. feature-level data, select numeric response columns. curve-level data .measures, leave empty apply locations. run_order_col Name column containing run order (injection sequence). Must numeric/integer. sample_type_col Name column containing sample type. qc_type Value(s) sample_type_col identify QC samples use drift modeling. Default \"qc\". apply_to samples apply correction : \"\" (default): Correct samples \"unknown\": correct unknown samples min_qc Minimum number QC samples required. Default 5. role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Drift Correction — step_measure_drift_linear","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"how-it-works","dir":"Reference","previous_headings":"","what":"How It Works","title":"Linear Drift Correction — step_measure_drift_linear","text":"prep(): linear regression fit QC sample responses vs run order feature. bake(): Correction factors calculated : correction = median(QC_responses) / predicted_value sample's response multiplied correction factor.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"when-to-use","dir":"Reference","previous_headings":"","what":"When to Use","title":"Linear Drift Correction — step_measure_drift_linear","text":"Use linear drift correction : Drift approximately linear run fewer QC samples (requires least 3) want conservative correction non-linear drift patterns, use step_measure_drift_qc_loess() step_measure_drift_spline().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Drift Correction — step_measure_drift_linear","text":"","code":"library(recipes)  # Data with linear drift data <- data.frame(   sample_id = paste0(\"S\", 1:20),   sample_type = rep(c(\"qc\", \"unknown\", \"unknown\", \"unknown\", \"qc\"), 4),   run_order = 1:20,   feature1 = 100 + (1:20) * 0.5 + rnorm(20, sd = 2) )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_drift_linear(feature1) |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":null,"dir":"Reference","previous_headings":"","what":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"step_measure_drift_qc_loess() creates specification recipe step corrects signal drift across run order using QC (reference) samples. implements QC-RLSC (robust LOESS signal correction) method.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"","code":"step_measure_drift_qc_loess(   recipe,   ...,   run_order_col = \"run_order\",   sample_type_col = \"sample_type\",   qc_type = \"qc\",   apply_to = c(\"all\", \"unknown\"),   span = 0.75,   degree = 2,   robust = TRUE,   min_qc = 5,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_drift_qc_loess\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"recipe recipe object. ... One selector functions choose feature columns. feature-level data, select numeric response columns. curve-level data .measures, leave empty apply locations. run_order_col Name column containing run order (injection sequence). Must numeric/integer. sample_type_col Name column containing sample type. qc_type Value(s) sample_type_col identify QC samples use drift modeling. Default \"qc\". apply_to samples apply correction : \"\" (default): Correct samples \"unknown\": correct unknown samples span LOESS span parameter controlling smoothness. Default 0.75. Smaller values = flexible fit. degree Polynomial degree LOESS (1 2). Default 2. robust Logical. Use robust LOESS fitting? Default TRUE. min_qc Minimum number QC samples required. Default 5. role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"how-it-works","dir":"Reference","previous_headings":"","what":"How It Works","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"prep(): LOESS model fit QC sample responses vs run order feature/location. bake(): Correction factors calculated : correction = median(QC_responses) / predicted_value sample's response multiplied correction factor run order position.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"data-levels","dir":"Reference","previous_headings":"","what":"Data Levels","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"step supports : Feature-level data: Applies correction selected numeric column Curve-level data: Applies correction location measure_list","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"diagnostics","dir":"Reference","previous_headings":"","what":"Diagnostics","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"trained step stores drift model information accessible via tidy(): LOESS model parameters QC response trends Correction factors applied","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_qc_loess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"QC-Based Drift Correction Using LOESS — step_measure_drift_qc_loess","text":"","code":"library(recipes)  # Feature-level data with drift data <- data.frame(   sample_id = paste0(\"S\", 1:20),   sample_type = rep(c(\"qc\", \"unknown\", \"unknown\", \"unknown\", \"qc\"), 4),   run_order = 1:20,   feature1 = 100 + (1:20) * 0.5 + rnorm(20, sd = 2),  # Upward drift   feature2 = 50 - (1:20) * 0.3 + rnorm(20, sd = 1)    # Downward drift )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_drift_qc_loess(feature1, feature2) |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Spline-Based Drift Correction — step_measure_drift_spline","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"step_measure_drift_spline() creates specification recipe step corrects signal drift using smoothing splines fit QC samples. offers flexibility linear correction stable LOESS sparse QC data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"","code":"step_measure_drift_spline(   recipe,   ...,   run_order_col = \"run_order\",   sample_type_col = \"sample_type\",   qc_type = \"qc\",   apply_to = c(\"all\", \"unknown\"),   df = NULL,   spar = NULL,   min_qc = 4,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_drift_spline\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"recipe recipe object. ... One selector functions choose feature columns. feature-level data, select numeric response columns. curve-level data .measures, leave empty apply locations. run_order_col Name column containing run order (injection sequence). Must numeric/integer. sample_type_col Name column containing sample type. qc_type Value(s) sample_type_col identify QC samples use drift modeling. Default \"qc\". apply_to samples apply correction : \"\" (default): Correct samples \"unknown\": correct unknown samples df Degrees freedom smoothing spline. Default NULL, uses cross-validation select optimal df. Lower values = smoother. spar Smoothing parameter (alternative df). NULL (default), cross-validation used. min_qc Minimum number QC samples required. Default 5. role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":"how-it-works","dir":"Reference","previous_headings":"","what":"How It Works","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"Uses stats::smooth.spline() fit flexible curve QC responses. spline automatically adapts data complexity df specified.","code":""},{"path":[]},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_drift_spline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spline-Based Drift Correction — step_measure_drift_spline","text":"","code":"library(recipes)  # Data with non-linear drift set.seed(123) data <- data.frame(   sample_id = paste0(\"S\", 1:30),   sample_type = rep(c(\"qc\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"qc\"), 5),   run_order = 1:30,   feature1 = 100 + sin((1:30) / 5) * 10 + rnorm(30, sd = 2) )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_drift_spline(feature1) |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":null,"dir":"Reference","previous_headings":"","what":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"step_measure_emsc() creates specification recipe step applies Extended Multiplicative Scatter Correction spectral data. EMSC accounts wavelength-dependent scatter effects using polynomial terms.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"","code":"step_measure_emsc(   recipe,   degree = 2L,   reference = \"mean\",   measures = NULL,   role = NA,   trained = FALSE,   ref_spectrum = NULL,   locations = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_emsc\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"recipe recipe object. degree Polynomial degree wavelength-dependent terms. Default 2. Higher values can model complex scatter effects risk overfitting. reference Reference spectrum method: \"mean\" (default) \"median\". Alternatively, numeric vector can supplied reference spectrum. measures optional character vector measure column names. role used. trained Logical indicating step trained. ref_spectrum learned reference spectrum (training). locations location values polynomial terms (training). skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"Extended MSC (EMSC) extends standard MSC modeling wavelength-dependent scatter effects. spectrum \\(x_i\\) reference \\(x_r\\), model : $$x_i = a_i + b_i \\cdot x_r + c_i \\cdot \\lambda + d_i \\cdot \\lambda^2 + ... + \\epsilon$$ corrected spectrum : $$EMSC(x_i) = \\frac{x_i - a_i - c_i \\cdot \\lambda - d_i \\cdot \\lambda^2 - ...}{b_i}$$ polynomial terms (\\(\\lambda\\), \\(\\lambda^2\\), etc.) account wavelength-dependent baseline effects vary samples. use EMSC vs MSC: Use MSC simple additive/multiplicative scatter Use EMSC scatter effects vary wavelength Start degree=2, increase needed complex scatter","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_emsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extended Multiplicative Scatter Correction (EMSC) — step_measure_emsc","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_emsc(degree = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":null,"dir":"Reference","previous_headings":"","what":"Exclude Measurement Ranges — step_measure_exclude","title":"Exclude Measurement Ranges — step_measure_exclude","text":"step_measure_exclude() creates specification recipe step removes measurement points within specified x-axis range(s).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exclude Measurement Ranges — step_measure_exclude","text":"","code":"step_measure_exclude(   recipe,   ranges,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_exclude\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exclude Measurement Ranges — step_measure_exclude","text":"recipe recipe object. step added sequence operations recipe. ranges list numeric vectors, length 2 specifying ranges exclude c(min, max). Points location >= min <= max range removed. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exclude Measurement Ranges — step_measure_exclude","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exclude Measurement Ranges — step_measure_exclude","text":"step removes measurements falling within specified ranges. useful : Removing solvent peaks chromatography Excluding system peaks artifacts Removing detector saturation regions Removing known interference regions spectroscopy Multiple ranges can excluded providing list ranges. Points falling within specified ranges removed.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_exclude.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exclude Measurement Ranges — step_measure_exclude","text":"","code":"library(recipes)  # Exclude specific regions (e.g., solvent peaks) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_exclude(ranges = list(c(1, 5), c(95, 100))) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7  [89 × 2] #>  2     2  46    40.1    13.5  [89 × 2] #>  3     3  71     8.4    20.5  [89 × 2] #>  4     4  72.8   5.9    20.7  [89 × 2] #>  5     5  58.3  25.5    15.5  [89 × 2] #>  6     6  44    42.7    13.7  [89 × 2] #>  7     7  44    42.7    13.7  [89 × 2] #>  8     8  69.3  10.6    19.3  [89 × 2] #>  9     9  61.4  19.9    17.7  [89 × 2] #> 10    10  61.4  19.9    17.7  [89 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":null,"dir":"Reference","previous_headings":"","what":"Fourier Low-Pass Filtering — step_measure_filter_fourier","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"step_measure_filter_fourier() creates specification recipe step applies Fourier-domain low-pass filtering remove high-frequency noise.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"","code":"step_measure_filter_fourier(   recipe,   measures = NULL,   cutoff = 0.1,   type = c(\"lowpass\", \"highpass\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_filter_fourier\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"recipe recipe object. measures optional character vector measure column names. cutoff cutoff frequency fraction Nyquist frequency (0 0.5). Default 0.1. Frequencies attenuated. Tunable via fourier_cutoff(). type Type filter: \"lowpass\" (default) keeps low frequencies, \"highpass\" keeps high frequencies. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"Fourier filtering transforms spectrum frequency domain using FFT, applies frequency mask, transforms back. effective : Removing periodic noise Smoothing precise frequency control Removing high-frequency detector noise cutoff specified fraction Nyquist frequency. cutoff 0.1 keeps lowest 10% frequencies.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_filter_fourier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fourier Low-Pass Filtering — step_measure_filter_fourier","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_filter_fourier(cutoff = 0.1) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute Missing Values in Measurements — step_measure_impute","title":"Impute Missing Values in Measurements — step_measure_impute","text":"step_measure_impute() creates specification recipe step imputes (fills ) missing values (NA) measurement data using interpolation methods.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute Missing Values in Measurements — step_measure_impute","text":"","code":"step_measure_impute(   recipe,   measures = NULL,   method = c(\"linear\", \"spline\", \"constant\", \"mean\"),   max_gap = Inf,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_impute\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute Missing Values in Measurements — step_measure_impute","text":"recipe recipe object. measures optional character vector measure column names. method Imputation method: \"linear\" (default): Linear interpolation \"spline\": Cubic spline interpolation \"constant\": Nearest non-NA value \"mean\": Global mean non-NA values max_gap Maximum gap size impute. Gaps larger left NA. Default Inf (impute ). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute Missing Values in Measurements — step_measure_impute","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impute Missing Values in Measurements — step_measure_impute","text":"Missing values can occur due : Removed spikes (despiking replacement set NA) Excluded regions Instrument gaps dropouts Linear spline interpolation use stats::approx() stats::spline() functions respectively. appropriate gaps small relative spectral features.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_impute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute Missing Values in Measurements — step_measure_impute","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_impute(method = \"linear\") |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Measurements from a Single Column — step_measure_input_long","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"step_measure_input_long creates specification recipe step converts measures organized column analytical results (one columns numeric indices) internal format used package.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"","code":"step_measure_input_long(   recipe,   ...,   location,   col_name = \".measures\",   dim_names = NULL,   dim_units = NULL,   pad = FALSE,   role = \"measure\",   trained = FALSE,   columns = NULL,   skip = FALSE,   id = rand_id(\"measure_input_long\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose single column contains analytical measurements. selection order measurement's profile. location One selector functions choose column(s) locations analytical values. 1D data (spectra, chromatograms), select single location column. 2D higher dimensional data (LC-DAD, 2D NMR, EEM), select multiple location columns. Columns renamed location_1, location_2, etc. order. col_name single character string specifying name output column contain measure data. Defaults \".measures\". Use different names creating multiple measure columns (e.g., \".uv_spectrum\" \".ms_spectrum\"). dim_names Optional character vector semantic names dimension (e.g., c(\"retention_time\", \"wavelength\")). used multi-dimensional data. dim_units Optional character vector units dimension (e.g., c(\"min\", \"nm\")). used multi-dimensional data. pad Whether pad measurements ensure number values. useful missing values measurements. role used step since new variables created. trained logical indicate quantities preprocessing estimated. columns character vector column names determined recipe. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"step designed data format column analytical measurement (e.g., absorption, etc.) one columns location value (e.g., wave number, retention time, wavelength, etc.). step_measure_input_long() collect data put format used internally package. data structure row independent experimental unit nested tibble sample's measure (measurement location). assumes unique combinations columns data define individual patterns associated pattern. case, special values might inappropriately restructured. best advice column type indicates unique sample number measure. example, 200 values measure 7 samples, input data (long format) 1,400 rows. advise column 7 unique values indicating rows correspond sample.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"multi-dimensional-data","dir":"Reference","previous_headings":"","what":"Multi-Dimensional Data","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"2D higher dimensional data, provide multiple location columns:   result measure_nd_list column instead measure_list.","code":"# LC-DAD data with retention time and wavelength step_measure_input_long(   absorbance,   location = vars(retention_time, wavelength),   dim_names = c(\"time\", \"wavelength\"),   dim_units = c(\"min\", \"nm\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"missing-data","dir":"Reference","previous_headings":"","what":"Missing Data","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"Currently, measure assumes equal numbers values within sample. missing values measurements, need pad missing values (opposed absent row long format). , error occur.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"tidy() step, tibble indicating original columns used reformat data.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest Measurements from a Single Column — step_measure_input_long","text":"","code":"library(recipes)  # 1D data (traditional usage) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Measurements in Separate Columns — step_measure_input_wide","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"step_measure_input_wide creates specification recipe step converts measures organized multiple columns internal format used package.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"","code":"step_measure_input_wide(   recipe,   ...,   role = \"measure\",   trained = FALSE,   columns = NULL,   location_values = NULL,   col_name = \".measures\",   skip = FALSE,   id = rand_id(\"measure_input_wide\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See selections() details. role used step since new variables created. trained logical indicate quantities preprocessing estimated. columns character string selected variable names. field placeholder populated recipes::prep() used. location_values numeric vector values specify location measurements (e.g., wavelength etc.) order variables selected .... specified, sequence integers (starting 1L) used. col_name single character string specifying name output column contain measure data. Defaults \".measures\". Use different names creating multiple measure columns (e.g., \".uv_spectrum\" \".ms_spectrum\"). skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"step designed data format analytical measurements separate columns. step_measure_input_wide() collect data put format used internally package. data structure row independent experimental unit nested tibble sample's measure (measurement location). assumes unique combinations columns data define individual patterns associated pattern. case, special values might inappropriately restructured. best advice column type indicates unique sample number measure. example, 20 rows input data set, columns analytically measurements show duplicate combinations 20 rows.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"tidy() step, tibble indicating original columns used reformat data.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_input_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest Measurements in Separate Columns — step_measure_input_wide","text":"","code":"data(meats, package = \"modeldata\")  # Outcome data is to the right names(meats) |> tail(10) #>  [1] \"x_094\"   \"x_095\"   \"x_096\"   \"x_097\"   \"x_098\"   \"x_099\"   \"x_100\"   #>  [8] \"water\"   \"fat\"     \"protein\"  # ------------------------------------------------------------------------------ # Ingest data without adding the location (i.e. wave number) for the spectra  rec <-   recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\")) |>   prep()  summary(rec) #> # A tibble: 4 × 4 #>   variable  type      role    source   #>   <chr>     <list>    <chr>   <chr>    #> 1 water     <chr [2]> outcome original #> 2 fat       <chr [2]> outcome original #> 3 protein   <chr [2]> outcome original #> 4 .measures <chr [1]> measure derived   # ------------------------------------------------------------------------------ # Ingest data without adding the location (i.e. wave number) for the spectra  # Make up some locations for the spectra's x-axis index <- seq(1, 2, length.out = 100)  rec <-   recipe(water + fat + protein ~ ., data = meats) |>   step_measure_input_wide(starts_with(\"x_\"), location_values = index) |>   prep()  summary(rec) #> # A tibble: 4 × 4 #>   variable  type      role    source   #>   <chr>     <list>    <chr>   <chr>    #> 1 water     <chr [2]> outcome original #> 2 fat       <chr [2]> outcome original #> 3 protein   <chr [2]> outcome original #> 4 .measures <chr [1]> measure derived"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Region Integrals — step_measure_integrals","title":"Calculate Region Integrals — step_measure_integrals","text":"step_measure_integrals() creates specification recipe step calculates integrated areas specified x-axis regions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Region Integrals — step_measure_integrals","text":"","code":"step_measure_integrals(   recipe,   regions,   method = c(\"trapezoid\", \"simpson\"),   measures = NULL,   prefix = \"integral_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_integrals\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Region Integrals — step_measure_integrals","text":"recipe recipe object. regions named unnamed list numeric vectors, length 2 specifying regions c(min, max). example: list(peak1 = c(1000, 1100), peak2 = c(1500, 1600)). method Integration method: \"trapezoid\" (default) \"simpson\". measures optional character vector measure column names. prefix Prefix output column names. Default \"integral_\". role Role generated columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Region Integrals — step_measure_integrals","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Region Integrals — step_measure_integrals","text":"step calculates integrated area curve specified region. result added new predictor columns, one per region. Column naming: regions named: prefix + name (e.g., \"integral_peak1\") regions unnamed: prefix + index (e.g., \"integral_1\") Integration methods: \"trapezoid\": Trapezoidal rule, fast accurate smooth data \"simpson\": Simpson's rule, accurate smooth curves","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_integrals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Region Integrals — step_measure_integrals","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_integrals(     regions = list(low = c(1, 30), mid = c(40, 60), high = c(70, 100))   ) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 8 #>       id water   fat protein .measures integral_low integral_mid integral_high #>    <int> <dbl> <dbl>   <dbl>    <meas>        <dbl>        <dbl>         <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2]         77.1         61.8          93.6 #>  2     2  46    40.1    13.5 [100 × 2]         85.0         67.4         101.  #>  3     3  71     8.4    20.5 [100 × 2]         76.1         59.4          85.0 #>  4     4  72.8   5.9    20.7 [100 × 2]         83.1         64.6          94.2 #>  5     5  58.3  25.5    15.5 [100 × 2]         82.8         67.6         103.  #>  6     6  44    42.7    13.7 [100 × 2]         90.6         72.3         109.  #>  7     7  44    42.7    13.7 [100 × 2]         90.2         72.0         107.  #>  8     8  69.3  10.6    19.3 [100 × 2]         74.3         59.7          90.5 #>  9     9  61.4  19.9    17.7 [100 × 2]         98.3         78.8         119.  #> 10    10  61.4  19.9    17.7 [100 × 2]        102.          82.6         124.  #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolate Gaps in Measurement Data — step_measure_interpolate","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"step_measure_interpolate() creates specification recipe step fills gaps missing values measurement data using interpolation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"","code":"step_measure_interpolate(   recipe,   ranges,   method = c(\"linear\", \"spline\"),   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_interpolate\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"recipe recipe object. ranges list numeric vectors specifying ranges interpolate. element vector length 2: c(min, max). method Interpolation method: \"linear\" \"spline\". Default \"linear\". measures optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"step useful : Filling gaps left excluded regions need restoration Handling missing invalid data points Smoothing detector saturation regions interpolation uses data points immediately outside specified ranges estimate values within ranges.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_interpolate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpolate Gaps in Measurement Data — step_measure_interpolate","text":"","code":"library(recipes)  # Interpolate over a problematic region rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_interpolate(ranges = list(c(40, 50)), method = \"spline\") |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":null,"dir":"Reference","previous_headings":"","what":"Kubelka-Munk Transformation — step_measure_kubelka_munk","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"step_measure_kubelka_munk() creates specification recipe step applies Kubelka-Munk transformation diffuse reflectance data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"","code":"step_measure_kubelka_munk(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_kubelka_munk\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"Kubelka-Munk transformation used diffuse reflectance spectroscopy convert reflectance quantity proportional concentration: $$f(R) = \\frac{(1-R)^2}{2R}$$ \\(R\\) reflectance (0 1). Important: Reflectance values range (0, 1). Values boundaries produce extreme values Inf. transformation commonly used : NIR diffuse reflectance spectroscopy Analysis powders solid samples Beer-Lambert law apply directly measurement locations preserved unchanged.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_kubelka_munk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kubelka-Munk Transformation — step_measure_kubelka_munk","text":"","code":"library(recipes)  # Assuming reflectance data in (0, 1) range # Note: meats_long has transmittance, this is illustrative rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_kubelka_munk()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Transformation — step_measure_log","title":"Log Transformation — step_measure_log","text":"step_measure_log() creates specification recipe step applies logarithmic transformation measurement values.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Transformation — step_measure_log","text":"","code":"step_measure_log(   recipe,   base = exp(1),   offset = 0,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_log\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Transformation — step_measure_log","text":"recipe recipe object. step added sequence operations recipe. base base logarithm. Default exp(1) (natural log). Use 10 log10 transformation. offset numeric offset added values taking log. Default 0. Use small positive value (e.g., 1 log1p) handle zero near-zero values. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Transformation — step_measure_log","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Transformation — step_measure_log","text":"step applies transformation: $$y' = \\log_b(y + \\text{offset})$$ \\(b\\) base. Log transformation commonly used : Variance stabilization Normalizing skewed distributions Converting multiplicative relationships additive Warning: Non-positive values (offset) produce -Inf NaN. measurement locations preserved unchanged.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Transformation — step_measure_log","text":"","code":"library(recipes)  # Natural log transformation rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_log(offset = 1) |>   prep()  # Log10 transformation rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_log(base = 10) |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a Custom Function to Measurements — step_measure_map","title":"Apply a Custom Function to Measurements — step_measure_map","text":"step_measure_map() creates specification recipe step applies custom function sample's measurements. Use built-preprocessing steps (SNV, MSC, Savitzky-Golay) cover needs.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a Custom Function to Measurements — step_measure_map","text":"","code":"step_measure_map(   recipe,   fn,   ...,   measures = NULL,   verbosity = 1L,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_map\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a Custom Function to Measurements — step_measure_map","text":"recipe recipe object. step added sequence operations recipe. fn function apply sample's measurement tibble. function accept tibble location value columns return tibble structure. Can also formula (e.g., ~ { .x$value <- log1p(.x$value); .x }) converted via rlang::as_function(). ... Additional arguments passed fn baking. measures optional character vector measure column names process. NULL (default), measure columns processed. verbosity integer controlling output verbosity: 0: Silent - suppress messages output fn 1: Normal (default) - show output fn role used step since new variables created. trained logical indicate step trained. skip logical. step skipped recipe baked? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a Custom Function to Measurements — step_measure_map","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a Custom Function to Measurements — step_measure_map","text":"step \"escape hatch\" custom sample-wise transformations covered built-steps. integrates fully recipes framework, meaning custom transformation : Applied consistently prep() bake() Included bundling recipes workflows Reproducible across sessions","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"function-requirements","dir":"Reference","previous_headings":"","what":"Function Requirements","title":"Apply a Custom Function to Measurements — step_measure_map","text":"function fn must: Accept tibble location value columns Return tibble location value columns change number rows (measurements must remain aligned)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"when-to-use-this-step","dir":"Reference","previous_headings":"","what":"When to Use This Step","title":"Apply a Custom Function to Measurements — step_measure_map","text":"Use step_measure_map() domain-specific transformations covered built-steps: Custom baseline correction algorithms Specialized normalization methods Instrument-specific corrections Experimental preprocessing techniques common operations, prefer built-steps: Scatter correction → step_measure_snv() step_measure_msc() Smoothing/derivatives → step_measure_savitzky_golay()","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"prototyping-with-measure-map-","dir":"Reference","previous_headings":"","what":"Prototyping with measure_map()","title":"Apply a Custom Function to Measurements — step_measure_map","text":"developing custom transformation, may find helpful prototype using measure_map() baked data wrapping step. function works correctly, use `step_measure_ production pipelines.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a Custom Function to Measurements — step_measure_map","text":"","code":"library(recipes)  # Example 1: Custom log transformation log_transform <- function(x) {   x$value <- log1p(x$value)   x }  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_map(log_transform) |>   step_measure_snv() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows  # Example 2: Using formula syntax for inline transformations rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_map(~ {     # Subtract minimum to remove offset     .x$value <- .x$value - min(.x$value)     .x   }) |>   prep()  # Example 3: Using external package functions # (e.g., custom baseline from a spectroscopy package) if (FALSE) { # \\dontrun{ rec3 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_map(my_baseline_correction, method = \"als\") |>   step_measure_output_wide() } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":null,"dir":"Reference","previous_headings":"","what":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"step_measure_mcr_als() creates specification recipe step applies Multivariate Curve Resolution - Alternating Least Squares (MCR-ALS) multi-dimensional measurement data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"","code":"step_measure_mcr_als(   recipe,   ...,   n_components = 3L,   max_iter = 500L,   tol = 1e-06,   non_negativity = TRUE,   unimodality = FALSE,   prefix = \"mcr_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_mcr_als\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"recipe recipe object. ... One selector functions choose measure columns. empty, nD measure columns used. n_components Number components extract. Default 3. max_iter Maximum number iterations. Default 500. tol Convergence tolerance. Default 1e-6. non_negativity Logical. non-negativity constraints applied? Default TRUE. unimodality Logical. unimodality constraints applied? Default FALSE. prefix Prefix output column names. Default \"mcr_\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"MCR-ALS powerful technique resolving mixtures pure component contributions. particularly useful : Chromatographic data (time x wavelength) Spectroscopic mixtures Process analytical data Unlike PARAFAC, MCR-ALS bilinear method works 2D data (samples unfolded 3D). allows flexible constraints like non-negativity unimodality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"experimental-status","dir":"Reference","previous_headings":"","what":"Experimental Status","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"step experimental API may change future versions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"Input must measure_nd_list 2 dimensions samples must grid (regular, aligned)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"experimental feature. implementation uses simple ALS algorithm without advanced constraints. production use, consider using dedicated MCR-ALS packages.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mcr_als.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCR-ALS Decomposition for Multi-Dimensional Data — step_measure_mcr_als","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes)  # After ingesting chromatographic data rec <- recipe(concentration ~ ., data = chrom_data) |>   step_measure_input_long(     absorbance,     location = vars(time, wavelength)   ) |>   step_measure_mcr_als(n_components = 3) |>   prep()  bake(rec, new_data = NULL) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Statistical Moments — step_measure_moments","title":"Calculate Statistical Moments — step_measure_moments","text":"step_measure_moments() creates specification recipe step calculates statistical moments spectra.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Statistical Moments — step_measure_moments","text":"","code":"step_measure_moments(   recipe,   moments = c(\"mean\", \"sd\", \"skewness\", \"kurtosis\"),   weighted = FALSE,   measures = NULL,   prefix = \"moment_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_moments\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Statistical Moments — step_measure_moments","text":"recipe recipe object. moments Character vector specifying moments calculate. Options: \"mean\", \"sd\", \"skewness\", \"kurtosis\", \"entropy\". Default c(\"mean\", \"sd\", \"skewness\", \"kurtosis\"). weighted Logical. TRUE, moments weighted location values. Default FALSE. measures optional character vector measure column names. prefix Prefix output column names. Default \"moment_\". role Role generated columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Statistical Moments — step_measure_moments","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Statistical Moments — step_measure_moments","text":"step calculates statistical moments summarize distribution values spectrum: weighted = TRUE, location (x-axis) values used weights, can useful calculating center mass weighted statistics.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Statistical Moments — step_measure_moments","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_moments(moments = c(\"mean\", \"sd\", \"skewness\")) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 8 #>       id water   fat protein .measures moment_mean moment_sd moment_skewness #>    <int> <dbl> <dbl>   <dbl>    <meas>       <dbl>     <dbl>           <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2]        2.97     0.270          0.222  #>  2     2  46    40.1    13.5 [100 × 2]        3.24     0.234         -0.311  #>  3     3  71     8.4    20.5 [100 × 2]        2.82     0.206          0.536  #>  4     4  72.8   5.9    20.7 [100 × 2]        3.09     0.238          0.540  #>  5     5  58.3  25.5    15.5 [100 × 2]        3.25     0.326          0.102  #>  6     6  44    42.7    13.7 [100 × 2]        3.48     0.262         -0.387  #>  7     7  44    42.7    13.7 [100 × 2]        3.44     0.249         -0.405  #>  8     8  69.3  10.6    19.3 [100 × 2]        2.87     0.280          0.338  #>  9     9  61.4  19.9    17.7 [100 × 2]        3.79     0.329          0.0588 #> 10    10  61.4  19.9    17.7 [100 × 2]        3.94     0.345          0.0582 #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiplicative Scatter Correction (MSC) — step_measure_msc","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"step_measure_msc() creates specification recipe step applies Multiplicative Scatter Correction spectral data. MSC removes physical light scatter accounting additive multiplicative effects.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"","code":"step_measure_msc(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   ref_spectra = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_msc\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. ref_spectra named list numeric vectors containing reference spectra computed training measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"Multiplicative Scatter Correction (MSC) normalization method attempts account additive multiplicative effects aligning spectrum reference spectrum. spectrum \\(x_i\\) reference \\(x_r\\), transformation : $$x_i = m_i \\cdot x_r + a_i$$ $$MSC(x_i) = \\frac{x_i - a_i}{m_i}$$ \\(a_i\\) \\(m_i\\) additive (intercept) multiplicative (slope) terms regressing \\(x_i\\) \\(x_r\\). reference spectrum computed mean training spectra prep() stored use applying transformation new data. MSC commonly used remove physical light scatter effects NIR spectroscopy caused differences particle size path length. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long(). measurement locations preserved unchanged.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"tidy() step, tibble columns terms (set \".measures\") id returned.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"Geladi, P., MacDougall, D., Martens, H. 1985. Linearization Scatter-Correction Near-Infrared Reflectance Spectra Meat. Applied Spectroscopy, 39(3):491-500.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_msc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiplicative Scatter Correction (MSC) — step_measure_msc","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_msc() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"step_measure_mw_averages() creates specification recipe step calculates molecular weight averages size exclusion chromatography data. step superseded measure.sec::step_sec_mw_averages(). new code, recommend using measure.sec package provides complete SEC/GPC analysis functionality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"","code":"step_measure_mw_averages(   recipe,   measures = NULL,   calibration = NULL,   integration_range = NULL,   output_cols = c(\"mn\", \"mw\", \"mz\", \"mp\", \"dispersity\"),   prefix = \"mw_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_mw_averages\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"recipe recipe object. measures optional character vector measure column names. calibration Calibration method converting x-axis log(MW). Can : NULL (default): Assumes x-axis already log10(MW) numeric vector length 2: Linear calibration c(slope, intercept) log10(MW) = slope * x + intercept \"auto\": Estimate data range (assumes typical polymer range) integration_range Optional numeric vector c(min, max) specifying x-axis range integration. NULL, uses full range. output_cols Character vector metrics calculate. Default includes : c(\"mn\", \"mw\", \"mz\", \"mp\", \"dispersity\"). prefix Prefix output column names. Default \"mw_\". role Role generated columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"step calculates standard molecular weight averages SEC/GPC data: detector signal assumed proportional weight concentration. RI detection, typically valid. UV detection, response factors may need applied first using step_measure_calibrate_y(). Prerequisites: Data baseline corrected X-axis represent retention time/volume log(MW) Integration limits exclude solvent peaks","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_averages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Molecular Weight Averages for SEC/GPC — step_measure_mw_averages","text":"","code":"library(recipes)  # Assuming x-axis is already calibrated to log10(MW) # rec <- recipe(~., data = gpc_data) |> #   step_measure_input_wide(starts_with(\"signal_\")) |> #   step_measure_baseline_als() |> #   step_measure_mw_averages() |> #   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"step_measure_mw_distribution() creates specification recipe step generates molecular weight distribution curves SEC/GPC data. step superseded measure.sec::step_sec_mw_distribution(). new code, recommend using measure.sec package provides complete SEC/GPC analysis functionality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"","code":"step_measure_mw_distribution(   recipe,   measures = NULL,   type = c(\"differential\", \"cumulative\", \"both\"),   calibration = NULL,   n_points = 100L,   mw_range = NULL,   normalize = TRUE,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_mw_distribution\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"recipe recipe object. measures optional character vector measure column names. type Type distribution generate: \"differential\" (default): dW/d(log M) differential distribution \"cumulative\": Cumulative weight fraction distribution \"\": Generate distributions calibration Calibration method converting x-axis log(MW). See step_measure_mw_averages() details. n_points Number points output distribution. Default 100. NULL, uses original data resolution. mw_range Optional numeric vector c(min, max) specifying MW range output distribution. NULL, uses range data. normalize Logical. differential distribution normalized integrate 1? Default TRUE. role Role generated columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"step transforms raw chromatogram standard MW distribution representations: Differential Distribution (dW/d(log M)): weight fraction per unit log(MW). representation preferred area curve represents weight fraction MW range. Cumulative Distribution: cumulative weight fraction low high MW. Values range 0 1. output replaces .measures column distribution data, location contains log10(MW) values value contains distribution values.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Molecular Weight Distribution Curve — step_measure_mw_distribution","text":"","code":"library(recipes)  # Generate differential MW distribution # rec <- recipe(~., data = gpc_data) |> #   step_measure_input_wide(starts_with(\"signal_\")) |> #   step_measure_baseline_als() |> #   step_measure_mw_distribution(type = \"differential\") |> #   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"step_measure_mw_fractions() creates specification recipe step calculates weight fractions specified molecular weight cutoffs. step superseded measure.sec::step_sec_mw_fractions(). new code, recommend using measure.sec package provides complete SEC/GPC analysis functionality.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"","code":"step_measure_mw_fractions(   recipe,   measures = NULL,   cutoffs = c(1000, 10000, 1e+05),   calibration = NULL,   integration_range = NULL,   prefix = \"frac_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_mw_fractions\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"recipe recipe object. measures optional character vector measure column names. cutoffs Numeric vector MW cutoff values. cutoff, step calculates weight fraction value. calibration Calibration method converting x-axis log(MW). See step_measure_mw_averages() details. integration_range Optional numeric vector c(min, max) specifying x-axis range integration. NULL, uses full range. prefix Prefix output column names. Default \"frac_\". role Role generated columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"cutoff value C, step calculates: frac_below_C: Weight fraction MW < C frac_above_C: Weight fraction MW >= C fractions sum 1.0 useful characterizing polymer distributions. Common cutoffs include: 1000 Da oligomer content 10000 Da low MW fraction 100000 Da high MW fraction","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_mw_fractions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Molecular Weight Fractions for SEC/GPC — step_measure_mw_fractions","text":"","code":"library(recipes)  # Calculate fractions at multiple cutoffs # rec <- recipe(~., data = gpc_data) |> #   step_measure_input_wide(starts_with(\"signal_\")) |> #   step_measure_baseline_als() |> #   step_measure_mw_fractions(cutoffs = c(1000, 10000, 100000)) |> #   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize by Area Under Curve — step_measure_normalize_auc","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"step_measure_normalize_auc() creates specification recipe step divides spectrum area curve (computed using trapezoidal integration). useful chromatography peak areas meaningful.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"","code":"step_measure_normalize_auc(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_auc\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"area curve computed using trapezoidal integration: $$AUC = \\sum_{=1}^{n-1} \\frac{(y_i + y_{+1})}{2} \\cdot (x_{+1} - x_i)$$ \\(y\\) values \\(x\\) locations. transformation, AUC spectrum equal 1. AUC zero NA, warning issued original values returned unchanged. least 2 points required integration. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_auc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize by Area Under Curve — step_measure_normalize_auc","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_auc() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Standard Normalization — step_measure_normalize_istd","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"step_measure_normalize_istd() alias step_measure_normalize_peak() domain-specific naming chromatography mass spectrometry users. normalizes spectra dividing value computed specific region (internal standard peak).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"","code":"step_measure_normalize_istd(   recipe,   location_min,   location_max,   method = \"mean\",   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_istd\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"recipe recipe object. step added sequence operations recipe. location_min Numeric. lower bound region use normalization. parameter tunable peak_location_min(). location_max Numeric. upper bound region use normalization. parameter tunable peak_location_max(). method Character. summary statistic compute region. One \"mean\" (default), \"max\", \"integral\". measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"function identical step_measure_normalize_peak() uses terminology familiar chromatography mass spectrometry practitioners. Internal standard (ISTD) normalization commonly used correct : Injection volume variations Ionization efficiency differences Matrix effects Instrument drift internal standard compound : chemically stable naturally occur samples Elutes distinct region consistent response","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_istd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Internal Standard Normalization — step_measure_normalize_istd","text":"","code":"library(recipes)  # Normalize to internal standard peak region (channels 50-60) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_istd(     location_min = 50,     location_max = 60,     method = \"integral\"   )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize by Maximum Value — step_measure_normalize_max","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"step_measure_normalize_max() creates specification recipe step divides spectrum maximum value. useful peak-focused analysis want highest peak equal 1.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"","code":"step_measure_normalize_max(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_max\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"spectrum \\(x\\), transformation : $$x_{norm} = \\frac{x}{\\max(x)}$$ transformation, maximum value spectrum equal 1. maximum zero NA, warning issued original values returned unchanged. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_max.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize by Maximum Value — step_measure_normalize_max","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_max() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize to a Specific Peak Region — step_measure_normalize_peak","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"step_measure_normalize_peak() creates specification recipe step divides spectrum summary statistic computed specified region. commonly used internal standard normalization.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"","code":"step_measure_normalize_peak(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   location_min = NULL,   location_max = NULL,   method = \"mean\",   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_peak\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. location_min Numeric. lower bound region use normalization. parameter tunable peak_location_min(). location_max Numeric. upper bound region use normalization. parameter tunable peak_location_max(). method Character. summary statistic compute region. One \"mean\" (default), \"max\", \"integral\". skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"spectrum, step: Selects values region [location_min, location_max] Computes summary statistic (mean, max, integral) region Divides entire spectrum value useful internal standard peak known location want normalize spectra peak. location_min location_max parameters tunable peak_location_min() peak_location_max() hyperparameter optimization. values fall within specified region, error raised. computed normalizer zero NA, warning issued original values returned unchanged. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_peak.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize to a Specific Peak Region — step_measure_normalize_peak","text":"","code":"library(recipes)  # Normalize to mean of region 40-60 rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_peak(location_min = 40, location_max = 60) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize to Range 0-1 — step_measure_normalize_range","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"step_measure_normalize_range() creates specification recipe step applies min-max normalization scale spectrum range 0 1.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"","code":"step_measure_normalize_range(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_range\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"spectrum \\(x\\), transformation : $$x_{norm} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}$$ transformation, minimum value spectrum 0 maximum 1. range zero (constant spectrum), warning issued centered values returned (minimum subtracted scaling). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_range.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize to Range 0-1 — step_measure_normalize_range","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_range() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"step_measure_normalize_sum() creates specification recipe step divides spectrum sum (total intensity). useful comparing relative abundances across samples different total signals.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"","code":"step_measure_normalize_sum(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_sum\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"spectrum \\(x\\), transformation : $$x_{norm} = \\frac{x}{\\sum x}$$ transformation, sum spectrum equal 1. sum zero NA, warning issued original values returned unchanged. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_sum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize by Sum (Total Intensity) — step_measure_normalize_sum","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_sum() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"step_measure_normalize_vector() creates specification recipe step divides spectrum L2 (Euclidean) norm. transformation, spectrum unit length Euclidean space.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"","code":"step_measure_normalize_vector(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_normalize_vector\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"spectrum \\(x\\), transformation : $$x_{norm} = \\frac{x}{\\|x\\|_2} = \\frac{x}{\\sqrt{\\sum x^2}}$$ transformation, L2 norm spectrum equal 1. L2 norm zero NA, warning issued original values returned unchanged. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_normalize_vector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize by L2 (Euclidean) Norm — step_measure_normalize_vector","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_normalize_vector() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":null,"dir":"Reference","previous_headings":"","what":"Orthogonal Signal Correction (OSC) — step_measure_osc","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"step_measure_osc() creates specification recipe step applies Orthogonal Signal Correction remove variation orthogonal outcome.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"","code":"step_measure_osc(   recipe,   n_components = 1L,   tolerance = 1e-06,   max_iter = 100L,   measures = NULL,   role = NA,   trained = FALSE,   weights = NULL,   loadings = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_osc\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"recipe recipe object. n_components Number orthogonal components remove. Default 1. tolerance Convergence tolerance NIPALS algorithm. Default 1e-6. max_iter Maximum iterations NIPALS. Default 100. measures optional character vector measure column names. role used. trained Logical indicating step trained. weights learned orthogonal weights (training). loadings learned orthogonal loadings (training). skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"Orthogonal Signal Correction (OSC) removes variation X orthogonal Y (outcome). useful removing systematic variation related response. Algorithm: Compute initial score t Y using SVD Orthogonalize t respect Y Iterate NIPALS find orthogonal components Remove orthogonal components X Important: recipe must least one outcome variable role \"outcome\" Outcomes automatically detected recipe's role definitions Multiple outcomes supported (multivariate Y) OSC originally described Wold et al. (1998) NIR spectroscopy.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"Wold, S., Antti, H., Lindgren, F., Ohman, J. (1998). Orthogonal signal correction near-infrared spectra. Chemometrics Intelligent Laboratory Systems, 44(1-2), 175-185.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_osc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Orthogonal Signal Correction (OSC) — step_measure_osc","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_osc(n_components = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorganize Measurements to Long Format — step_measure_output_long","title":"Reorganize Measurements to Long Format — step_measure_output_long","text":"step_measure_output_long creates specification recipe","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorganize Measurements to Long Format — step_measure_output_long","text":"","code":"step_measure_output_long(   recipe,   values_to = \".measure\",   location_to = \".location\",   measures = NULL,   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = rand_id(\"measure_output_long\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorganize Measurements to Long Format — step_measure_output_long","text":"recipe recipe object. step added sequence operations recipe. values_to single character string column containing analytical measurement. location_to single character string column name prefix location columns. 1D data, becomes column name (default: .location). nD data, becomes prefix dimension suffixes (e.g., .location_1, .location_2). measures optional single character string specifying measure column output. NULL (default) one measure column exists, column used. multiple measure columns exist measures NULL, error thrown prompting specify column output. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reorganize Measurements to Long Format — step_measure_output_long","text":"step converts measures format columns measurement corresponding location (.e., \"long\" format). step designed convert analytical measurements internal data structure long format explicit location columns. 1D data, output two columns: measurement value single location column. n-dimensional data (2D, 3D, etc.), output n+1 columns: measurement value n location columns named location_to prefix followed dimension numbers (e.g., .location_1, .location_2).","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorganize Measurements to Long Format — step_measure_output_long","text":"","code":"library(dplyr)  data(glucose_bioreactors) bioreactors_small$batch_sample <- NULL  small_tr <- bioreactors_small[1:200, ] small_te <- bioreactors_small[201:210, ]  small_rec <-   recipe(glucose ~ ., data = small_tr) |>   update_role(batch_id, day, new_role = \"id columns\") |>   step_measure_input_wide(`400`:`3050`) |>   prep()  # Before reformatting:  small_rec |> bake(new_data = small_te) #> # A tibble: 10 × 4 #>    batch_id   day glucose   .measures #>    <chr>    <int>   <dbl>      <meas> #>  1 S_15         5    2.04 [2,651 × 2] #>  2 S_15         6    5.56 [2,651 × 2] #>  3 S_15         7    4.65 [2,651 × 2] #>  4 S_15         8    9.91 [2,651 × 2] #>  5 S_15         9    4.96 [2,651 × 2] #>  6 S_15        10    6.78 [2,651 × 2] #>  7 S_15        11    6.72 [2,651 × 2] #>  8 S_15        12    4.69 [2,651 × 2] #>  9 S_15        13    6.30 [2,651 × 2] #> 10 S_15        14    3.10 [2,651 × 2]  # After reformatting:  output_rec <-   small_rec |>   step_measure_output_long() |>   prep()  output_rec |> bake(new_data = small_te) #> # A tibble: 26,510 × 5 #>    batch_id   day glucose .location .measure #>    <chr>    <int>   <dbl>     <dbl>    <dbl> #>  1 S_15         5    2.04         1  760094. #>  2 S_15         5    2.04         2  779053. #>  3 S_15         5    2.04         3  797154. #>  4 S_15         5    2.04         4  817226. #>  5 S_15         5    2.04         5  832725. #>  6 S_15         5    2.04         6  840075. #>  7 S_15         5    2.04         7  841721. #>  8 S_15         5    2.04         8  832112. #>  9 S_15         5    2.04         9  819494. #> 10 S_15         5    2.04        10  799601. #> # ℹ 26,500 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorganize Measurements to Separate Columns — step_measure_output_wide","title":"Reorganize Measurements to Separate Columns — step_measure_output_wide","text":"step_measure_output_wide creates specification recipe step converts measures multiple columns (.e., \"wide\" format).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorganize Measurements to Separate Columns — step_measure_output_wide","text":"","code":"step_measure_output_wide(   recipe,   prefix = \"measure_\",   measures = NULL,   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = rand_id(\"measure_output_wide\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorganize Measurements to Separate Columns — step_measure_output_wide","text":"recipe recipe object. step added sequence operations recipe. prefix character string used name new columns. measures optional single character string specifying measure column output. NULL (default) one measure column exists, column used. multiple measure columns exist measures NULL, error thrown prompting specify column output. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_wide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reorganize Measurements to Separate Columns — step_measure_output_wide","text":"step designed convert analytical measurements internal data structure separate columns. Wide outputs can helpful want use standard recipes steps measuresments, recipes::step_pca(), recipes::step_pls(), .","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_output_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorganize Measurements to Separate Columns — step_measure_output_wide","text":"","code":"library(dplyr)  data(glucose_bioreactors) bioreactors_small$batch_sample <- NULL  small_tr <- bioreactors_small[1:200, ] small_te <- bioreactors_small[201:210, ]  small_rec <-   recipe(glucose ~ ., data = small_tr) |>   update_role(batch_id, day, new_role = \"id columns\") |>   step_measure_input_wide(`400`:`3050`) |>   prep()  # Before reformatting:  small_rec |> bake(new_data = small_te) #> # A tibble: 10 × 4 #>    batch_id   day glucose   .measures #>    <chr>    <int>   <dbl>      <meas> #>  1 S_15         5    2.04 [2,651 × 2] #>  2 S_15         6    5.56 [2,651 × 2] #>  3 S_15         7    4.65 [2,651 × 2] #>  4 S_15         8    9.91 [2,651 × 2] #>  5 S_15         9    4.96 [2,651 × 2] #>  6 S_15        10    6.78 [2,651 × 2] #>  7 S_15        11    6.72 [2,651 × 2] #>  8 S_15        12    4.69 [2,651 × 2] #>  9 S_15        13    6.30 [2,651 × 2] #> 10 S_15        14    3.10 [2,651 × 2]  # After reformatting:  output_rec <-   small_rec |>   step_measure_output_wide() |>   prep()  output_rec |> bake(new_data = small_te) #> # A tibble: 10 × 2,654 #>    batch_id   day glucose measure_0001 measure_0002 measure_0003 measure_0004 #>    <chr>    <int>   <dbl>        <dbl>        <dbl>        <dbl>        <dbl> #>  1 S_15         5    2.04      760094.      779053.      797154.      817226. #>  2 S_15         6    5.56      854812.      874105.      893653.      912190. #>  3 S_15         7    4.65      961786.      979449.     1000054.     1019400. #>  4 S_15         8    9.91     1092681.     1110867.     1132371.     1151944. #>  5 S_15         9    4.96     1243318.     1259961.     1281630.     1301011. #>  6 S_15        10    6.78     1500414.     1517867.     1536436.     1557016. #>  7 S_15        11    6.72     1818328.     1836446.     1856983.     1876906. #>  8 S_15        12    4.69     2035750.     2053903.     2073901.     2093514. #>  9 S_15        13    6.30     2192191.     2211502.     2230969.     2251089. #> 10 S_15        14    3.10     2353638.     2371877.     2392865.     2412822. #> # ℹ 2,647 more variables: measure_0005 <dbl>, measure_0006 <dbl>, #> #   measure_0007 <dbl>, measure_0008 <dbl>, measure_0009 <dbl>, #> #   measure_0010 <dbl>, measure_0011 <dbl>, measure_0012 <dbl>, #> #   measure_0013 <dbl>, measure_0014 <dbl>, measure_0015 <dbl>, #> #   measure_0016 <dbl>, measure_0017 <dbl>, measure_0018 <dbl>, #> #   measure_0019 <dbl>, measure_0020 <dbl>, measure_0021 <dbl>, #> #   measure_0022 <dbl>, measure_0023 <dbl>, measure_0024 <dbl>, …"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":null,"dir":"Reference","previous_headings":"","what":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"step_measure_parafac() creates specification recipe step applies Parallel Factor Analysis (PARAFAC) multi-dimensional measurement data, extracting component scores features modeling.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"","code":"step_measure_parafac(   recipe,   ...,   n_components = 3L,   center = TRUE,   scale = FALSE,   max_iter = 500L,   tol = 1e-06,   prefix = \"parafac_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_parafac\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"recipe recipe object. ... One selector functions choose measure columns. empty, nD measure columns used. n_components Number PARAFAC components extract. Default 3. center Logical. data centered decomposition? Default TRUE. scale Logical. data scaled decomposition? Default FALSE. max_iter Maximum number iterations. Default 500. tol Convergence tolerance. Default 1e-6. prefix Prefix output column names. Default \"parafac_\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"PARAFAC (also known CANDECOMP/PARAFAC CP decomposition) decomposes three-way higher array sum rank-one tensors. measurement data like EEM (excitation-emission matrices) LC-DAD, extracts interpretable components corresponding underlying chemical species.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"Input must measure_nd_list 2+ dimensions samples must grid (regular, aligned) multiway package must installed (Suggests)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"Creates numeric feature columns: parafac_1, parafac_2, ..., parafac_n representing sample's scores extracted components.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"step requires multiway package. Install : install.packages(\"multiway\")","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_parafac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PARAFAC Decomposition for Multi-Dimensional Data — step_measure_parafac","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes)  # After ingesting EEM data as 2D measurements rec <- recipe(concentration ~ ., data = eem_data) |>   step_measure_input_long(     fluorescence,     location = vars(excitation, emission)   ) |>   step_measure_parafac(n_components = 3) |>   prep()  bake(rec, new_data = NULL) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":null,"dir":"Reference","previous_headings":"","what":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"step_measure_peaks_deconvolve() creates specification recipe step resolves overlapping peaks using curve fitting. step requires peaks detected first using step_measure_peaks_detect().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"","code":"step_measure_peaks_deconvolve(   recipe,   model = c(\"gaussian\", \"emg\", \"bigaussian\"),   max_iter = 100L,   tol = 1e-06,   peaks_col = \".peaks\",   measures_col = \".measures\",   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_peaks_deconvolve\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"recipe recipe object. model Peak model use: \"gaussian\" (symmetric), \"emg\" (exponentially modified Gaussian tailing peaks), \"bigaussian\" (asymmetric). Default \"gaussian\". max_iter Maximum iterations optimization. Default 100. tol Convergence tolerance. Default 1e-6. peaks_col Name peaks column. Default \".peaks\". measures_col Name measures column. Default \".measures\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"updated recipe new step added. .peaks column updated deconvolved peak parameters fitted areas.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"Peak deconvolution fits mathematical models overlapping peaks determine individual contributions. essential quantitative analysis peaks baseline-resolved. Peak Models: gaussian: Symmetric Gaussian peak (3 params: height, center, width) emg: Exponentially Modified Gaussian (4 params, handles tailing) bigaussian: Bi-Gaussian (5 params, flexible asymmetry) optimization uses initial estimates detected peak positions refines minimize residual sum squares.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_deconvolve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deconvolve Overlapping Peaks — step_measure_peaks_deconvolve","text":"","code":"library(recipes)  # Deconvolve overlapping peaks # rec <- recipe(~., data = chromatogram_data) |> #   step_measure_input_long(signal, location = vars(time)) |> #   step_measure_peaks_detect(method = \"derivative\") |> #   step_measure_peaks_deconvolve(model = \"gaussian\") |> #   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Peaks in Measurements — step_measure_peaks_detect","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"step_measure_peaks_detect() creates specification recipe step detects peaks measurement data stores new .peaks column.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"","code":"step_measure_peaks_detect(   recipe,   method = c(\"prominence\", \"derivative\"),   min_height = 0,   min_distance = 0,   min_prominence = 0,   snr_threshold = FALSE,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_peaks_detect\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"recipe recipe object. method Peak detection method. One \"prominence\" (default) \"derivative\". min_height Minimum peak height. snr_threshold = TRUE, interpreted signal--noise ratio threshold. min_distance Minimum distance peaks x-axis units. min_prominence Minimum peak prominence (method = \"prominence\"). snr_threshold Logical. TRUE, min_height interpreted signal--noise ratio. Noise estimated MAD signal. measures Optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"step detects peaks measurement data creates new .peaks column containing detected peaks sample. original .measures column preserved. Detection methods: \"prominence\": Finds local maxima calculates prominence (much peak stands surrounding signal). robust noise. \"derivative\": Finds peaks detecting zero-crossings first derivative. Faster sensitive noise. Peak properties stored: peak_id: Integer identifier location: X-axis position peak apex height: Y-value peak apex left_base, right_base: X-axis positions peak boundaries area: Initially NA; use step_measure_peaks_integrate() calculate","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_detect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Peaks in Measurements — step_measure_peaks_detect","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_peaks_detect(min_height = 0.5, min_distance = 5) |>   prep()  result <- bake(rec, new_data = NULL) # Result now has .peaks column alongside .measures"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Peaks by Criteria — step_measure_peaks_filter","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"step_measure_peaks_filter() creates specification recipe step filters detected peaks based various criteria.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"","code":"step_measure_peaks_filter(   recipe,   min_height = NULL,   min_area = NULL,   min_area_pct = NULL,   min_prominence = NULL,   max_peaks = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_peaks_filter\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"recipe recipe object. min_height Minimum peak height. Peaks removed. min_area Minimum peak area. Requires prior integration. min_area_pct Minimum area percentage total. Peaks area less percentage total peak area removed. min_prominence Minimum peak prominence. max_peaks Maximum number peaks keep (keeps largest area height). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"step removes peaks meet specified criteria. Multiple criteria can combined - peaks must pass specified filters.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Peaks by Criteria — step_measure_peaks_filter","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_peaks_detect(min_height = 0.3) |>   step_measure_peaks_integrate() |>   step_measure_peaks_filter(min_area_pct = 1) |>   prep()  result <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrate Peak Areas — step_measure_peaks_integrate","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"step_measure_peaks_integrate() creates specification recipe step calculates area detected peak.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"","code":"step_measure_peaks_integrate(   recipe,   method = c(\"trapezoid\", \"simpson\"),   baseline = c(\"local\", \"none\", \"global\"),   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_peaks_integrate\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"recipe recipe object. method Integration method. One \"trapezoid\" (default) \"simpson\". baseline Baseline handling. One \"local\" (linear interpolation peak bases), \"none\" (integrate zero), \"global\" (use minimum value baseline). measures Optional character vector measure column names. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"step calculates area peak detected step_measure_peaks_detect(). areas stored area column .peaks tibble. Integration methods: \"trapezoid\": Trapezoidal rule integration. Fast accurate well-resolved peaks. \"simpson\": Simpson's rule integration. accurate smooth curves requires odd number points. Baseline handling: \"local\": Subtracts linear baseline connecting left right peak bases integration. \"none\": Integrates directly y=0. \"global\": Subtracts minimum value peak region.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_integrate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrate Peak Areas — step_measure_peaks_integrate","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_peaks_detect(min_height = 0.5) |>   step_measure_peaks_integrate() |>   prep()  result <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"step_measure_peaks_to_table() creates specification recipe step converts peaks list-column wide format one column per peak property.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"","code":"step_measure_peaks_to_table(   recipe,   prefix = \"peak_\",   properties = c(\"location\", \"height\", \"area\"),   max_peaks = 10,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_peaks_to_table\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"recipe recipe object. prefix Prefix generated column names. Default \"peak_\". properties peak properties include. Default includes location, height, area peak. max_peaks Maximum number peaks include output. sample peaks, first max_peaks included. role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"step converts peak data wide format suitable modeling. peak, creates columns like peak_1_location, peak_1_height, peak_1_area, etc. .peaks .measures columns removed conversion.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_peaks_to_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Peaks to Tidy Table — step_measure_peaks_to_table","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_peaks_detect(min_height = 0.5) |>   step_measure_peaks_integrate() |>   step_measure_peaks_to_table(max_peaks = 5) |>   prep()  result <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":null,"dir":"Reference","previous_headings":"","what":"QC Bracketing Interpolation — step_measure_qc_bracket","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"step_measure_qc_bracket() creates specification recipe step corrects drift using linear interpolation bracketing QC reference samples. simple, intuitive method sample corrected based two nearest QC samples.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"","code":"step_measure_qc_bracket(   recipe,   ...,   run_order_col = \"run_order\",   sample_type_col = \"sample_type\",   qc_type = \"qc\",   apply_to = c(\"all\", \"unknown\"),   extrapolate = TRUE,   min_qc = 2,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_qc_bracket\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"recipe recipe object. ... One selector functions choose feature columns. feature-level data, select numeric response columns. curve-level data .measures, leave empty apply locations. run_order_col Name column containing run order (injection sequence). Must numeric/integer. sample_type_col Name column containing sample type. qc_type Value(s) sample_type_col identify QC samples use drift modeling. Default \"qc\". apply_to samples apply correction : \"\" (default): Correct samples \"unknown\": correct unknown samples extrapolate Logical. correction extrapolated samples first last QC? Default TRUE. FALSE, samples use nearest QC's correction factor. min_qc Minimum number QC samples required. Default 5. role used step. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"how-it-works","dir":"Reference","previous_headings":"","what":"How It Works","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"sample run order t: Find nearest QC samples (t1) (t2) Calculate correction factors t1 t2 (target / observed) Linearly interpolate correction factor t Apply interpolated correction method commonly used clinical bioanalytical laboratories QC samples injected regular intervals throughout run.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"when-to-use","dir":"Reference","previous_headings":"","what":"When to Use","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"Regular QC injection intervals Short analytical runs want simple, transparent corrections Regulatory environments interpretability important","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_bracket.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"QC Bracketing Interpolation — step_measure_qc_bracket","text":"","code":"library(recipes)  # Data with QC samples at regular intervals data <- data.frame(   sample_id = paste0(\"S\", 1:15),   sample_type = c(\"qc\", rep(\"unknown\", 4), \"qc\", rep(\"unknown\", 4), \"qc\",                   rep(\"unknown\", 3), \"qc\"),   run_order = 1:15,   feature1 = c(100, 101, 103, 105, 107, 105, 107, 109, 111, 113,                110, 112, 114, 116, 115)  # Drift pattern )  rec <- recipe(~ ., data = data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_qc_bracket(feature1) |>   prep()  corrected <- bake(rec, new_data = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Outlier Samples — step_measure_qc_outlier","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"step_measure_qc_outlier() creates specification recipe step detects outlier samples using Mahalanobis distance PCA-based methods. new column added indicating outlier status.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"","code":"step_measure_qc_outlier(   recipe,   measures = NULL,   method = c(\"mahalanobis\", \"pca\"),   threshold = 3,   n_components = NULL,   new_col = \".outlier\",   new_col_score = \".outlier_score\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_qc_outlier\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"recipe recipe object. measures optional character vector measure column names. method Detection method: \"mahalanobis\" (default): Mahalanobis distance robust covariance \"pca\": PCA score-based outliers (Hotelling's T^2) threshold Threshold outlier detection standard deviation units. Default 3. Tunable via outlier_threshold(). n_components PCA method, number components use. Default NULL (auto-select based variance explained). new_col Name new outlier flag column. Default \".outlier\". new_col_score Name outlier score column. Default \".outlier_score\". role Role new columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"Outlier samples can arise measurement errors, sample preparation issues, genuine unusual samples. step helps identify . Mahalanobis method: Computes multivariate distance sample center distribution, accounting correlations. Uses robust estimation center covariance via median MAD. PCA method: Projects data onto principal components computes Hotelling's T^2 statistic. Samples extreme scores flagged. Two columns added: .outlier: Logical flag .outlier_score: Numeric score (higher = extreme)","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_outlier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Outlier Samples — step_measure_qc_outlier","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_qc_outlier(threshold = 3) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 7 #>       id water   fat protein .measures .outlier .outlier_score #>    <int> <dbl> <dbl>   <dbl>    <meas> <lgl>             <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2] FALSE             0.305 #>  2     2  46    40.1    13.5 [100 × 2] FALSE             0.323 #>  3     3  71     8.4    20.5 [100 × 2] FALSE             0.626 #>  4     4  72.8   5.9    20.7 [100 × 2] FALSE             0.133 #>  5     5  58.3  25.5    15.5 [100 × 2] FALSE             0.310 #>  6     6  44    42.7    13.7 [100 × 2] FALSE             0.793 #>  7     7  44    42.7    13.7 [100 × 2] FALSE             0.731 #>  8     8  69.3  10.6    19.3 [100 × 2] FALSE             0.522 #>  9     9  61.4  19.9    17.7 [100 × 2] FALSE             1.44  #> 10    10  61.4  19.9    17.7 [100 × 2] FALSE             1.78  #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Saturated Measurements — step_measure_qc_saturated","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"step_measure_qc_saturated() creates specification recipe step detects saturated (clipped) regions measurements adds metadata columns indicating saturation status.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"","code":"step_measure_qc_saturated(   recipe,   measures = NULL,   upper_limit = NULL,   lower_limit = NULL,   tolerance = 0.01,   new_col_flag = \".saturated\",   new_col_pct = \".sat_pct\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_qc_saturated\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"recipe recipe object. measures optional character vector measure column names. upper_limit Upper saturation threshold. Default NULL (auto-detect). lower_limit Lower saturation threshold. Default NULL (auto-detect). tolerance close limit counts saturated. Default 0.01. new_col_flag Name column saturation flag. Default \".saturated\". new_col_pct Name column saturation percentage. Default \".sat_pct\". role Role new columns. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"Saturation occurs detector response reaches maximum (minimum) capacity. Saturated data points lose quantitative information may need special handling. limits specified, auto-detected values appearing flat regions extreme values (using min() max()). Two new columns added: .saturated: Logical, TRUE saturation detected .sat_pct: Percentage points saturated","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_saturated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Saturated Measurements — step_measure_qc_saturated","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_qc_saturated() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 7 #>       id water   fat protein .measures .saturated .sat_pct #>    <int> <dbl> <dbl>   <dbl>    <meas> <lgl>         <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2] FALSE             0 #>  2     2  46    40.1    13.5 [100 × 2] FALSE             0 #>  3     3  71     8.4    20.5 [100 × 2] FALSE             0 #>  4     4  72.8   5.9    20.7 [100 × 2] FALSE             0 #>  5     5  58.3  25.5    15.5 [100 × 2] FALSE             0 #>  6     6  44    42.7    13.7 [100 × 2] FALSE             0 #>  7     7  44    42.7    13.7 [100 × 2] FALSE             0 #>  8     8  69.3  10.6    19.3 [100 × 2] FALSE             0 #>  9     9  61.4  19.9    17.7 [100 × 2] FALSE             0 #> 10    10  61.4  19.9    17.7 [100 × 2] FALSE             0 #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"step_measure_qc_snr() creates specification recipe step calculates signal--noise ratio (SNR) measurement adds new column. useful quality control filtering.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"","code":"step_measure_qc_snr(   recipe,   measures = NULL,   new_col = \".snr\",   signal_method = c(\"max\", \"range\", \"rms\"),   noise_method = c(\"diff\", \"mad\", \"residual\"),   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_qc_snr\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"recipe recipe object. measures optional character vector measure column names. new_col Name new column store SNR values. Default \".snr\". signal_method estimate signal: \"max\" (default): Maximum absolute value \"range\": Peak--peak range \"rms\": Root mean square noise_method estimate noise: \"diff\" (default): RMS first differences (estimates high-freq noise) \"mad\": Median absolute deviation values \"residual\": Residuals smoothed fit role Role new column. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"SNR calculated signal / noise, signal noise estimated using specified methods. Higher values indicate cleaner data. \"diff\" noise method particularly useful estimates high-frequency noise without affected broad spectral features: $$noise = \\sqrt{\\frac{1}{2(n-1)} \\sum_{=2}^{n} (x_i - x_{-1})^2}$$","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_qc_snr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Signal-to-Noise Ratio — step_measure_qc_snr","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_qc_snr() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 6 #>       id water   fat protein .measures  .snr #>    <int> <dbl> <dbl>   <dbl>    <meas> <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2]  277. #>  2     2  46    40.1    13.5 [100 × 2]  370. #>  3     3  71     8.4    20.5 [100 × 2]  291. #>  4     4  72.8   5.9    20.7 [100 × 2]  278. #>  5     5  58.3  25.5    15.5 [100 × 2]  271. #>  6     6  44    42.7    13.7 [100 × 2]  374. #>  7     7  44    42.7    13.7 [100 × 2]  374. #>  8     8  69.3  10.6    19.3 [100 × 2]  255. #>  9     9  61.4  19.9    17.7 [100 × 2]  310. #> 10    10  61.4  19.9    17.7 [100 × 2]  303. #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"step_measure_ratio_reference() creates specification recipe step computes ratio spectrum reference, optionally blank subtraction.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"","code":"step_measure_ratio_reference(   recipe,   reference,   blank = NULL,   measures = NULL,   role = NA,   trained = FALSE,   learned_ref = NULL,   learned_blank = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_ratio_reference\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"recipe recipe object. step added sequence operations recipe. reference required external reference spectrum. Can : measure_tbl object location value columns numeric vector (must match number locations data) data.frame location value columns (interpolated) blank optional blank spectrum subtract sample reference computing ratio. format options reference. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_ref named list containing validated reference values measure column. NULL step trained. learned_blank named list containing learned blank values measure column. NULL step trained. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"step computes ratio relative reference spectrum: Without blank: result = sample / reference blank: result = (sample - blank) / (reference - blank) useful computing relative measurements, absorbance transmittance sample reference scans.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratio_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Ratio to Reference Spectrum — step_measure_ratio_reference","text":"","code":"library(recipes)  # Create reference and blank spectra ref_spectrum <- rep(1.0, 100) blank_spectrum <- rep(0.05, 100)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_ratio_reference(     reference = ref_spectrum,     blank = blank_spectrum   )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Region Ratios — step_measure_ratios","title":"Calculate Region Ratios — step_measure_ratios","text":"step_measure_ratios() creates specification recipe step calculates ratios integrated regions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Region Ratios — step_measure_ratios","text":"","code":"step_measure_ratios(   recipe,   numerator,   denominator,   name = NULL,   method = c(\"trapezoid\", \"simpson\"),   measures = NULL,   prefix = \"ratio_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_ratios\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Region Ratios — step_measure_ratios","text":"recipe recipe object. numerator numeric vector length 2 specifying numerator region. denominator numeric vector length 2 specifying denominator region. name Output column name. NULL, auto-generated prefix. method Integration method: \"trapezoid\" (default) \"simpson\". measures optional character vector measure column names. prefix Prefix output column name name NULL. Default \"ratio_\". role Role generated column. Default \"predictor\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Region Ratios — step_measure_ratios","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Region Ratios — step_measure_ratios","text":"step calculates ratio integrated areas two regions: ratio = integral(numerator) / integral(denominator) useful calculating peak ratios spectroscopy, relative concentrations chromatography. denominator integral zero NA, ratio NA.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_ratios.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Region Ratios — step_measure_ratios","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_ratios(     numerator = c(1, 30),     denominator = c(70, 100),     name = \"low_high_ratio\"   ) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 6 #>       id water   fat protein .measures low_high_ratio #>    <int> <dbl> <dbl>   <dbl>    <meas>          <dbl> #>  1     1  60.5  22.5    16.7 [100 × 2]          0.824 #>  2     2  46    40.1    13.5 [100 × 2]          0.839 #>  3     3  71     8.4    20.5 [100 × 2]          0.896 #>  4     4  72.8   5.9    20.7 [100 × 2]          0.882 #>  5     5  58.3  25.5    15.5 [100 × 2]          0.800 #>  6     6  44    42.7    13.7 [100 × 2]          0.829 #>  7     7  44    42.7    13.7 [100 × 2]          0.841 #>  8     8  69.3  10.6    19.3 [100 × 2]          0.821 #>  9     9  61.4  19.9    17.7 [100 × 2]          0.824 #> 10    10  61.4  19.9    17.7 [100 × 2]          0.828 #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":null,"dir":"Reference","previous_headings":"","what":"Resample Measurements to New Grid — step_measure_resample","title":"Resample Measurements to New Grid — step_measure_resample","text":"step_measure_resample() creates specification recipe step interpolates measurements new regular x-axis grid.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resample Measurements to New Grid — step_measure_resample","text":"","code":"step_measure_resample(   recipe,   n = NULL,   spacing = NULL,   range = NULL,   method = c(\"linear\", \"spline\"),   measures = NULL,   role = NA,   trained = FALSE,   new_locations = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_resample\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resample Measurements to New Grid — step_measure_resample","text":"recipe recipe object. step added sequence operations recipe. n positive integer specifying number points new grid. Mutually exclusive spacing. spacing positive numeric value specifying spacing points new grid. Mutually exclusive n. range Optional numeric vector length 2 specifying range new grid c(min, max). NULL (default), uses range existing measurements. method interpolation method. One : \"linear\": Linear interpolation (default) \"spline\": Cubic spline interpolation (smoother) measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. new_locations computed new grid locations (training). skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resample Measurements to New Grid — step_measure_resample","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resample Measurements to New Grid — step_measure_resample","text":"step interpolates measurements new regular grid x-axis values. useful : Aligning data different instruments different sampling rates Reducing data density faster processing Ensuring uniform spacing methods require Matching measurements reference grid new grid determined prep() based training data. range specified, grid spans minimum maximum location values training data. Interpolation methods: \"linear\": Fast simple, may introduce slight distortion peaks \"spline\": Smoother interpolation preserves peak shape better","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_resample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resample Measurements to New Grid — step_measure_resample","text":"","code":"library(recipes)  # Resample to 50 evenly spaced points rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_resample(n = 50) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7  [50 × 2] #>  2     2  46    40.1    13.5  [50 × 2] #>  3     3  71     8.4    20.5  [50 × 2] #>  4     4  72.8   5.9    20.7  [50 × 2] #>  5     5  58.3  25.5    15.5  [50 × 2] #>  6     6  44    42.7    13.7  [50 × 2] #>  7     7  44    42.7    13.7  [50 × 2] #>  8     8  69.3  10.6    19.3  [50 × 2] #>  9     9  61.4  19.9    17.7  [50 × 2] #> 10    10  61.4  19.9    17.7  [50 × 2] #> # ℹ 205 more rows  # Resample with specific spacing rec2 <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_resample(spacing = 2, method = \"spline\") |>   prep()  bake(rec2, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7  [51 × 2] #>  2     2  46    40.1    13.5  [51 × 2] #>  3     3  71     8.4    20.5  [51 × 2] #>  4     4  72.8   5.9    20.7  [51 × 2] #>  5     5  58.3  25.5    15.5  [51 × 2] #>  6     6  44    42.7    13.7  [51 × 2] #>  7     7  44    42.7    13.7  [51 × 2] #>  8     8  69.3  10.6    19.3  [51 × 2] #>  9     9  61.4  19.9    17.7  [51 × 2] #> 10    10  61.4  19.9    17.7  [51 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":null,"dir":"Reference","previous_headings":"","what":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"step_measure_savitzky_golay creates specification recipe step smooths filters measurement sequence.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"","code":"step_measure_savitzky_golay(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   degree = 3,   window_side = 11,   differentiation_order = 0,   skip = FALSE,   id = rand_id(\"measure_savitzky_golay\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. degree integer polynomial degree use smoothing. window_side integer many units side window. means window_side = 1 total window width 3 (e.g., width 2 * window_side + 1). differentiation_order integer degree filtering (zero indicates differentiation). skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"method can smooth random noise reduce -predictor correlation. fits polynomial window measurements results fewer measurements input. Measurements assumed equally spaced. polynomial degree less window size. Also, window size must greater polynomial degree. either case true, original argument values increased satisfy conditions (warning). selectors supplied step function. data special internal format produced step_measure_input_wide() step_measure_input_long(). measurement locations reset integer indices starting one.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"tidy() step, tibble columns  returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_savitzky_golay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Savitzky-Golay Pre-Processing — step_measure_savitzky_golay","text":"","code":"if (rlang::is_installed(\"prospectr\")) {   rec <-     recipe(water + fat + protein ~ ., data = meats_long) |>     update_role(id, new_role = \"id\") |>     step_measure_input_long(transmittance, location = vars(channel)) |>     step_measure_savitzky_golay(       differentiation_order = 1,       degree = 3,       window_side = 5     ) |>     prep() }"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":null,"dir":"Reference","previous_headings":"","what":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"step_measure_scale_auto() creates specification recipe step applies auto-scaling (also known z-score normalization standardization) measurement location. centers scales unit variance.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"","code":"step_measure_scale_auto(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   learned_params = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_scale_auto\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_params named list containing learned means locations measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"Auto-scaling (standardization) transforms variable zero mean unit variance. gives equal importance measurement locations regardless original scale. data matrix \\(X\\), transformation : $$X_{scaled} = \\frac{X - \\bar{X}}{s_X}$$ \\(\\bar{X}\\) \\(s_X\\) column-wise mean standard deviation computed training data. column zero standard deviation (constant values), column centered, scaled (divisor set 1). means standard deviations learned prep() training data stored use applying transformation new data bake(). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_auto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Auto-Scaling (Z-Score Normalization) — step_measure_scale_auto","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_scale_auto() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":null,"dir":"Reference","previous_headings":"","what":"Pareto Scaling — step_measure_scale_pareto","title":"Pareto Scaling — step_measure_scale_pareto","text":"step_measure_scale_pareto() creates specification recipe step applies Pareto scaling measurement location. compromise scaling auto-scaling, commonly used metabolomics.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pareto Scaling — step_measure_scale_pareto","text":"","code":"step_measure_scale_pareto(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   learned_params = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_scale_pareto\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pareto Scaling — step_measure_scale_pareto","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_params named list containing learned means locations measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pareto Scaling — step_measure_scale_pareto","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pareto Scaling — step_measure_scale_pareto","text":"Pareto scaling divides square root standard deviation rather standard deviation . reduces relative importance large values still giving weight larger fold changes. data matrix \\(X\\), transformation : $$X_{scaled} = \\frac{X - \\bar{X}}{\\sqrt{s_X}}$$ \\(\\bar{X}\\) \\(s_X\\) column-wise mean standard deviation computed training data. column zero standard deviation (constant values), column centered, scaled. means standard deviations learned prep() training data stored use applying transformation new data bake(). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pareto Scaling — step_measure_scale_pareto","text":"van den Berg, R.., Hoefsloot, H.C., Westerhuis, J.., Smilde, .K., van der Werf, M.J. 2006. Centering, scaling, transformations: improving biological information content metabolomics data. BMC Genomics, 7:142.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_pareto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pareto Scaling — step_measure_scale_pareto","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_scale_pareto() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":null,"dir":"Reference","previous_headings":"","what":"Range Scaling — step_measure_scale_range","title":"Range Scaling — step_measure_scale_range","text":"step_measure_scale_range() creates specification recipe step applies range scaling measurement location. centers divides range (max - min) variable.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Range Scaling — step_measure_scale_range","text":"","code":"step_measure_scale_range(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   learned_params = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_scale_range\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Range Scaling — step_measure_scale_range","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_params named list containing learned means locations measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Range Scaling — step_measure_scale_range","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Range Scaling — step_measure_scale_range","text":"Range scaling centers data divides range, giving bounded values suitable methods sensitive variable scale. data matrix \\(X\\), transformation : $$X_{scaled} = \\frac{X - \\bar{X}}{\\max(X) - \\min(X)}$$ \\(\\bar{X}\\) column-wise mean range computed training data. column zero range (constant values), column centered, scaled. means ranges learned prep() training data stored use applying transformation new data bake(). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_range.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Range Scaling — step_measure_scale_range","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_scale_range() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":null,"dir":"Reference","previous_headings":"","what":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"step_measure_scale_vast() creates specification recipe step applies VAST (Variable Stability) scaling measurement location. focuses variables high stability (low coefficient variation).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"","code":"step_measure_scale_vast(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   learned_params = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_scale_vast\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_params named list containing learned means locations measure column. NULL step trained. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"VAST scaling divides product standard deviation coefficient variation (CV = SD/mean). gives weight variables stable across samples (low CV). data matrix \\(X\\), transformation : $$X_{scaled} = \\frac{X - \\bar{X}}{s_X \\cdot CV_X}$$ \\(\\bar{X}\\), \\(s_X\\), \\(CV_X = s_X / |\\bar{X}|\\) computed training data. column zero divisor (constant values zero mean), column centered, scaled. means, standard deviations, CVs learned prep() training data stored use applying transformation new data bake(). selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"van den Berg, R.., Hoefsloot, H.C., Westerhuis, J.., Smilde, .K., van der Werf, M.J. 2006. Centering, scaling, transformations: improving biological information content metabolomics data. BMC Genomics, 7:142.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_scale_vast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VAST Scaling (Variable Stability Scaling) — step_measure_scale_vast","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_scale_vast() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"step_measure_smooth_gaussian() creates specification recipe step applies Gaussian kernel smoothing. produces smooth results preserving general shape peaks.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"","code":"step_measure_smooth_gaussian(   recipe,   measures = NULL,   sigma = 1,   window = NULL,   edge_method = c(\"reflect\", \"constant\", \"NA\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_smooth_gaussian\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"recipe recipe object. measures optional character vector measure column names. sigma standard deviation Gaussian kernel. Default 1. Larger values produce smoothing. Tunable via smooth_sigma(). window window size. NULL (default), automatically set ceiling(6 * sigma) | 1 (6 sigma rule, ensuring odd). edge_method handle edges. One \"reflect\" (default), \"constant\", \"NA\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"Gaussian smoothing convolves spectrum Gaussian kernel: $$G(x) = \\exp(-x^2 / 2\\sigma^2)$$ kernel normalized sum 1. provides smooth, natural-looking results preserve peak shapes better moving average.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_gaussian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Kernel Smoothing — step_measure_smooth_gaussian","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_smooth_gaussian(sigma = 2) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving Average Smoothing — step_measure_smooth_ma","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"step_measure_smooth_ma() creates specification recipe step applies moving average smoothing measurement data. simple fast method reducing high-frequency noise.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"","code":"step_measure_smooth_ma(   recipe,   measures = NULL,   window = 5L,   edge_method = c(\"reflect\", \"constant\", \"NA\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_smooth_ma\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"recipe recipe object. measures optional character vector measure column names. window window size moving average. Must odd integer least 3. Default 5. Larger values produce smoothing. Tunable via smooth_window(). edge_method handle edges full window fit. One \"reflect\" (default, reflects values boundaries), \"constant\" (pads edge values), \"NA\" (returns NA edge values). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"Moving average smoothing replaces point mean neighbors within sliding window. equivalent convolution uniform kernel. window size w, smoothed value position : $$y_i = \\frac{1}{w} \\sum_{j=-k}^{k} x_{+j}$$ k = (w-1)/2 half-window size.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_ma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moving Average Smoothing — step_measure_smooth_ma","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_smooth_ma(window = 5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Median Filter Smoothing — step_measure_smooth_median","title":"Median Filter Smoothing — step_measure_smooth_median","text":"step_measure_smooth_median() creates specification recipe step applies median filter smoothing. robust method particularly effective removing spike noise preserving edges.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Median Filter Smoothing — step_measure_smooth_median","text":"","code":"step_measure_smooth_median(   recipe,   measures = NULL,   window = 5L,   edge_method = c(\"reflect\", \"constant\", \"NA\"),   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_smooth_median\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Median Filter Smoothing — step_measure_smooth_median","text":"recipe recipe object. measures optional character vector measure column names. window window size moving average. Must odd integer least 3. Default 5. Larger values produce smoothing. Tunable via smooth_window(). edge_method handle edges full window fit. One \"reflect\" (default, reflects values boundaries), \"constant\" (pads edge values), \"NA\" (returns NA edge values). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Median Filter Smoothing — step_measure_smooth_median","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Median Filter Smoothing — step_measure_smooth_median","text":"Median filtering replaces point median neighbors within sliding window. Unlike moving average, median filtering robust outliers spikes, making ideal : Removing cosmic ray spikes Raman spectroscopy Cleaning detector artifacts Preserving sharp edges removing noise","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Median Filter Smoothing — step_measure_smooth_median","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_smooth_median(window = 5) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":null,"dir":"Reference","previous_headings":"","what":"Wavelet Denoising — step_measure_smooth_wavelet","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"step_measure_smooth_wavelet() creates specification recipe step applies wavelet-based denoising measurement data. method particularly effective signals localized features like peaks.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"","code":"step_measure_smooth_wavelet(   recipe,   measures = NULL,   wavelet = \"DaubExPhase\",   filter_number = 4L,   threshold_type = c(\"soft\", \"hard\"),   threshold_policy = c(\"universal\", \"sure\", \"cv\"),   levels = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_smooth_wavelet\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"recipe recipe object. measures optional character vector measure column names. wavelet wavelet family use. Default \"DaubExPhase\". Options include \"DaubExPhase\", \"DaubLeAsworthy\", \"Lawton\". filter_number filter number within wavelet family. Default 4. Higher numbers give smoother wavelets. threshold_type Type thresholding: \"soft\" (default) \"hard\". Soft thresholding shrinks coefficients toward zero; hard thresholding sets small coefficients exactly zero. threshold_policy determine threshold: \"universal\" (default): Uses universal threshold sqrt(2*log(n)) \"sure\": Stein's Unbiased Risk Estimate \"cv\": Cross-validation levels Number decomposition levels. Default NULL (auto). role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"Wavelet denoising works : Decomposing signal wavelet coefficients Thresholding small coefficients (presumed noise) Reconstructing signal remaining coefficients approach powerful : adapts local signal characteristics preserves sharp features like peaks can separate noise signal multiple scales Requires wavethresh package installed.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"Wavelet transforms require signal lengths powers 2. Signals automatically padded next power 2 trimmed processing.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_smooth_wavelet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wavelet Denoising — step_measure_smooth_wavelet","text":"","code":"library(recipes)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_smooth_wavelet() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Normal Variate (SNV) Transformation — step_measure_snv","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"step_measure_snv() creates specification recipe step applies Standard Normal Variate transformation spectral data. SNV normalizes spectrum zero mean unit standard deviation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"","code":"step_measure_snv(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_snv\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. Use limit processing specific measure columns working multiple measurement types. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked recipes::bake()? operations baked recipes::prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"Standard Normal Variate (SNV) row-wise transformation normalizes spectrum independently. spectrum \\(x\\), transformation : $$SNV(x) = \\frac{x - \\bar{x}}{s_x}$$ \\(\\bar{x}\\) mean \\(s_x\\) standard deviation spectrum values. SNV commonly used remove multiplicative effects scatter particle size NIR spectroscopy. SNV transformation, spectrum mean zero standard deviation one. selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long(). measurement locations preserved unchanged.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"tidy() step, tibble column terms (set \".measures\") id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_snv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard Normal Variate (SNV) Transformation — step_measure_snv","text":"","code":"library(recipes)  rec <-   recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_snv() |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7 [100 × 2] #>  2     2  46    40.1    13.5 [100 × 2] #>  3     3  71     8.4    20.5 [100 × 2] #>  4     4  72.8   5.9    20.7 [100 × 2] #>  5     5  58.3  25.5    15.5 [100 × 2] #>  6     6  44    42.7    13.7 [100 × 2] #>  7     7  44    42.7    13.7 [100 × 2] #>  8     8  69.3  10.6    19.3 [100 × 2] #>  9     9  61.4  19.9    17.7 [100 × 2] #> 10    10  61.4  19.9    17.7 [100 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Addition Correction — step_measure_standard_addition","title":"Standard Addition Correction — step_measure_standard_addition","text":"step_measure_standard_addition() creates specification recipe step performs standard addition correction compensate matrix effects. method creates sample-specific calibration unknown accurately quantify presence matrix interference.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Addition Correction — step_measure_standard_addition","text":"","code":"step_measure_standard_addition(   recipe,   ...,   addition_col = \"addition\",   sample_id_col,   min_points = 3,   output_suffix = \"_corrected\",   diagnostics = TRUE,   role = \"outcome\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_standard_addition\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Addition Correction — step_measure_standard_addition","text":"recipe recipe object. ... One selector functions choose response columns correct using standard addition. addition_col Name column containing amount standard added (spike amount). Default \"addition\". sample_id_col Name column identifying unique samples. sample gets standard addition curve. min_points Minimum number addition points required per sample. Default 3. output_suffix Suffix output concentration columns. Default \"_corrected\". diagnostics Include diagnostic information (R², slope, intercept)? Default TRUE. role Recipe role new columns. Default \"outcome\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Addition Correction — step_measure_standard_addition","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"standard-addition-method","dir":"Reference","previous_headings":"","what":"Standard Addition Method","title":"Standard Addition Correction — step_measure_standard_addition","text":"Standard addition works : Splitting unknown sample multiple aliquots Adding increasing known amounts analyte aliquot Measuring response aliquots Fitting regression: response = intercept + slope * addition Calculating original concentration x-intercept x-intercept (response = 0) -intercept / slope. Since intercept positive (response original sample) slope positive (response increases addition), original concentration : concentration = intercept / slope","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"data-format","dir":"Reference","previous_headings":"","what":"Data Format","title":"Standard Addition Correction — step_measure_standard_addition","text":"input data : sample identifier column (unique sample) addition amount column (0 unspiked, increasing amounts) Response column(s) corrected","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"when-to-use","dir":"Reference","previous_headings":"","what":"When to Use","title":"Standard Addition Correction — step_measure_standard_addition","text":"Use standard addition : Significant matrix effects present Matrix-matched calibrators available Sample--sample matrix variation expected","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"limitations","dir":"Reference","previous_headings":"","what":"Limitations","title":"Standard Addition Correction — step_measure_standard_addition","text":"Requires multiple measurements per sample Assumes linear response addition range correct non-specific interferences","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_standard_addition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard Addition Correction — step_measure_standard_addition","text":"","code":"library(recipes)  # Standard addition data for two samples sa_data <- data.frame(   sample_id = rep(c(\"Sample1\", \"Sample2\"), each = 4),   addition = rep(c(0, 10, 20, 30), 2),   response = c(     # Sample 1: original conc ~15     150, 250, 350, 450,     # Sample 2: original conc ~25     250, 350, 450, 550   ) )  rec <- recipe(~ ., data = sa_data) |>   step_measure_standard_addition(     response,     addition_col = \"addition\",     sample_id_col = \"sample_id\"   ) |>   prep() #> Warning: essentially perfect fit: summary may be unreliable #> Warning: essentially perfect fit: summary may be unreliable  bake(rec, new_data = NULL) #> # A tibble: 8 × 7 #>   sample_id addition response response_corrected response_sa_slope #>   <fct>        <dbl>    <dbl>              <dbl>             <dbl> #> 1 Sample1          0      150                 15                10 #> 2 Sample1         10      250                 15                10 #> 3 Sample1         20      350                 15                10 #> 4 Sample1         30      450                 15                10 #> 5 Sample2          0      250                 25                10 #> 6 Sample2         10      350                 25                10 #> 7 Sample2         20      450                 25                10 #> 8 Sample2         30      550                 25                10 #> # ℹ 2 more variables: response_sa_intercept <dbl>, response_sa_rsquared <dbl>"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract Blank Measurement — step_measure_subtract_blank","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"step_measure_subtract_blank() creates specification recipe step subtracts divides blank measurement. blank can provided externally learned training data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"","code":"step_measure_subtract_blank(   recipe,   blank = NULL,   blank_col = NULL,   blank_value = NULL,   method = \"subtract\",   measures = NULL,   role = NA,   trained = FALSE,   learned_blank = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_subtract_blank\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"recipe recipe object. step added sequence operations recipe. blank optional external blank use. Can : measure_tbl object location value columns numeric vector (must match number locations data) data.frame location value columns (interpolated) NULL, blank learned training data using blank_col blank_value. blank_col optional column name (unquoted) identifies sample types. Used blank_value identify blank samples training data. blank_value value blank_col identifies blank samples. step prepped, mean blank samples computed stored use baking. method correction method apply: \"subtract\" (default): Subtract blank spectrum \"divide\": Divide spectrum blank measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_blank named list containing learned blank values measure column. NULL step trained. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"Blank subtraction fundamental preprocessing step analytical chemistry. removes background signal present measurements related analyte interest. Two modes operation: External blank: provide blank spectrum directly via blank argument. useful known reference blank. Learned blank: specify samples blanks training data using blank_col blank_value. prep(), mean blank samples computed stored. approach useful batch-specific blank correction. Common use cases: UV-Vis: Remove solvent absorbance IR: Remove atmospheric CO2/H2O interference Fluorescence: Remove buffer background Raman scatter Chromatography: Remove ghost peaks solvent artifacts selectors supplied step function. data internal format produced step_measure_input_wide() step_measure_input_long().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"tidying","dir":"Reference","previous_headings":"","what":"Tidying","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"tidy() step, tibble columns terms, method, blank_source, id returned.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_blank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subtract Blank Measurement — step_measure_subtract_blank","text":"","code":"library(recipes)  # Example with external blank (numeric vector) blank_spectrum <- rep(0.1, 100)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_subtract_blank(blank = blank_spectrum)  # Example learning blank from training data # (assuming sample_type column with \"blank\" values) # rec <- recipe(outcome ~ ., data = my_data) |> #   step_measure_input_long(...) |> #   step_measure_subtract_blank(blank_col = sample_type, blank_value = \"blank\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"step_measure_subtract_reference() creates specification recipe step subtracts divides spectrum external reference. simpler version step_measure_subtract_blank() always uses externally provided reference.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"","code":"step_measure_subtract_reference(   recipe,   reference,   method = \"subtract\",   measures = NULL,   role = NA,   trained = FALSE,   learned_ref = NULL,   skip = FALSE,   id = recipes::rand_id(\"measure_subtract_reference\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"recipe recipe object. step added sequence operations recipe. reference required external reference spectrum. Can : measure_tbl object location value columns numeric vector (must match number locations data) data.frame location value columns (interpolated) method correction method apply: \"subtract\" (default): Subtract blank spectrum \"divide\": Divide spectrum blank measures optional character vector measure column names process. NULL (default), measure columns (columns class measure_list) processed. role used step since new variables created. trained logical indicate quantities preprocessing estimated. learned_ref named list containing validated reference values measure column. NULL step trained. skip logical. step skipped recipe baked? id character string unique step identify .","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"step applies simple reference correction spectrum: method = \"subtract\": result = sample - reference method = \"divide\": result = sample / reference Unlike step_measure_subtract_blank(), step always requires externally provided reference support learning training data.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_subtract_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subtract or Divide by Reference Spectrum — step_measure_subtract_reference","text":"","code":"library(recipes)  # Create a reference spectrum ref_spectrum <- rep(1.0, 100)  rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_subtract_reference(reference = ref_spectrum, method = \"divide\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":null,"dir":"Reference","previous_headings":"","what":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"step_measure_surrogate_recovery() creates specification recipe step calculates recovery percentages surrogate internal standards. essential quality control analytical workflows spiked compounds used monitor method performance.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"","code":"step_measure_surrogate_recovery(   recipe,   ...,   expected_col = NULL,   expected_value = NULL,   recovery_suffix = \"_recovery\",   action = c(\"add_column\", \"flag\", \"filter\"),   flag_col = \".surrogate_pass\",   min_recovery = 70,   max_recovery = 130,   role = \"surrogate\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_surrogate_recovery\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"recipe recipe object. ... One selector functions choose surrogate columns (measured concentrations responses). expected_col Name column containing expected concentrations sample. Mutually exclusive expected_value. expected_value fixed numeric value expected concentration. Used surrogates expected value. Mutually exclusive expected_col. recovery_suffix Suffix appended column names recovery output. Default \"_recovery\". action recovery calculations: \"add_column\" (default): Add new columns recovery percentages \"flag\": Add boolean column indicating recovery within limits \"filter\": Remove rows surrogate outside limits flag_col Name flag column action = \"flag\". Default \".surrogate_pass\". min_recovery Minimum acceptable recovery percentage. Default 70. max_recovery Maximum acceptable recovery percentage. Default 130. role Recipe role new recovery columns. Default \"surrogate\". trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"updated recipe new step added.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"recovery-calculation","dir":"Reference","previous_headings":"","what":"Recovery Calculation","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"Recovery calculated : recovery_pct = (measured / expected) * 100 : measured observed concentration/response surrogate expected known spike amount theoretical value","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"acceptance-criteria","dir":"Reference","previous_headings":"","what":"Acceptance Criteria","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"Typical acceptance limits vary application: ICH M10 (Bioanalytical): 70-130% surrogates EPA Methods: Often 50-150% method-specific FDA Guidance: Application-specific, often 80-120%","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"use-cases","dir":"Reference","previous_headings":"","what":"Use Cases","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"Monitor extraction efficiency sample preparation Track instrument performance across runs Identify samples matrix effects procedural errors","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_surrogate_recovery.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surrogate/Internal Standard Recovery — step_measure_surrogate_recovery","text":"","code":"library(recipes)  # Example: QC data with spiked surrogates qc_data <- data.frame(   sample_id = paste0(\"QC\", 1:10),   surrogate_1 = rnorm(10, mean = 100, sd = 10),   surrogate_2 = rnorm(10, mean = 50, sd = 5),   analyte = rnorm(10, mean = 75, sd = 8) )  # Add recovery columns for surrogates with expected value of 100 and 50 rec <- recipe(~ ., data = qc_data) |>   update_role(sample_id, new_role = \"id\") |>   step_measure_surrogate_recovery(     surrogate_1,     expected_value = 100,     min_recovery = 80,     max_recovery = 120   ) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 10 × 5 #>    sample_id surrogate_1 surrogate_2 analyte surrogate_1_recovery #>    <chr>           <dbl>       <dbl>   <dbl>                <dbl> #>  1 QC1              95.7        51.4    71.3                 95.7 #>  2 QC2             101.         55.1    81.6                101.  #>  3 QC3              91.1        54.1    79.1                 91.1 #>  4 QC4             103.         49.0    70.3                103.  #>  5 QC5             104.         51.9    67.0                104.  #>  6 QC6              99.7        45.3    76.2                 99.7 #>  7 QC7              75.3        54.3    74.9                 75.3 #>  8 QC8             126.         47.7    60.7                126.  #>  9 QC9              97.9        62.1    75.3                 97.9 #> 10 QC10            107.         41.7    76.5                107."},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Absorbance to Transmittance — step_measure_transmittance","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"step_measure_transmittance() creates specification recipe step converts absorbance values transmittance.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"","code":"step_measure_transmittance(   recipe,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_transmittance\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"recipe recipe object. step added sequence operations recipe. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"step applies inverse Beer-Lambert law transformation: $$T = 10^{-}$$ \\(\\) absorbance \\(T\\) transmittance. measurement locations preserved unchanged.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_transmittance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Absorbance to Transmittance — step_measure_transmittance","text":"","code":"library(recipes)  # Convert to absorbance then back to transmittance (round-trip) rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_absorbance() |>   step_measure_transmittance() |>   prep()"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim Measurements to Specified Range — step_measure_trim","title":"Trim Measurements to Specified Range — step_measure_trim","text":"step_measure_trim() creates specification recipe step keeps measurement points within specified x-axis range(s).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim Measurements to Specified Range — step_measure_trim","text":"","code":"step_measure_trim(   recipe,   range,   measures = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_trim\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim Measurements to Specified Range — step_measure_trim","text":"recipe recipe object. step added sequence operations recipe. range numeric vector length 2 specifying range keep c(min, max). Points location >= min <= max retained. measures optional character vector measure column names process. NULL (default), measure columns processed. role used step since new variables created. trained logical indicate step trained. skip logical. step skipped baking? id character string unique step.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim Measurements to Specified Range — step_measure_trim","text":"updated version recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trim Measurements to Specified Range — step_measure_trim","text":"step filters measurements keep points within specified range. useful : Defining integration windows (e.g., keep 8-18 mL elution range) Removing noisy regions start/end measurement Focusing analysis region interest Points location values outside range removed. order remaining points preserved.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_trim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim Measurements to Specified Range — step_measure_trim","text":"","code":"library(recipes)  # Keep only a specific wavelength range rec <- recipe(water + fat + protein ~ ., data = meats_long) |>   update_role(id, new_role = \"id\") |>   step_measure_input_long(transmittance, location = vars(channel)) |>   step_measure_trim(range = c(10, 90)) |>   prep()  bake(rec, new_data = NULL) #> # A tibble: 215 × 5 #>       id water   fat protein .measures #>    <int> <dbl> <dbl>   <dbl>    <meas> #>  1     1  60.5  22.5    16.7  [81 × 2] #>  2     2  46    40.1    13.5  [81 × 2] #>  3     3  71     8.4    20.5  [81 × 2] #>  4     4  72.8   5.9    20.7  [81 × 2] #>  5     5  58.3  25.5    15.5  [81 × 2] #>  6     6  44    42.7    13.7  [81 × 2] #>  7     7  44    42.7    13.7  [81 × 2] #>  8     8  69.3  10.6    19.3  [81 × 2] #>  9     9  61.4  19.9    17.7  [81 × 2] #> 10    10  61.4  19.9    17.7  [81 × 2] #> # ℹ 205 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":null,"dir":"Reference","previous_headings":"","what":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"step_measure_tucker() creates specification recipe step applies Tucker decomposition multi-dimensional measurement data, extracting component scores features modeling.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"","code":"step_measure_tucker(   recipe,   ...,   ranks = 3L,   center = TRUE,   scale = FALSE,   max_iter = 500L,   tol = 1e-06,   prefix = \"tucker_\",   role = \"predictor\",   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"measure_tucker\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"recipe recipe object. ... One selector functions choose measure columns. empty, nD measure columns used. ranks vector ranks mode. single integer, rank used modes. Default 3. center Logical. data centered decomposition? Default TRUE. scale Logical. data scaled decomposition? Default FALSE. max_iter Maximum number iterations. Default 500. tol Convergence tolerance. Default 1e-6. prefix Prefix output column names. Default \"tucker_\". role used. trained Logical indicating step trained. skip Logical. step skipped baking? id Unique step identifier.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"updated recipe new step added.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"Tucker decomposition (also known higher-order SVD multilinear SVD) decomposes tensor core tensor multiplied factor matrices along mode. Unlike PARAFAC, Tucker allows different ranks mode, providing flexibility.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"Input must measure_nd_list 2+ dimensions samples must grid (regular, aligned) multiway package must installed (Suggests)","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"Creates numeric feature columns representing unfolded core tensor scores sample.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"step requires multiway package. Install : install.packages(\"multiway\")","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/step_measure_tucker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tucker Decomposition for Multi-Dimensional Data — step_measure_tucker","text":"","code":"if (FALSE) { # \\dontrun{ library(recipes)  # After ingesting 2D data as nD measurements rec <- recipe(concentration ~ ., data = lc_dad_data) |>   step_measure_input_long(     absorbance,     location = vars(time, wavelength)   ) |>   step_measure_tucker(ranks = c(5, 3)) |>   prep()  bake(rec, new_data = NULL) } # }"},{"path":"https://jameshwade.github.io/measure/dev/reference/subtract_rf_baseline.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract baseline using robust fitting method — subtract_rf_baseline","title":"Subtract baseline using robust fitting method — subtract_rf_baseline","text":"standalone function robust fitting baseline subtraction using local regression iterative reweighting. use within recipe workflow, see step_measure_baseline_rf().","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/subtract_rf_baseline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract baseline using robust fitting method — subtract_rf_baseline","text":"","code":"subtract_rf_baseline(data, yvar, span = 2/3, maxit = c(5, 5))"},{"path":"https://jameshwade.github.io/measure/dev/reference/subtract_rf_baseline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract baseline using robust fitting method — subtract_rf_baseline","text":"data dataframe containing variable baseline subtraction yvar name column baseline subtraction span Controls amount smoothing based fraction data use computing fitted value, defaults 2/3. maxit number iterations use robust fit, defaults c(5, 5) first value specifies iterations asymmetric weighting function second value symmetric weighting function.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/subtract_rf_baseline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtract baseline using robust fitting method — subtract_rf_baseline","text":"dataframe matching column data plus raw baseline columns","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/subtract_rf_baseline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subtract baseline using robust fitting method — subtract_rf_baseline","text":"","code":"library(dplyr) meats_long |>   group_by(id) |>   subtract_rf_baseline(yvar = transmittance) #> # A tibble: 21,500 × 8 #> # Groups:   id [215] #>       id water   fat protein channel transmittance   raw baseline #>    <int> <dbl> <dbl>   <dbl>   <int>         <dbl> <dbl>    <dbl> #>  1     1  60.5  22.5    16.7       1       0.0668   2.62     2.55 #>  2     1  60.5  22.5    16.7       2       0.0598   2.62     2.56 #>  3     1  60.5  22.5    16.7       3       0.0527   2.62     2.57 #>  4     1  60.5  22.5    16.7       4       0.0458   2.62     2.57 #>  5     1  60.5  22.5    16.7       5       0.0389   2.62     2.58 #>  6     1  60.5  22.5    16.7       6       0.0321   2.62     2.59 #>  7     1  60.5  22.5    16.7       7       0.0256   2.62     2.60 #>  8     1  60.5  22.5    16.7       8       0.0193   2.62     2.60 #>  9     1  60.5  22.5    16.7       9       0.0133   2.63     2.61 #> 10     1  60.5  22.5    16.7      10       0.00753  2.63     2.62 #> # ℹ 21,490 more rows"},{"path":"https://jameshwade.github.io/measure/dev/reference/summary.measure_validation_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a Validation Report — summary.measure_validation_report","title":"Summarize a Validation Report — summary.measure_validation_report","text":"Creates summary table validation sections report, showing section status, result counts, notes.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/summary.measure_validation_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a Validation Report — summary.measure_validation_report","text":"","code":"# S3 method for class 'measure_validation_report' summary(object, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/summary.measure_validation_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a Validation Report — summary.measure_validation_report","text":"object measure_validation_report object. ... Additional arguments (currently ignored).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/summary.measure_validation_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a Validation Report — summary.measure_validation_report","text":"tibble columns: section: Section name status: Pass/fail/info status n_results: Number results section notes: Additional notes Returns NULL invisibly report validation sections.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/summary.measure_validation_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize a Validation Report — summary.measure_validation_report","text":"","code":"# Create a report with some sections report <- measure_validation_report(   title = \"Test Report\",   specificity = \"No interference observed\" ) summary(report) #>  #> ── Validation Report Summary ─────────────────────────────────────────────────── #> Method: Not specified #> Date: 2026-01-01 #>  #> # A tibble: 1 × 4 #>   section                 status n_results notes #>   <chr>                   <chr>      <int> <chr> #> 1 Specificity/Selectivity info          NA \"\"    #>  #> ✔ All sections meet acceptance criteria"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a Calibration Curve — tidy.measure_calibration","title":"Tidy a Calibration Curve — tidy.measure_calibration","text":"Extract coefficients statistics calibration curve tidy format.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a Calibration Curve — tidy.measure_calibration","text":"","code":"# S3 method for class 'measure_calibration' tidy(x, ...)  # S3 method for class 'measure_calibration_verify' tidy(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a Calibration Curve — tidy.measure_calibration","text":"x measure_calibration object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a Calibration Curve — tidy.measure_calibration","text":"tibble columns: term: Coefficient name (intercept, slope, quadratic) estimate: Coefficient estimate std_error: Standard error statistic: t-statistic p_value: p-value","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_calibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a Calibration Curve — tidy.measure_calibration","text":"","code":"data <- data.frame(   nominal_conc = c(0, 10, 25, 50, 100),   response = c(0.5, 15.2, 35.8, 72.1, 148.3) ) cal <- measure_calibration_fit(data, response ~ nominal_conc) tidy(cal) #> # A tibble: 2 × 5 #>   term         estimate std_error statistic    p_value #>   <chr>           <dbl>     <dbl>     <dbl>      <dbl> #> 1 (Intercept)    -0.260    0.811     -0.320 0.770      #> 2 nominal_conc    1.48     0.0158    93.6   0.00000269"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_lod.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy LOD/LOQ Results — tidy.measure_lod","title":"Tidy LOD/LOQ Results — tidy.measure_lod","text":"Tidy LOD/LOQ Results","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_lod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy LOD/LOQ Results — tidy.measure_lod","text":"","code":"# S3 method for class 'measure_lod' tidy(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_lod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy LOD/LOQ Results — tidy.measure_lod","text":"x measure_lod, measure_loq, measure_lod_loq object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_lod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy LOD/LOQ Results — tidy.measure_lod","text":"tibble limit value(s) method information.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_uncertainty_budget.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","title":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","text":"Extract uncertainty budget information tidy format.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_uncertainty_budget.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","text":"","code":"# S3 method for class 'measure_uncertainty_budget' tidy(x, type = c(\"components\", \"summary\"), ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_uncertainty_budget.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","text":"x measure_uncertainty_budget object. type return: \"components\" (default): Table individual components \"summary\": Single row summary budget ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_uncertainty_budget.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","text":"tibble budget information.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_uncertainty_budget.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy an Uncertainty Budget — tidy.measure_uncertainty_budget","text":"","code":"u1 <- uncertainty_component(\"Repeatability\", 0.05, type = \"A\", df = 9) u2 <- uncertainty_component(\"Calibrator\", 0.02, type = \"B\") budget <- measure_uncertainty_budget(u1, u2)  tidy(budget) #> # A tibble: 2 × 8 #>   name          type      u sensitivity contribution variance_contribution #>   <chr>         <chr> <dbl>       <dbl>        <dbl>                 <dbl> #> 1 Repeatability A      0.05           1         0.05                0.0025 #> 2 Calibrator    B      0.02           1         0.02                0.0004 #> # ℹ 2 more variables: percent_contribution <dbl>, df <dbl> tidy(budget, type = \"summary\") #> # A tibble: 1 × 7 #>   combined_u effective_df coverage_factor expanded_U result_value relative_u #>        <dbl>        <dbl>           <dbl>      <dbl>        <dbl>      <dbl> #> 1     0.0539         12.1               2      0.108           NA         NA #> # ℹ 1 more variable: relative_U <dbl>"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_validation_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a Validation Report — tidy.measure_validation_report","title":"Tidy a Validation Report — tidy.measure_validation_report","text":"Extracts key parameters statistics validation sections tidy tibble format suitable analysis reporting.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_validation_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a Validation Report — tidy.measure_validation_report","text":"","code":"# S3 method for class 'measure_validation_report' tidy(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_validation_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a Validation Report — tidy.measure_validation_report","text":"x measure_validation_report object. ... Additional arguments (currently ignored).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_validation_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a Validation Report — tidy.measure_validation_report","text":"tibble columns: section: Section name parameter: Parameter name value: Parameter value unit: Unit measurement (available) status: Pass/fail status (available) Returns empty tibble sections contain tidy-able data.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.measure_validation_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a Validation Report — tidy.measure_validation_report","text":"","code":"# Create sample data blank_data <- data.frame(   response = rnorm(10, mean = 50, sd = 15),   sample_type = \"blank\" ) lod_result <- measure_lod(blank_data, response_col = \"response\")  report <- measure_validation_report(   title = \"Test Report\",   lod_loq = lod_result ) tidy(report) #> # A tibble: 1 × 6 #>   section limit_type value method       k uncertainty #>   <chr>   <chr>      <dbl> <chr>    <dbl>       <dbl> #> 1 LOD/LOQ LOD         81.3 blank_sd     3        10.2"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidiers for measure steps — tidy.measure_accuracy","title":"Tidiers for measure steps — tidy.measure_accuracy","text":"Tidiers measure steps","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidiers for measure steps — tidy.measure_accuracy","text":"","code":"# S3 method for class 'measure_accuracy' tidy(x, ...)  # S3 method for class 'measure_linearity' tidy(x, ...)  # S3 method for class 'measure_carryover' tidy(x, ...)  # S3 method for class 'step_measure_align_shift' tidy(x, ...)  # S3 method for class 'step_measure_align_reference' tidy(x, ...)  # S3 method for class 'step_measure_align_dtw' tidy(x, ...)  # S3 method for class 'step_measure_align_ptw' tidy(x, ...)  # S3 method for class 'step_measure_align_cow' tidy(x, ...)  # S3 method for class 'step_measure_augment_noise' tidy(x, ...)  # S3 method for class 'step_measure_augment_shift' tidy(x, ...)  # S3 method for class 'step_measure_augment_scale' tidy(x, ...)  # S3 method for class 'step_measure_baseline_als' tidy(x, ...)  # S3 method for class 'step_measure_baseline_custom' tidy(x, ...)  # S3 method for class 'step_measure_baseline_rolling' tidy(x, ...)  # S3 method for class 'step_measure_baseline_airpls' tidy(x, ...)  # S3 method for class 'step_measure_baseline_snip' tidy(x, ...)  # S3 method for class 'step_measure_baseline_arpls' tidy(x, ...)  # S3 method for class 'step_measure_baseline_tophat' tidy(x, ...)  # S3 method for class 'step_measure_baseline_morph' tidy(x, ...)  # S3 method for class 'step_measure_baseline_minima' tidy(x, ...)  # S3 method for class 'step_measure_baseline_auto' tidy(x, ...)  # S3 method for class 'step_measure_baseline_gpc' tidy(x, ...)  # S3 method for class 'step_measure_baseline_poly' tidy(x, ...)  # S3 method for class 'step_measure_baseline_py' tidy(x, ...)  # S3 method for class 'step_measure_baseline_rf' tidy(x, ...)  # S3 method for class 'step_measure_batch_reference' tidy(x, ...)  # S3 method for class 'step_measure_calibrate_x' tidy(x, ...)  # S3 method for class 'step_measure_calibrate_y' tidy(x, ...)  # S3 method for class 'measure_control_limits' tidy(x, ...)  # S3 method for class 'measure_control_chart' tidy(x, type = c(\"data\", \"violations\", \"limits\"), ...)  # S3 method for class 'measure_sst' tidy(x, ...)  # S3 method for class 'step_measure_despike' tidy(x, ...)  # S3 method for class 'step_measure_detrend' tidy(x, ...)  # S3 method for class 'step_measure_dilution_correct' tidy(x, ...)  # S3 method for class 'step_measure_drift_qc_loess' tidy(x, ...)  # S3 method for class 'step_measure_drift_linear' tidy(x, ...)  # S3 method for class 'step_measure_drift_spline' tidy(x, ...)  # S3 method for class 'step_measure_qc_bracket' tidy(x, ...)  # S3 method for class 'step_measure_integrals' tidy(x, ...)  # S3 method for class 'step_measure_ratios' tidy(x, ...)  # S3 method for class 'step_measure_moments' tidy(x, ...)  # S3 method for class 'step_measure_bin' tidy(x, ...)  # S3 method for class 'step_measure_input_long' tidy(x, ...)  # S3 method for class 'step_measure_input_wide' tidy(x, ...)  # S3 method for class 'measure_matrix_effect' tidy(x, ...)  # S3 method for class 'measure_matrix_effect' glance(x, ...)  # S3 method for class 'step_measure_standard_addition' tidy(x, ...)  # S3 method for class 'step_measure_map' tidy(x, ...)  # S3 method for class 'measure_bland_altman' tidy(x, ...)  # S3 method for class 'measure_deming_regression' tidy(x, ...)  # S3 method for class 'measure_passing_bablok' tidy(x, ...)  # S3 method for class 'measure_proficiency_score' tidy(x, type = c(\"scores\", \"summary\"), ...)  # S3 method for class 'measure_bland_altman' glance(x, ...)  # S3 method for class 'measure_deming_regression' glance(x, ...)  # S3 method for class 'measure_passing_bablok' glance(x, ...)  # S3 method for class 'measure_proficiency_score' glance(x, ...)  # S3 method for class 'step_measure_msc' tidy(x, ...)  # S3 method for class 'step_measure_mw_averages' tidy(x, ...)  # S3 method for class 'step_measure_mw_fractions' tidy(x, ...)  # S3 method for class 'step_measure_mw_distribution' tidy(x, ...)  # S3 method for class 'step_measure_normalize_sum' tidy(x, ...)  # S3 method for class 'step_measure_normalize_max' tidy(x, ...)  # S3 method for class 'step_measure_normalize_range' tidy(x, ...)  # S3 method for class 'step_measure_normalize_vector' tidy(x, ...)  # S3 method for class 'step_measure_normalize_auc' tidy(x, ...)  # S3 method for class 'step_measure_normalize_peak' tidy(x, ...)  # S3 method for class 'step_measure_output_long' tidy(x, ...)  # S3 method for class 'step_measure_output_wide' tidy(x, ...)  # S3 method for class 'step_measure_peaks_detect' tidy(x, ...)  # S3 method for class 'step_measure_peaks_integrate' tidy(x, ...)  # S3 method for class 'step_measure_peaks_filter' tidy(x, ...)  # S3 method for class 'step_measure_peaks_to_table' tidy(x, ...)  # S3 method for class 'step_measure_peaks_deconvolve' tidy(x, ...)  # S3 method for class 'measure_precision' tidy(x, ...)  # S3 method for class 'measure_gage_rr' tidy(x, ...)  # S3 method for class 'step_measure_qc_snr' tidy(x, ...)  # S3 method for class 'step_measure_qc_saturated' tidy(x, ...)  # S3 method for class 'step_measure_impute' tidy(x, ...)  # S3 method for class 'step_measure_qc_outlier' tidy(x, ...)  # S3 method for class 'step_measure_subtract_blank' tidy(x, ...)  # S3 method for class 'step_measure_subtract_reference' tidy(x, ...)  # S3 method for class 'step_measure_ratio_reference' tidy(x, ...)  # S3 method for class 'step_measure_trim' tidy(x, ...)  # S3 method for class 'step_measure_exclude' tidy(x, ...)  # S3 method for class 'step_measure_resample' tidy(x, ...)  # S3 method for class 'step_measure_interpolate' tidy(x, ...)  # S3 method for class 'step_measure_savitzky_golay' tidy(x, ...)  # S3 method for class 'step_measure_center' tidy(x, ...)  # S3 method for class 'step_measure_scale_auto' tidy(x, ...)  # S3 method for class 'step_measure_scale_pareto' tidy(x, ...)  # S3 method for class 'step_measure_scale_range' tidy(x, ...)  # S3 method for class 'step_measure_scale_vast' tidy(x, ...)  # S3 method for class 'step_measure_emsc' tidy(x, ...)  # S3 method for class 'step_measure_osc' tidy(x, ...)  # S3 method for class 'step_measure_smooth_wavelet' tidy(x, ...)  # S3 method for class 'step_measure_smooth_ma' tidy(x, ...)  # S3 method for class 'step_measure_smooth_median' tidy(x, ...)  # S3 method for class 'step_measure_smooth_gaussian' tidy(x, ...)  # S3 method for class 'step_measure_filter_fourier' tidy(x, ...)  # S3 method for class 'step_measure_snv' tidy(x, ...)  # S3 method for class 'step_measure_absorbance' tidy(x, ...)  # S3 method for class 'step_measure_transmittance' tidy(x, ...)  # S3 method for class 'step_measure_log' tidy(x, ...)  # S3 method for class 'step_measure_kubelka_munk' tidy(x, ...)  # S3 method for class 'step_measure_derivative' tidy(x, ...)  # S3 method for class 'step_measure_derivative_gap' tidy(x, ...)  # S3 method for class 'step_measure_channel_align' tidy(x, ...)  # S3 method for class 'step_measure_channel_combine' tidy(x, ...)  # S3 method for class 'step_measure_channel_ratio' tidy(x, ...)  # S3 method for class 'step_measure_mcr_als' tidy(x, type = \"parameters\", ...)  # S3 method for class 'step_measure_parafac' tidy(x, type = \"parameters\", ...)  # S3 method for class 'step_measure_tucker' tidy(x, type = \"parameters\", ...)  # S3 method for class 'step_measure_surrogate_recovery' tidy(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tidy.recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidiers for measure steps — tidy.measure_accuracy","text":"x step object. ... used. type PARAFAC steps, either \"loadings\" \"parameters\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tunable_measure.html","id":null,"dir":"Reference","previous_headings":"","what":"tunable methods for measure — tunable.step_measure_align_cow","title":"tunable methods for measure — tunable.step_measure_align_cow","text":"functions define parameters can tuned specific steps. also define recommended objects dials package can used generate new parameter values characteristics.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tunable_measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tunable methods for measure — tunable.step_measure_align_cow","text":"","code":"# S3 method for class 'step_measure_align_cow' tunable(x, ...)  # S3 method for class 'step_measure_baseline_custom' tunable(x, ...)  # S3 method for class 'step_measure_baseline_airpls' tunable(x, ...)  # S3 method for class 'step_measure_baseline_arpls' tunable(x, ...)  # S3 method for class 'step_measure_baseline_py' tunable(x, ...)  # S3 method for class 'step_measure_bin' tunable(x, ...)  # S3 method for class 'step_measure_savitzky_golay' tunable(x, ...)  # S3 method for class 'step_measure_baseline_als' tunable(x, ...)  # S3 method for class 'step_measure_baseline_poly' tunable(x, ...)  # S3 method for class 'step_measure_baseline_rf' tunable(x, ...)  # S3 method for class 'step_measure_detrend' tunable(x, ...)  # S3 method for class 'step_measure_normalize_peak' tunable(x, ...)  # S3 method for class 'step_measure_derivative' tunable(x, ...)  # S3 method for class 'step_measure_derivative_gap' tunable(x, ...)  # S3 method for class 'step_measure_baseline_airpls' tunable(x, ...)  # S3 method for class 'step_measure_baseline_arpls' tunable(x, ...)  # S3 method for class 'step_measure_smooth_ma' tunable(x, ...)  # S3 method for class 'step_measure_smooth_median' tunable(x, ...)  # S3 method for class 'step_measure_smooth_gaussian' tunable(x, ...)  # S3 method for class 'step_measure_filter_fourier' tunable(x, ...)  # S3 method for class 'step_measure_despike' tunable(x, ...)  # S3 method for class 'step_measure_align_shift' tunable(x, ...)  # S3 method for class 'step_measure_qc_outlier' tunable(x, ...)  # S3 method for class 'step_measure_emsc' tunable(x, ...)  # S3 method for class 'step_measure_osc' tunable(x, ...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/tunable_measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tunable methods for measure — tunable.step_measure_align_cow","text":"x recipe step object ... used.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/tunable_measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"tunable methods for measure — tunable.step_measure_align_cow","text":"tibble object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Uncertainty Component — uncertainty_component","title":"Create an Uncertainty Component — uncertainty_component","text":"Defines single uncertainty component use uncertainty budget. follows ISO GUM terminology Type (statistical) Type B (means) uncertainty evaluation.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Uncertainty Component — uncertainty_component","text":"","code":"uncertainty_component(   name,   value,   type = c(\"A\", \"B\"),   sensitivity = 1,   df = Inf,   distribution = c(\"normal\", \"rectangular\", \"triangular\", \"u-shaped\"),   coverage_factor = 1 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Uncertainty Component — uncertainty_component","text":"name Name/description uncertainty source. value Standard uncertainty value (u). type Type evaluation: \"\": Statistical evaluation (repeated measurements) \"B\": Evaluated means (specifications, certificates, etc.) sensitivity Sensitivity coefficient (c). Default 1. contribution combined uncertainty |c| * u. df Degrees freedom component. Default Inf (Type B DOF information). distribution Distribution assumed Type B: \"normal\": Normal distribution (default Type ) \"rectangular\": Uniform distribution (common Type B) \"triangular\": Triangular distribution \"u-shaped\": U-shaped distribution coverage_factor Coverage factor (k) used derive value expanded uncertainty. Default 1 (value already standard uncertainty).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Uncertainty Component — uncertainty_component","text":"uncertainty_component object.","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"type-a-evaluation","dir":"Reference","previous_headings":"","what":"Type A Evaluation","title":"Create an Uncertainty Component — uncertainty_component","text":"Type components, standard uncertainty typically standard error mean: u = s / sqrt(n), df = n - 1.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"type-b-evaluation","dir":"Reference","previous_headings":"","what":"Type B Evaluation","title":"Create an Uncertainty Component — uncertainty_component","text":"Type B components expanded uncertainties coverage k: u = U / k. rectangular distributions: u = / sqrt(3).","code":""},{"path":[]},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_component.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Uncertainty Component — uncertainty_component","text":"","code":"# Type A: Repeatability from 10 measurements u_repeat <- uncertainty_component(   name = \"Repeatability\",   value = 0.05,  # Standard error of mean   type = \"A\",   df = 9 )  # Type B: Calibrator uncertainty from certificate (k=2) u_cal <- uncertainty_component(   name = \"Calibrator\",   value = 0.02 / 2,  # Divide expanded uncertainty by k   type = \"B\",   df = 50 )  # Type B: Temperature effect (rectangular distribution) u_temp <- uncertainty_component(   name = \"Temperature\",   value = 0.1 / sqrt(3),  # Half-width / sqrt(3) for rectangular   type = \"B\",   distribution = \"rectangular\" )"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_a.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","title":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","text":"Helper function calculate Type uncertainty vector repeated measurements.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_a.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","text":"","code":"uncertainty_type_a(x, name = \"Type A\", sensitivity = 1)"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_a.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","text":"x Numeric vector repeated measurements. name Name uncertainty component. sensitivity Sensitivity coefficient (default 1).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_a.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","text":"uncertainty_component object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_a.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Type A Uncertainty from Repeated Measurements — uncertainty_type_a","text":"","code":"measurements <- c(10.1, 10.3, 9.9, 10.2, 10.0) u_repeat <- uncertainty_type_a(measurements, \"Repeatability\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_expanded.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","title":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","text":"Helper function create Type B uncertainty component expanded uncertainty value (e.g., certificate).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_expanded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","text":"","code":"uncertainty_type_b_expanded(   expanded_U,   k = 2,   name = \"Type B\",   df = Inf,   sensitivity = 1 )"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_expanded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","text":"expanded_U expanded uncertainty value. k Coverage factor used expanded uncertainty. name Name uncertainty component. df Degrees freedom (default Inf). sensitivity Sensitivity coefficient (default 1).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_expanded.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","text":"uncertainty_component object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_expanded.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Type B Uncertainty from Expanded Uncertainty — uncertainty_type_b_expanded","text":"","code":"# From a calibrator certificate: U = 0.05, k = 2 u_cal <- uncertainty_type_b_expanded(0.05, k = 2, name = \"Calibrator\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_rectangular.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","title":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","text":"Helper function create Type B uncertainty component rectangular (uniform) distribution, common specifications tolerances.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_rectangular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","text":"","code":"uncertainty_type_b_rectangular(half_width, name = \"Type B\", sensitivity = 1)"},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_rectangular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","text":"half_width half-width rectangular distribution (). Standard uncertainty / sqrt(3). name Name uncertainty component. sensitivity Sensitivity coefficient (default 1).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_rectangular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","text":"uncertainty_component object.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/uncertainty_type_b_rectangular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Type B Uncertainty from Rectangular Distribution — uncertainty_type_b_rectangular","text":"","code":"# Temperature stability +/- 0.5 degrees u_temp <- uncertainty_type_b_rectangular(0.5, name = \"Temperature\")"},{"path":"https://jameshwade.github.io/measure/dev/reference/validate_measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate measure data — validate_measure","title":"Validate measure data — validate_measure","text":"Performs comprehensive validation checks measure data, including axis monotonicity, duplicate detection, missing value detection, spacing regularity.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/validate_measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate measure data — validate_measure","text":"","code":"validate_measure(   x,   checks = c(\"monotonic\", \"duplicates\", \"missing\", \"spacing\"),   tolerance = 1e-06,   action = c(\"error\", \"warn\", \"message\") )"},{"path":"https://jameshwade.github.io/measure/dev/reference/validate_measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate measure data — validate_measure","text":"x measure_tbl, measure_list, data frame measure column. checks Character vector checks perform. Default checks: \"monotonic\", \"duplicates\", \"missing\", \"spacing\". tolerance Numeric tolerance spacing regularity check. Default 1e-6. action validation fails: \"error\" (default), \"warn\", \"message\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/validate_measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate measure data — validate_measure","text":"Invisibly returns list validation results. element list valid (logical), message (character), details.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/validate_measure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate measure data — validate_measure","text":"","code":"# Create valid measure data spec <- new_measure_tbl(location = 1:100, value = sin(1:100 / 10)) validate_measure(spec)  # Data with issues spec_dup <- new_measure_tbl(location = c(1, 2, 2, 3), value = c(1, 2, 3, 4)) try(validate_measure(spec_dup)) #> Error in validate_measure(spec_dup) : Measure validation failed: #> ✖ Duplicate locations found in 1 sample(s) Irregular spacing found in 1 #>   sample(s)  # Only check specific issues validate_measure(spec, checks = c(\"monotonic\", \"missing\"))"},{"path":"https://jameshwade.github.io/measure/dev/reference/vctrs-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"vctrs methods for measure classes — print.measure_tbl","title":"vctrs methods for measure classes — print.measure_tbl","text":"methods enable nice printing measure objects tibbles.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/vctrs-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"vctrs methods for measure classes — print.measure_tbl","text":"","code":"# S3 method for class 'measure_tbl' print(x, ..., n = NULL, width = NULL)  # S3 method for class 'measure_tbl' vec_ptype_abbr(x, ...)  # S3 method for class 'measure_list' print(x, ...)  # S3 method for class 'measure_list' vec_ptype_abbr(x, ...)  # S3 method for class 'measure_list' vec_ptype_full(x, ...)  # S3 method for class 'measure_list' format(x, ...)  # S3 method for class 'measure_list' obj_print_data(x, ...)  # S3 method for class 'measure_list' x[i, ...]  # S3 method for class 'measure_list' x[[i, ...]]  # S3 method for class 'measure_list' c(...)  # S3 method for class 'measure_nd_tbl' print(x, ..., n = NULL, width = NULL)  # S3 method for class 'measure_nd_tbl' vec_ptype_abbr(x, ...)  # S3 method for class 'measure_nd_list' print(x, ...)  # S3 method for class 'measure_nd_list' vec_ptype_abbr(x, ...)  # S3 method for class 'measure_nd_list' vec_ptype_full(x, ...)  # S3 method for class 'measure_nd_list' format(x, ...)  # S3 method for class 'measure_nd_list' obj_print_data(x, ...)  # S3 method for class 'measure_nd_list' x[i, ...]  # S3 method for class 'measure_nd_list' x[[i, ...]]  # S3 method for class 'measure_nd_list' c(...)"},{"path":"https://jameshwade.github.io/measure/dev/reference/vctrs-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"vctrs methods for measure classes — print.measure_tbl","text":"x measure_list measure_tbl object. ... Additional arguments (unused).","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter for measure steps — window_side","title":"Parameter for measure steps — window_side","text":"window_side() differentiation_order() used Savitzky-Golay processing.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter for measure steps — window_side","text":"","code":"window_side(range = c(1L, 5L), trans = NULL)  differentiation_order(range = c(0L, 4L), trans = NULL)"},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter for measure steps — window_side","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::transform_log10() scales::transform_reciprocal(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter for measure steps — window_side","text":"function classes \"quant_param\" \"param\".","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameter for measure steps — window_side","text":"parameter often used correct zero-count data tables proportions.","code":""},{"path":"https://jameshwade.github.io/measure/dev/reference/window_side.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter for measure steps — window_side","text":"","code":"window_side() #> Window Size (one side) (quantitative) #> Range: [1, 5] differentiation_order() #> Differentiation Order (quantitative) #> Range: [0, 4]"}]
