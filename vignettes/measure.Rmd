---
title: "Getting Started with measure"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with measure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 4
)
```

```{r setup, message = FALSE}
library(measure)
library(recipes)
library(dplyr)
library(tidyr)
library(ggplot2)
```

## Introduction

The measure package extends [tidymodels](https://www.tidymodels.org/) with preprocessing steps designed specifically for analytical measurement data. If you work with spectroscopy, chromatography, or other instrument-generated signals, measure provides familiar recipes-style preprocessing that integrates seamlessly with the tidymodels ecosystem.

### Why measure?

Analytical data has unique preprocessing requirements:

1. **Multi-dimensional signals**: Each sample produces many measurements (e.g., absorbance at hundreds of wavelengths)
2. **Specialized transformations**: Techniques like Savitzky-Golay derivatives and scatter correction are standard practice
3. **Format flexibility**: Data may arrive in wide format (one column per wavelength) or long format (one row per measurement)

measure handles all of this while keeping the intuitive recipes interface you already know.
## The measure workflow

The typical measure workflow has three phases:

1. **Input step**: Convert your data to measure's internal format
2. **Processing steps**: Apply spectral preprocessing (smoothing, derivatives, normalization)
3. **Output step**: Convert back to a format suitable for modeling

Let's see this in action with real data.

## Example: NIR spectroscopy of meat samples

We'll use the `meats_long` dataset included in measure. This contains NIR (Near-Infrared) transmittance spectra of meat samples, with the goal of predicting water, fat, and protein content.

```{r data}
data(meats_long)

# Each sample has 100 spectral channels
meats_long
```

The data is in "long" format where each row represents one measurement at one channel for one sample. Let's visualize a few spectra:

```{r raw-spectra}
meats_long |>
  filter(id <= 10) |>
  ggplot(aes(x = channel, y = transmittance, group = id, color = factor(id))) +
  geom_line(alpha = 0.8) +
  labs(
    x = "Channel",
    y = "Transmittance",
    title = "Raw NIR Spectra",
    color = "Sample ID"
  ) +
  theme_minimal()
```

### Creating a recipe

We start by creating a recipe that specifies the outcome variables and predictors:

```{r basic-recipe}
rec <- recipe(water + fat + protein ~ ., data = meats_long) |>
  # Mark 'id' as an identifier, not a predictor
  update_role(id, new_role = "id")

rec
```

### Step 1: Input the measurements

Since our data is in long format, we use `step_measure_input_long()`. This converts the `transmittance` values (indexed by `channel`) into measure's internal format:

```{r input-step}
rec <- rec |>
  step_measure_input_long(transmittance, location = vars(channel))

rec
```

After prepping and baking, you'll see that the original `transmittance` and `channel` columns are replaced by a `.measures` column containing nested tibbles:

```{r show-internal}
rec_prepped <- prep(rec)
internal_format <- bake(rec_prepped, new_data = NULL)

# The data now has a .measures list-column
internal_format

# Each element contains location and value
internal_format$.measures[[1]]
```

### Step 2: Apply preprocessing

Now we can add spectral preprocessing steps. These operate on the internal `.measures` column:

```{r processing-steps}
rec <- recipe(water + fat + protein ~ ., data = meats_long) |>
  update_role(id, new_role = "id") |>
  step_measure_input_long(transmittance, location = vars(channel)) |>

  # Savitzky-Golay first derivative for baseline removal
  step_measure_savitzky_golay(
    window_side = 5,
    differentiation_order = 1
  ) |>
  # Standard Normal Variate for scatter correction
  step_measure_snv()

rec
```

measure provides many built-in preprocessing steps:

- **Filtering**: `step_measure_savitzky_golay()` for smoothing and derivatives
- **Scatter correction**: `step_measure_snv()`, `step_measure_msc()`
- **Sample-wise normalization**: `step_measure_normalize_sum()`, `step_measure_normalize_max()`, `step_measure_normalize_peak()`, and more
- **Variable-wise scaling**: `step_measure_center()`, `step_measure_scale_auto()`, `step_measure_scale_pareto()`, and more
- **Custom transformations**: `step_measure_map()` for when built-in steps don't cover your needs

See `vignette("preprocessing")` for details on all available options.

Let's see how this transforms our spectra:

```{r processed-spectra}
processed <- bake(prep(rec), new_data = NULL)

# Unnest for plotting
plot_data <- processed |>
  filter(row_number() <= 10) |>
  mutate(sample_id = row_number()) |>
  unnest(.measures)

ggplot(plot_data, aes(x = location, y = value, group = sample_id, color = factor(sample_id))) +
  geom_line(alpha = 0.8) +
  labs(
    x = "Channel",
    y = "Preprocessed Signal",
    title = "After Savitzky-Golay + SNV",
    subtitle = "First derivative removes baseline; SNV normalizes scatter",
    color = "Sample"
  ) +
  theme_minimal()
```

### Step 3: Output for modeling

For most modeling workflows, you'll want data in wide format (one column per spectral feature):

```{r output-step}
rec_full <- recipe(water + fat + protein ~ ., data = meats_long) |>
  update_role(id, new_role = "id") |>
  step_measure_input_long(transmittance, location = vars(channel)) |>
  step_measure_savitzky_golay(window_side = 5, differentiation_order = 1) |>
  step_measure_snv() |>
  step_measure_output_wide(prefix = "nir_")

modeling_data <- bake(prep(rec_full), new_data = NULL)

# Ready for modeling!
modeling_data[1:5, 1:10]
```

## Working with wide-format data

If your data starts in wide format (measurements as columns), use `step_measure_input_wide()` instead. Here's an example using data from modeldata:

```{r wide-format, message = FALSE}
library(modeldata)
data(meats)

# This data has x_001, x_002, ... columns for spectral channels
head(meats[, 1:8])

# Create location values (optional - defaults to 1, 2, 3, ...)
wavelengths <- seq(850, 1050, length.out = 100)

rec_wide <- recipe(water + fat + protein ~ ., data = meats) |>
  step_measure_input_wide(
    starts_with("x_"),
    location_values = wavelengths
  ) |>
  step_measure_snv() |>
  step_measure_output_wide(prefix = "spec_")

bake(prep(rec_wide), new_data = NULL)[1:5, 1:8]
```

## Applying recipes to new data

Like any recipe, you prep once on training data, then bake on new data:
```{r train-test}
# Split the data
set.seed(123)
train_idx <- sample(nrow(meats), 180)
train_data <- meats[train_idx, ]
test_data <- meats[-train_idx, ]

# Prep on training data
rec <- recipe(water + fat + protein ~ ., data = train_data) |>
  step_measure_input_wide(starts_with("x_")) |>
  step_measure_savitzky_golay(window_side = 7, differentiation_order = 1) |>
  step_measure_snv() |>
  step_measure_output_wide(prefix = "nir_")

rec_prepped <- prep(rec, training = train_data)

# Bake on both
train_processed <- bake(rec_prepped, new_data = NULL)
test_processed <- bake(rec_prepped, new_data = test_data)

cat("Training samples:", nrow(train_processed), "\n")
cat("Test samples:", nrow(test_processed), "\n")
```

## Integration with tidymodels

measure recipes work seamlessly with the broader tidymodels ecosystem. See `vignette("recipes")` for complete examples including:

- Bundling preprocessing with models using workflows
- Cross-validation with measure recipes
- Hyperparameter tuning for preprocessing steps
- Comparing preprocessing strategies

## Finding test data

### Included datasets

The measure package includes several datasets for testing and examples:
```{r datasets, eval=FALSE}
# NIR spectroscopy
data(meats_long)           # 215 meat samples, long format

# Raman spectroscopy
data(glucose_bioreactors)  # Loads bioreactors_small (210) and bioreactors_large (42)

# Chromatography
data(hplc_chromatograms)   # 20 simulated HPLC samples
data(sec_chromatograms)    # 10 SEC samples (5 standards + 5 polymers)
data(sec_calibration)      # MW calibration standards

# Mass spectrometry
data(maldi_spectra)        # 16 simulated MALDI-TOF spectra
```

### External data sources

For additional test data, several R packages provide spectral datasets:

```{r external-data, eval=FALSE}
# modeldata - meats dataset in wide format
library(modeldata)
data(meats)

# prospectr - NIR soil spectroscopy (825 samples)
data(NIRsoil, package = "prospectr")
```
**Online repositories** with public analytical data:

- **[Mendeley Data](https://data.mendeley.com)** - Search for spectroscopy/chromatography datasets
- **[Zenodo](https://zenodo.org)** - Open science data repository
- **[NIST Chemistry WebBook](https://webbook.nist.gov/chemistry/)** - Reference IR, MS, UV-Vis spectra
- **[MassBank](https://massbank.eu/MassBank/)** - Mass spectrometry database
- **[HMDB](https://hmdb.ca/)** - Human Metabolome Database (NMR, MS)

## Next steps

- See `vignette("preprocessing")` for a detailed guide to each preprocessing technique, including:
  - Savitzky-Golay smoothing and derivatives
  - SNV and MSC scatter correction
  - Sample-wise normalization (sum, max, range, peak region)
  - Variable-wise scaling (centering, auto-scaling, Pareto scaling)
- Explore hyperparameter tuning with `tune` - Savitzky-Golay and peak normalization steps are tunable!
- Check out the [function reference](https://jameshwade.github.io/measure/reference/) for all available steps
